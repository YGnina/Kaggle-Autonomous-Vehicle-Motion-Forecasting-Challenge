{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0e7526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel, TFTModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "\n",
    "import os, os.path  \n",
    "import pickle5 as pickle\n",
    "from glob import glob\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04b3353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = 'C:\\\\Users\\\\sky\\\\DESKTOP\\\\argo2\\\\'\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    #f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    f_in = ROOT_PATH + split + \"\\\\\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        #f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        f_out = ROOT_PATH + split + \"\\\\\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2052ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "#cities = [\"palo-alto\"] # testing only\n",
    "\n",
    "scaler = 1500\n",
    "\n",
    "\n",
    "posX = []\n",
    "posY = []\n",
    "\n",
    "for city in cities:\n",
    "    data = get_city_trajectories(city = city, split = split)\n",
    "    for each in range(len(data[0])):\n",
    "        each_series = []\n",
    "        each_series.extend(data[0][each][:,0].tolist())\n",
    "        each_series.extend(data[1][each][:,0].tolist())\n",
    "        df = (pd.DataFrame (each_series, columns = ['pos'])/scaler).astype(np.float32)\n",
    "        df.insert(0, 'time_index', range(len(df)))\n",
    "        posX.append(TimeSeries.from_dataframe(df, 'time_index', 'pos'))\n",
    "        \n",
    "        each_series = []\n",
    "        each_series.extend(data[0][each][:,1].tolist())\n",
    "        each_series.extend(data[1][each][:,1].tolist())\n",
    "        df = (pd.DataFrame (each_series, columns = ['pos'])/scaler).astype(np.float32)\n",
    "        df.insert(0, 'time_index', range(len(df)))\n",
    "        posY.append(TimeSeries.from_dataframe(df, 'time_index', 'pos'))\n",
    "\n",
    "c = int(len(posX) * 0.8)\n",
    "posX_train, posY_train = posX[:c], posY[:c]\n",
    "posX_test, posY_test = posX[c:], posY[c:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-02 19:07:22,505] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: `torch_device_str` is deprecated and will be removed in a coming Darts version. For full support of all torch devices, use PyTorch-Lightnings trainer flags and pass them inside `pl_trainer_kwargs`. Flags of interest are {`accelerator`, `gpus`, `auto_select_gpus`, `devices`}. For more information, visit https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags\n",
      "[2022-04-02 19:07:22,505] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: `torch_device_str` is deprecated and will be removed in a coming Darts version. For full support of all torch devices, use PyTorch-Lightnings trainer flags and pass them inside `pl_trainer_kwargs`. Flags of interest are {`accelerator`, `gpus`, `auto_select_gpus`, `devices`}. For more information, visit https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags\n",
      "[2022-04-02 19:07:22,753] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 163052 samples.\n",
      "[2022-04-02 19:07:22,753] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 163052 samples.\n",
      "[2022-04-02 19:07:22,883] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 32-bits; casting model to float32.\n",
      "[2022-04-02 19:07:22,883] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 32-bits; casting model to float32.\n",
      "[2022-04-02 19:07:22,884] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-04-02 19:07:22,884] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 13.6 M\n",
      "-----------------------------------------\n",
      "13.6 M    Trainable params\n",
      "1.9 K     Non-trainable params\n",
      "13.6 M    Total params\n",
      "54.509    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|██████████████████████▍     | 1631/2039 [04:42<01:10,  5.78it/s, loss=1.24, v_num=logs, train_loss=1.060]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|██████████████████████▍     | 1634/2039 [04:42<01:10,  5.78it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  80%|██████████████████████▍     | 1637/2039 [04:42<01:09,  5.79it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  80%|██████████████████████▌     | 1640/2039 [04:42<01:08,  5.80it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▌     | 1643/2039 [04:42<01:08,  5.81it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▌     | 1646/2039 [04:43<01:07,  5.82it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▋     | 1649/2039 [04:43<01:06,  5.82it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▋     | 1652/2039 [04:43<01:06,  5.83it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▋     | 1655/2039 [04:43<01:05,  5.84it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▊     | 1658/2039 [04:43<01:05,  5.85it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████▊     | 1661/2039 [04:43<01:04,  5.85it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|██████████████████████▊     | 1664/2039 [04:43<01:03,  5.86it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|██████████████████████▉     | 1667/2039 [04:43<01:03,  5.87it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|██████████████████████▉     | 1670/2039 [04:44<01:02,  5.88it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|██████████████████████▉     | 1673/2039 [04:44<01:02,  5.89it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|███████████████████████     | 1676/2039 [04:44<01:01,  5.89it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|███████████████████████     | 1679/2039 [04:44<01:01,  5.90it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  82%|███████████████████████     | 1682/2039 [04:44<01:00,  5.91it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████▏    | 1685/2039 [04:44<00:59,  5.92it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████▏    | 1688/2039 [04:44<00:59,  5.92it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████▏    | 1691/2039 [04:45<00:58,  5.93it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████▎    | 1694/2039 [04:45<00:58,  5.94it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████▎    | 1697/2039 [04:45<00:57,  5.95it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████▎    | 1700/2039 [04:45<00:56,  5.95it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▍    | 1703/2039 [04:45<00:56,  5.96it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▍    | 1706/2039 [04:45<00:55,  5.97it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▍    | 1709/2039 [04:45<00:55,  5.98it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▌    | 1712/2039 [04:46<00:54,  5.99it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▌    | 1715/2039 [04:46<00:54,  5.99it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▌    | 1718/2039 [04:46<00:53,  6.00it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  84%|███████████████████████▋    | 1721/2039 [04:46<00:52,  6.01it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▋    | 1724/2039 [04:46<00:52,  6.01it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▋    | 1727/2039 [04:46<00:51,  6.02it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▊    | 1730/2039 [04:46<00:51,  6.03it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▊    | 1733/2039 [04:47<00:50,  6.04it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▊    | 1736/2039 [04:47<00:50,  6.05it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▉    | 1739/2039 [04:47<00:49,  6.05it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  85%|███████████████████████▉    | 1742/2039 [04:47<00:49,  6.06it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|███████████████████████▉    | 1745/2039 [04:47<00:48,  6.07it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████    | 1748/2039 [04:47<00:47,  6.08it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████    | 1751/2039 [04:47<00:47,  6.08it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████    | 1754/2039 [04:48<00:46,  6.09it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████▏   | 1757/2039 [04:48<00:46,  6.10it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████▏   | 1760/2039 [04:48<00:45,  6.11it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████▏   | 1763/2039 [04:48<00:45,  6.11it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▎   | 1766/2039 [04:48<00:44,  6.12it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▎   | 1769/2039 [04:48<00:44,  6.13it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▎   | 1772/2039 [04:48<00:43,  6.14it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▎   | 1775/2039 [04:48<00:42,  6.14it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▍   | 1778/2039 [04:49<00:42,  6.15it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▍   | 1781/2039 [04:49<00:41,  6.16it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  87%|████████████████████████▍   | 1784/2039 [04:49<00:41,  6.16it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████▌   | 1787/2039 [04:49<00:40,  6.17it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████▌   | 1790/2039 [04:49<00:40,  6.18it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████▌   | 1793/2039 [04:49<00:39,  6.19it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████▋   | 1796/2039 [04:49<00:39,  6.19it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████▋   | 1799/2039 [04:50<00:38,  6.20it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  88%|████████████████████████▋   | 1802/2039 [04:50<00:38,  6.21it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████▊   | 1805/2039 [04:50<00:37,  6.22it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████▊   | 1808/2039 [04:50<00:37,  6.22it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████▊   | 1811/2039 [04:50<00:36,  6.23it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████▉   | 1814/2039 [04:50<00:36,  6.24it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████▉   | 1817/2039 [04:50<00:35,  6.25it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████▉   | 1820/2039 [04:51<00:35,  6.25it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████   | 1823/2039 [04:51<00:34,  6.26it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████   | 1826/2039 [04:51<00:33,  6.27it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|█████████████████████████   | 1829/2039 [04:51<00:33,  6.28it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████▏  | 1832/2039 [04:51<00:32,  6.28it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████▏  | 1835/2039 [04:51<00:32,  6.29it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████▏  | 1838/2039 [04:51<00:31,  6.30it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████▎  | 1841/2039 [04:51<00:31,  6.31it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  90%|█████████████████████████▎  | 1844/2039 [04:52<00:30,  6.31it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▎  | 1847/2039 [04:52<00:30,  6.32it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▍  | 1850/2039 [04:52<00:29,  6.33it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▍  | 1853/2039 [04:52<00:29,  6.33it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▍  | 1856/2039 [04:52<00:28,  6.34it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▌  | 1859/2039 [04:52<00:28,  6.35it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▌  | 1862/2039 [04:52<00:27,  6.36it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  91%|█████████████████████████▌  | 1865/2039 [04:53<00:27,  6.36it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▋  | 1868/2039 [04:53<00:26,  6.37it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▋  | 1871/2039 [04:53<00:26,  6.38it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▋  | 1874/2039 [04:53<00:25,  6.39it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▊  | 1877/2039 [04:53<00:25,  6.39it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▊  | 1880/2039 [04:53<00:24,  6.40it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▊  | 1883/2039 [04:53<00:24,  6.41it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  92%|█████████████████████████▉  | 1886/2039 [04:54<00:23,  6.41it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████████▉  | 1889/2039 [04:54<00:23,  6.42it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  93%|█████████████████████████▉  | 1892/2039 [04:54<00:22,  6.43it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████  | 1895/2039 [04:54<00:22,  6.44it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████  | 1898/2039 [04:54<00:21,  6.44it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████  | 1901/2039 [04:54<00:21,  6.45it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  93%|██████████████████████████▏ | 1904/2039 [04:54<00:20,  6.46it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▏ | 1907/2039 [04:55<00:20,  6.46it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▏ | 1910/2039 [04:55<00:19,  6.47it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▎ | 1913/2039 [04:55<00:19,  6.48it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▎ | 1916/2039 [04:55<00:18,  6.49it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▎ | 1919/2039 [04:55<00:18,  6.49it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▍ | 1922/2039 [04:55<00:18,  6.50it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  94%|██████████████████████████▍ | 1925/2039 [04:55<00:17,  6.51it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▍ | 1928/2039 [04:55<00:17,  6.51it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▌ | 1931/2039 [04:56<00:16,  6.52it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▌ | 1934/2039 [04:56<00:16,  6.53it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▌ | 1937/2039 [04:56<00:15,  6.54it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▋ | 1940/2039 [04:56<00:15,  6.54it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▋ | 1943/2039 [04:56<00:14,  6.55it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████▋ | 1946/2039 [04:56<00:14,  6.56it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▊ | 1949/2039 [04:56<00:13,  6.56it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▊ | 1952/2039 [04:57<00:13,  6.57it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▊ | 1955/2039 [04:57<00:12,  6.58it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▉ | 1958/2039 [04:57<00:12,  6.58it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▉ | 1961/2039 [04:57<00:11,  6.59it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████▉ | 1964/2039 [04:57<00:11,  6.60it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  96%|███████████████████████████ | 1967/2039 [04:57<00:10,  6.61it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████ | 1970/2039 [04:57<00:10,  6.61it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████ | 1973/2039 [04:58<00:09,  6.62it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████▏| 1976/2039 [04:58<00:09,  6.63it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████▏| 1979/2039 [04:58<00:09,  6.63it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████▏| 1982/2039 [04:58<00:08,  6.64it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████▎| 1985/2039 [04:58<00:08,  6.65it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  97%|███████████████████████████▎| 1988/2039 [04:58<00:07,  6.66it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████▎| 1991/2039 [04:58<00:07,  6.66it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████▍| 1994/2039 [04:58<00:06,  6.67it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████▍| 1997/2039 [04:59<00:06,  6.68it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████▍| 2000/2039 [04:59<00:05,  6.68it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████▌| 2003/2039 [04:59<00:05,  6.69it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  98%|███████████████████████████▌| 2006/2039 [04:59<00:04,  6.70it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▌| 2009/2039 [04:59<00:04,  6.70it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▋| 2012/2039 [04:59<00:04,  6.71it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▋| 2015/2039 [04:59<00:03,  6.72it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▋| 2018/2039 [05:00<00:03,  6.72it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▊| 2021/2039 [05:00<00:02,  6.73it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0:  99%|███████████████████████████▊| 2024/2039 [05:00<00:02,  6.74it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  99%|███████████████████████████▊| 2027/2039 [05:00<00:01,  6.75it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████▉| 2030/2039 [05:00<00:01,  6.75it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████▉| 2033/2039 [05:00<00:00,  6.76it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████▉| 2036/2039 [05:00<00:00,  6.77it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████| 2039/2039 [05:01<00:00,  6.77it/s, loss=1.24, v_num=logs, train_loss=1.060]\u001b[A\n",
      "Epoch 0: 100%|████████████| 2039/2039 [05:01<00:00,  6.77it/s, loss=1.24, v_num=logs, train_loss=1.060, val_loss=0.901]\u001b[A\n",
      "Epoch 1:   8%|▉           | 168/2039 [00:27<05:08,  6.06it/s, loss=0.786, v_num=logs, train_loss=0.600, val_loss=0.901]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  80%|████▊ | 1632/2039 [04:30<01:07,  6.03it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 1635/2039 [04:30<01:06,  6.04it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 1638/2039 [04:30<01:06,  6.05it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  80%|████▊ | 1641/2039 [04:31<01:05,  6.05it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 1644/2039 [04:31<01:05,  6.06it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 1647/2039 [04:31<01:04,  6.07it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 1650/2039 [04:31<01:03,  6.08it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 1653/2039 [04:31<01:03,  6.09it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  81%|████▊ | 1656/2039 [04:31<01:02,  6.10it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  81%|████▉ | 1659/2039 [04:31<01:02,  6.10it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1662/2039 [04:31<01:01,  6.11it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1665/2039 [04:32<01:01,  6.12it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1668/2039 [04:32<01:00,  6.13it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1671/2039 [04:32<00:59,  6.14it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1674/2039 [04:32<00:59,  6.14it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1677/2039 [04:32<00:58,  6.15it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  82%|████▉ | 1680/2039 [04:32<00:58,  6.16it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|████▉ | 1683/2039 [04:32<00:57,  6.17it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|████▉ | 1686/2039 [04:32<00:57,  6.18it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|████▉ | 1689/2039 [04:33<00:56,  6.18it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|████▉ | 1692/2039 [04:33<00:56,  6.19it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|████▉ | 1695/2039 [04:33<00:55,  6.20it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|████▉ | 1698/2039 [04:33<00:54,  6.21it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  83%|█████ | 1701/2039 [04:33<00:54,  6.22it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1704/2039 [04:33<00:53,  6.23it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1707/2039 [04:33<00:53,  6.23it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1710/2039 [04:33<00:52,  6.24it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1713/2039 [04:34<00:52,  6.25it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1716/2039 [04:34<00:51,  6.26it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1719/2039 [04:34<00:51,  6.27it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  84%|█████ | 1722/2039 [04:34<00:50,  6.27it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████ | 1725/2039 [04:34<00:49,  6.28it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████ | 1728/2039 [04:34<00:49,  6.29it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████ | 1731/2039 [04:34<00:48,  6.30it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████ | 1734/2039 [04:35<00:48,  6.31it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████ | 1737/2039 [04:35<00:47,  6.31it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████ | 1740/2039 [04:35<00:47,  6.32it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  85%|█████▏| 1743/2039 [04:35<00:46,  6.33it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  86%|█████▏| 1746/2039 [04:35<00:46,  6.34it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  86%|█████▏| 1749/2039 [04:35<00:45,  6.34it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  86%|█████▏| 1752/2039 [04:35<00:45,  6.35it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  86%|█████▏| 1755/2039 [04:35<00:44,  6.36it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  86%|█████▏| 1758/2039 [04:36<00:44,  6.37it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  86%|█████▏| 1761/2039 [04:36<00:43,  6.38it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1764/2039 [04:36<00:43,  6.38it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1767/2039 [04:36<00:42,  6.39it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1770/2039 [04:36<00:42,  6.40it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1773/2039 [04:36<00:41,  6.41it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1776/2039 [04:36<00:40,  6.42it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1779/2039 [04:36<00:40,  6.42it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  87%|█████▏| 1782/2039 [04:37<00:39,  6.43it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1785/2039 [04:37<00:39,  6.44it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1788/2039 [04:37<00:38,  6.45it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1791/2039 [04:37<00:38,  6.45it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1794/2039 [04:37<00:37,  6.46it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1797/2039 [04:37<00:37,  6.47it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1800/2039 [04:37<00:36,  6.48it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  88%|█████▎| 1803/2039 [04:38<00:36,  6.49it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1806/2039 [04:38<00:35,  6.49it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1809/2039 [04:38<00:35,  6.50it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1812/2039 [04:38<00:34,  6.51it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1815/2039 [04:38<00:34,  6.52it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1818/2039 [04:38<00:33,  6.52it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1821/2039 [04:38<00:33,  6.53it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  89%|█████▎| 1824/2039 [04:38<00:32,  6.54it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  90%|█████▍| 1827/2039 [04:39<00:32,  6.55it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  90%|█████▍| 1830/2039 [04:39<00:31,  6.56it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  90%|█████▍| 1833/2039 [04:39<00:31,  6.56it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  90%|█████▍| 1836/2039 [04:39<00:30,  6.57it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  90%|█████▍| 1839/2039 [04:39<00:30,  6.58it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  90%|█████▍| 1842/2039 [04:39<00:29,  6.59it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  90%|█████▍| 1845/2039 [04:39<00:29,  6.59it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  91%|█████▍| 1848/2039 [04:39<00:28,  6.60it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  91%|█████▍| 1851/2039 [04:40<00:28,  6.61it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  91%|█████▍| 1854/2039 [04:40<00:27,  6.62it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  91%|█████▍| 1857/2039 [04:40<00:27,  6.62it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  91%|█████▍| 1860/2039 [04:40<00:26,  6.63it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  91%|█████▍| 1863/2039 [04:40<00:26,  6.64it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▍| 1866/2039 [04:40<00:26,  6.65it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▍| 1869/2039 [04:40<00:25,  6.65it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▌| 1872/2039 [04:40<00:25,  6.66it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▌| 1875/2039 [04:41<00:24,  6.67it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▌| 1878/2039 [04:41<00:24,  6.68it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▌| 1881/2039 [04:41<00:23,  6.69it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  92%|█████▌| 1884/2039 [04:41<00:23,  6.69it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1887/2039 [04:41<00:22,  6.70it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1890/2039 [04:41<00:22,  6.71it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1893/2039 [04:41<00:21,  6.72it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1896/2039 [04:42<00:21,  6.72it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1899/2039 [04:42<00:20,  6.73it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1902/2039 [04:42<00:20,  6.74it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  93%|█████▌| 1905/2039 [04:42<00:19,  6.75it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▌| 1908/2039 [04:42<00:19,  6.75it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▌| 1911/2039 [04:42<00:18,  6.76it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▋| 1914/2039 [04:42<00:18,  6.77it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▋| 1917/2039 [04:42<00:18,  6.78it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▋| 1920/2039 [04:43<00:17,  6.78it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▋| 1923/2039 [04:43<00:17,  6.79it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  94%|█████▋| 1926/2039 [04:43<00:16,  6.80it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1929/2039 [04:43<00:16,  6.81it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1932/2039 [04:43<00:15,  6.81it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1935/2039 [04:43<00:15,  6.82it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1938/2039 [04:43<00:14,  6.83it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1941/2039 [04:43<00:14,  6.84it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1944/2039 [04:44<00:13,  6.84it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  95%|█████▋| 1947/2039 [04:44<00:13,  6.85it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  96%|█████▋| 1950/2039 [04:44<00:12,  6.86it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  96%|█████▋| 1953/2039 [04:44<00:12,  6.87it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  96%|█████▊| 1956/2039 [04:44<00:12,  6.87it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  96%|█████▊| 1959/2039 [04:44<00:11,  6.88it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  96%|█████▊| 1962/2039 [04:44<00:11,  6.89it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  96%|█████▊| 1965/2039 [04:44<00:10,  6.89it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1968/2039 [04:45<00:10,  6.90it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1971/2039 [04:45<00:09,  6.91it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1974/2039 [04:45<00:09,  6.92it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1977/2039 [04:45<00:08,  6.92it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1980/2039 [04:45<00:08,  6.93it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1983/2039 [04:45<00:08,  6.94it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  97%|█████▊| 1986/2039 [04:45<00:07,  6.95it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▊| 1989/2039 [04:46<00:07,  6.95it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▊| 1992/2039 [04:46<00:06,  6.96it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▊| 1995/2039 [04:46<00:06,  6.97it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▉| 1998/2039 [04:46<00:05,  6.98it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▉| 2001/2039 [04:46<00:05,  6.98it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▉| 2004/2039 [04:46<00:05,  6.99it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  98%|█████▉| 2007/2039 [04:46<00:04,  7.00it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  99%|█████▉| 2010/2039 [04:46<00:04,  7.00it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  99%|█████▉| 2013/2039 [04:47<00:03,  7.01it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  99%|█████▉| 2016/2039 [04:47<00:03,  7.02it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  99%|█████▉| 2019/2039 [04:47<00:02,  7.03it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  99%|█████▉| 2022/2039 [04:47<00:02,  7.03it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  99%|█████▉| 2025/2039 [04:47<00:01,  7.04it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2:  99%|█████▉| 2028/2039 [04:47<00:01,  7.05it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2: 100%|█████▉| 2031/2039 [04:47<00:01,  7.06it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2: 100%|█████▉| 2034/2039 [04:47<00:00,  7.06it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2: 100%|█████▉| 2037/2039 [04:48<00:00,  7.07it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.0332]\u001b[A\n",
      "Epoch 2: 100%|█████| 2039/2039 [04:48<00:00,  7.07it/s, loss=0.00297, v_num=logs, train_loss=0.00281, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  80%|███▏| 1632/2039 [04:48<01:11,  5.66it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|███▏| 1635/2039 [04:48<01:11,  5.67it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  80%|███▏| 1638/2039 [04:48<01:10,  5.67it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  80%|███▏| 1641/2039 [04:48<01:10,  5.68it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  81%|███▏| 1644/2039 [04:48<01:09,  5.69it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  81%|███▏| 1647/2039 [04:49<01:08,  5.70it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  81%|███▏| 1650/2039 [04:49<01:08,  5.71it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  81%|███▏| 1653/2039 [04:49<01:07,  5.71it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  81%|███▏| 1656/2039 [04:49<01:06,  5.72it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  81%|███▎| 1659/2039 [04:49<01:06,  5.73it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1665/2039 [04:49<01:05,  5.74it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1668/2039 [04:49<01:04,  5.75it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1671/2039 [04:50<01:03,  5.76it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1674/2039 [04:50<01:03,  5.77it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1677/2039 [04:50<01:02,  5.78it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  82%|███▎| 1680/2039 [04:50<01:02,  5.78it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1683/2039 [04:50<01:01,  5.79it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1686/2039 [04:50<01:00,  5.80it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1689/2039 [04:50<01:00,  5.81it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1692/2039 [04:51<00:59,  5.81it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1695/2039 [04:51<00:59,  5.82it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1698/2039 [04:51<00:58,  5.83it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  83%|███▎| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▎| 1704/2039 [04:51<00:57,  5.85it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▎| 1707/2039 [04:51<00:56,  5.85it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▎| 1710/2039 [04:51<00:56,  5.86it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▎| 1713/2039 [04:51<00:55,  5.87it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▎| 1716/2039 [04:52<00:54,  5.88it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▎| 1719/2039 [04:52<00:54,  5.88it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  84%|███▍| 1722/2039 [04:52<00:53,  5.89it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1725/2039 [04:52<00:53,  5.90it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1728/2039 [04:52<00:52,  5.91it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1731/2039 [04:52<00:52,  5.91it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1734/2039 [04:52<00:51,  5.92it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1737/2039 [04:52<00:50,  5.93it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1740/2039 [04:53<00:50,  5.94it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  85%|███▍| 1743/2039 [04:53<00:49,  5.94it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  86%|███▍| 1746/2039 [04:53<00:49,  5.95it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  86%|███▍| 1749/2039 [04:53<00:48,  5.96it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  86%|███▍| 1752/2039 [04:53<00:48,  5.97it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  86%|███▍| 1755/2039 [04:53<00:47,  5.98it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  86%|███▍| 1758/2039 [04:53<00:46,  5.98it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  86%|███▍| 1761/2039 [04:53<00:46,  5.99it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1764/2039 [04:54<00:45,  6.00it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1767/2039 [04:54<00:45,  6.01it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1770/2039 [04:54<00:44,  6.01it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1773/2039 [04:54<00:44,  6.02it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1776/2039 [04:54<00:43,  6.03it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1779/2039 [04:54<00:43,  6.04it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  87%|███▍| 1782/2039 [04:54<00:42,  6.04it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1785/2039 [04:55<00:41,  6.05it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1788/2039 [04:55<00:41,  6.06it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1791/2039 [04:55<00:40,  6.07it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1794/2039 [04:55<00:40,  6.07it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1797/2039 [04:55<00:39,  6.08it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1800/2039 [04:55<00:39,  6.09it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  88%|███▌| 1803/2039 [04:55<00:38,  6.10it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  89%|███▌| 1806/2039 [04:55<00:38,  6.10it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  89%|███▌| 1809/2039 [04:56<00:37,  6.11it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  89%|███▌| 1812/2039 [04:56<00:37,  6.12it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  89%|███▌| 1815/2039 [04:56<00:36,  6.13it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  89%|███▌| 1818/2039 [04:56<00:36,  6.13it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  89%|███▌| 1821/2039 [04:56<00:35,  6.14it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  89%|███▌| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1827/2039 [04:56<00:34,  6.15it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1830/2039 [04:56<00:33,  6.16it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1833/2039 [04:57<00:33,  6.17it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1836/2039 [04:57<00:32,  6.18it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1839/2039 [04:57<00:32,  6.18it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1842/2039 [04:57<00:31,  6.19it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  90%|███▌| 1845/2039 [04:57<00:31,  6.20it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  91%|███▋| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  91%|███▋| 1851/2039 [04:57<00:30,  6.21it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  91%|███▋| 1854/2039 [04:58<00:29,  6.22it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  91%|███▋| 1857/2039 [04:58<00:29,  6.23it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  91%|███▋| 1860/2039 [04:58<00:28,  6.24it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  91%|███▋| 1863/2039 [04:58<00:28,  6.24it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1866/2039 [04:58<00:27,  6.25it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1869/2039 [04:58<00:27,  6.26it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1872/2039 [04:58<00:26,  6.27it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1875/2039 [04:58<00:26,  6.27it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1878/2039 [04:59<00:25,  6.28it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1881/2039 [04:59<00:25,  6.29it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  92%|███▋| 1884/2039 [04:59<00:24,  6.29it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1887/2039 [04:59<00:24,  6.30it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1890/2039 [04:59<00:23,  6.31it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1896/2039 [04:59<00:22,  6.32it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1899/2039 [04:59<00:22,  6.33it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1902/2039 [05:00<00:21,  6.34it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  93%|███▋| 1905/2039 [05:00<00:21,  6.35it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▋| 1908/2039 [05:00<00:20,  6.35it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▋| 1911/2039 [05:00<00:20,  6.36it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▊| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▊| 1917/2039 [05:00<00:19,  6.37it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▊| 1920/2039 [05:00<00:18,  6.38it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▊| 1923/2039 [05:00<00:18,  6.39it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  94%|███▊| 1926/2039 [05:01<00:17,  6.40it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1929/2039 [05:01<00:17,  6.40it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1932/2039 [05:01<00:16,  6.41it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1935/2039 [05:01<00:16,  6.42it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1938/2039 [05:01<00:15,  6.43it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1941/2039 [05:01<00:15,  6.43it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1944/2039 [05:01<00:14,  6.44it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  95%|███▊| 1947/2039 [05:02<00:14,  6.45it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  96%|███▊| 1950/2039 [05:02<00:13,  6.45it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  96%|███▊| 1953/2039 [05:02<00:13,  6.46it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  96%|███▊| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  96%|███▊| 1959/2039 [05:02<00:12,  6.48it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  96%|███▊| 1962/2039 [05:02<00:11,  6.48it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  96%|███▊| 1965/2039 [05:02<00:11,  6.49it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▊| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▊| 1971/2039 [05:03<00:10,  6.50it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▊| 1974/2039 [05:03<00:09,  6.51it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▉| 1977/2039 [05:03<00:09,  6.52it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▉| 1980/2039 [05:03<00:09,  6.53it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▉| 1983/2039 [05:03<00:08,  6.53it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  97%|███▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  98%|███▉| 1989/2039 [05:03<00:07,  6.55it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  98%|███▉| 1992/2039 [05:03<00:07,  6.55it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  98%|███▉| 1995/2039 [05:04<00:06,  6.56it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  98%|███▉| 1998/2039 [05:04<00:06,  6.57it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  98%|███▉| 2001/2039 [05:04<00:05,  6.57it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  98%|███▉| 2004/2039 [05:04<00:05,  6.58it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  98%|███▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2010/2039 [05:04<00:04,  6.60it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2013/2039 [05:04<00:03,  6.60it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2016/2039 [05:05<00:03,  6.61it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2019/2039 [05:05<00:03,  6.62it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2022/2039 [05:05<00:02,  6.62it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2025/2039 [05:05<00:02,  6.63it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3:  99%|███▉| 2028/2039 [05:05<00:01,  6.64it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3: 100%|███▉| 2031/2039 [05:05<00:01,  6.64it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3: 100%|███▉| 2034/2039 [05:05<00:00,  6.65it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3: 100%|███▉| 2037/2039 [05:05<00:00,  6.66it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.00534]\u001b[A\n",
      "Epoch 3: 100%|█████| 2039/2039 [05:06<00:00,  6.66it/s, loss=0.000936, v_num=logs, train_loss=0.00083, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  80%|███▏| 1632/2039 [04:47<01:11,  5.67it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|███▏| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  80%|███▏| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  80%|███▏| 1641/2039 [04:48<01:09,  5.70it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  81%|███▏| 1644/2039 [04:48<01:09,  5.71it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  81%|███▏| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  81%|███▏| 1650/2039 [04:48<01:07,  5.72it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  81%|███▏| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  81%|███▏| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  81%|███▎| 1659/2039 [04:48<01:06,  5.74it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  82%|███▎| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1686/2039 [04:49<01:00,  5.81it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  83%|███▎| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▎| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▎| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▎| 1710/2039 [04:51<00:55,  5.88it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▎| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▎| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▎| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  84%|███▍| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1734/2039 [04:52<00:51,  5.94it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  85%|███▍| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  86%|███▍| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  86%|███▍| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  86%|███▍| 1752/2039 [04:52<00:47,  5.98it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  86%|███▍| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  86%|███▍| 1758/2039 [04:53<00:46,  6.00it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  86%|███▍| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1776/2039 [04:53<00:43,  6.04it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1779/2039 [04:54<00:42,  6.05it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  87%|███▍| 1782/2039 [04:54<00:42,  6.06it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  88%|███▌| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  88%|███▌| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  88%|███▌| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  88%|███▌| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  88%|███▌| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  88%|███▌| 1800/2039 [04:54<00:39,  6.10it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  88%|███▌| 1803/2039 [04:55<00:38,  6.11it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1806/2039 [04:55<00:38,  6.12it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  89%|███▌| 1824/2039 [04:55<00:34,  6.16it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1827/2039 [04:56<00:34,  6.17it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1830/2039 [04:56<00:33,  6.18it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  90%|███▌| 1845/2039 [04:56<00:31,  6.21it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  91%|███▋| 1848/2039 [04:57<00:30,  6.22it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  91%|███▋| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  91%|███▋| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  91%|███▋| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  91%|███▋| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  91%|███▋| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1869/2039 [04:57<00:27,  6.27it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1872/2039 [04:58<00:26,  6.28it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  92%|███▋| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1890/2039 [04:58<00:23,  6.32it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1893/2039 [04:58<00:23,  6.33it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1896/2039 [04:59<00:22,  6.34it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1899/2039 [04:59<00:22,  6.35it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  93%|███▋| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▋| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▋| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▊| 1914/2039 [04:59<00:19,  6.38it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▊| 1917/2039 [04:59<00:19,  6.39it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▊| 1920/2039 [05:00<00:18,  6.40it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▊| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  94%|███▊| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1935/2039 [05:00<00:16,  6.43it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1938/2039 [05:00<00:15,  6.44it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1941/2039 [05:01<00:15,  6.45it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1944/2039 [05:01<00:14,  6.46it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  95%|███▊| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  96%|███▊| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  96%|███▊| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  96%|███▊| 1956/2039 [05:01<00:12,  6.48it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  96%|███▊| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  96%|███▊| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  96%|███▊| 1965/2039 [05:02<00:11,  6.51it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▊| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▊| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▊| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  97%|███▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  98%|███▉| 1989/2039 [05:03<00:07,  6.56it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  98%|███▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  98%|███▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  98%|███▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  98%|███▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  98%|███▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  98%|███▉| 2007/2039 [05:03<00:04,  6.60it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2010/2039 [05:03<00:04,  6.61it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2013/2039 [05:04<00:03,  6.62it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4:  99%|███▉| 2028/2039 [05:04<00:01,  6.65it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4: 100%|███▉| 2031/2039 [05:04<00:01,  6.66it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4: 100%|███▉| 2034/2039 [05:05<00:00,  6.67it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4: 100%|███▉| 2037/2039 [05:05<00:00,  6.68it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.0025]\u001b[A\n",
      "Epoch 4: 100%|███| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000599, v_num=logs, train_loss=0.000616, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  80%|██▍| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|██▍| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  80%|██▍| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  80%|██▍| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  81%|██▍| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  81%|██▍| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  81%|██▍| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  81%|██▍| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  81%|██▍| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  81%|██▍| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1671/2039 [04:48<01:03,  5.78it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  82%|██▍| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▍| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▍| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▍| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▍| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▍| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▍| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  83%|██▌| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  84%|██▌| 1722/2039 [04:51<00:53,  5.92it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  85%|██▌| 1743/2039 [04:52<00:49,  5.97it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  86%|██▌| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  86%|██▌| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  86%|██▌| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  86%|██▌| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  86%|██▌| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  86%|██▌| 1761/2039 [04:52<00:46,  6.01it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  87%|██▌| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  87%|██▌| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  87%|██▌| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  87%|██▌| 1773/2039 [04:53<00:44,  6.05it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  87%|██▌| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  87%|██▌| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  87%|██▌| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  88%|██▋| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  89%|██▋| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1833/2039 [04:55<00:33,  6.19it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  90%|██▋| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  91%|██▋| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  91%|██▋| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  91%|██▋| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  91%|██▋| 1857/2039 [04:56<00:29,  6.25it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  91%|██▋| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  91%|██▋| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▋| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▋| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▊| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▊| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▊| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▊| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  92%|██▊| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1902/2039 [04:58<00:21,  6.36it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  93%|██▊| 1905/2039 [04:59<00:21,  6.37it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1923/2039 [04:59<00:18,  6.41it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  94%|██▊| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1929/2039 [05:00<00:17,  6.43it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  95%|██▊| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  96%|██▊| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  96%|██▊| 1953/2039 [05:01<00:13,  6.49it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  96%|██▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  96%|██▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  96%|██▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  96%|██▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  97%|██▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  97%|██▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  97%|██▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  97%|██▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  97%|██▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  97%|██▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  97%|██▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  98%|██▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2019/2039 [05:03<00:03,  6.64it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2022/2039 [05:04<00:02,  6.65it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5:  99%|██▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5: 100%|██▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5: 100%|██▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5: 100%|██▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00175]\u001b[A\n",
      "Epoch 5: 100%|███| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000538, v_num=logs, train_loss=0.000543, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  80%|██▍| 1632/2039 [04:46<01:11,  5.70it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  80%|██▍| 1635/2039 [04:46<01:10,  5.71it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  80%|██▍| 1638/2039 [04:46<01:10,  5.71it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  80%|██▍| 1641/2039 [04:46<01:09,  5.72it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  81%|██▍| 1644/2039 [04:46<01:08,  5.73it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  81%|██▍| 1647/2039 [04:47<01:08,  5.74it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  81%|██▍| 1650/2039 [04:47<01:07,  5.75it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  81%|██▍| 1653/2039 [04:47<01:07,  5.75it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  81%|██▍| 1656/2039 [04:47<01:06,  5.76it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  81%|██▍| 1659/2039 [04:47<01:05,  5.77it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1662/2039 [04:47<01:05,  5.78it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1665/2039 [04:47<01:04,  5.78it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1668/2039 [04:47<01:04,  5.79it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1671/2039 [04:48<01:03,  5.80it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1674/2039 [04:48<01:02,  5.81it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1677/2039 [04:48<01:02,  5.82it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  82%|██▍| 1680/2039 [04:48<01:01,  5.82it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▍| 1683/2039 [04:48<01:01,  5.83it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▍| 1686/2039 [04:48<01:00,  5.84it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▍| 1689/2039 [04:48<00:59,  5.85it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▍| 1692/2039 [04:48<00:59,  5.85it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▍| 1695/2039 [04:49<00:58,  5.86it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▍| 1698/2039 [04:49<00:58,  5.87it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  83%|██▌| 1701/2039 [04:49<00:57,  5.88it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1704/2039 [04:49<00:56,  5.89it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1707/2039 [04:49<00:56,  5.89it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1710/2039 [04:49<00:55,  5.90it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1713/2039 [04:49<00:55,  5.91it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1716/2039 [04:50<00:54,  5.92it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1719/2039 [04:50<00:54,  5.92it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  84%|██▌| 1722/2039 [04:50<00:53,  5.93it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1725/2039 [04:50<00:52,  5.94it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1728/2039 [04:50<00:52,  5.95it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1731/2039 [04:50<00:51,  5.96it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1734/2039 [04:50<00:51,  5.96it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1737/2039 [04:50<00:50,  5.97it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1740/2039 [04:51<00:50,  5.98it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  85%|██▌| 1743/2039 [04:51<00:49,  5.99it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  86%|██▌| 1746/2039 [04:51<00:48,  5.99it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  86%|██▌| 1749/2039 [04:51<00:48,  6.00it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  86%|██▌| 1752/2039 [04:51<00:47,  6.01it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  86%|██▌| 1755/2039 [04:51<00:47,  6.02it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  86%|██▌| 1758/2039 [04:51<00:46,  6.02it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  86%|██▌| 1761/2039 [04:51<00:46,  6.03it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1764/2039 [04:52<00:45,  6.04it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1767/2039 [04:52<00:44,  6.05it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1770/2039 [04:52<00:44,  6.05it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1773/2039 [04:52<00:43,  6.06it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1776/2039 [04:52<00:43,  6.07it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1779/2039 [04:52<00:42,  6.08it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  87%|██▌| 1782/2039 [04:52<00:42,  6.08it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1785/2039 [04:52<00:41,  6.09it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1788/2039 [04:53<00:41,  6.10it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1791/2039 [04:53<00:40,  6.11it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1794/2039 [04:53<00:40,  6.11it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1797/2039 [04:53<00:39,  6.12it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1800/2039 [04:53<00:38,  6.13it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  88%|██▋| 1803/2039 [04:53<00:38,  6.14it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1806/2039 [04:53<00:37,  6.14it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1809/2039 [04:54<00:37,  6.15it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1812/2039 [04:54<00:36,  6.16it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1815/2039 [04:54<00:36,  6.17it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1818/2039 [04:54<00:35,  6.17it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1821/2039 [04:54<00:35,  6.18it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  89%|██▋| 1824/2039 [04:54<00:34,  6.19it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1827/2039 [04:54<00:34,  6.20it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1830/2039 [04:54<00:33,  6.20it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1833/2039 [04:55<00:33,  6.21it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1836/2039 [04:55<00:32,  6.22it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1839/2039 [04:55<00:32,  6.23it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1842/2039 [04:55<00:31,  6.23it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  90%|██▋| 1845/2039 [04:55<00:31,  6.24it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  91%|██▋| 1848/2039 [04:55<00:30,  6.25it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  91%|██▋| 1851/2039 [04:55<00:30,  6.26it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  91%|██▋| 1854/2039 [04:55<00:29,  6.26it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  91%|██▋| 1857/2039 [04:56<00:29,  6.27it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  91%|██▋| 1860/2039 [04:56<00:28,  6.28it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  91%|██▋| 1863/2039 [04:56<00:27,  6.29it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▋| 1866/2039 [04:56<00:27,  6.29it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▋| 1869/2039 [04:56<00:26,  6.30it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▊| 1872/2039 [04:56<00:26,  6.31it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▊| 1875/2039 [04:56<00:25,  6.32it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▊| 1878/2039 [04:56<00:25,  6.32it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▊| 1881/2039 [04:57<00:24,  6.33it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  92%|██▊| 1884/2039 [04:57<00:24,  6.34it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1887/2039 [04:57<00:23,  6.35it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1890/2039 [04:57<00:23,  6.35it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1893/2039 [04:57<00:22,  6.36it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1896/2039 [04:57<00:22,  6.37it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1899/2039 [04:57<00:21,  6.37it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1902/2039 [04:58<00:21,  6.38it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  93%|██▊| 1905/2039 [04:58<00:20,  6.39it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1908/2039 [04:58<00:20,  6.40it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1911/2039 [04:58<00:19,  6.40it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1914/2039 [04:58<00:19,  6.41it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1917/2039 [04:58<00:19,  6.42it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1920/2039 [04:58<00:18,  6.43it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1923/2039 [04:58<00:18,  6.43it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  94%|██▊| 1926/2039 [04:59<00:17,  6.44it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1929/2039 [04:59<00:17,  6.45it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1932/2039 [04:59<00:16,  6.45it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1935/2039 [04:59<00:16,  6.46it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1938/2039 [04:59<00:15,  6.47it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1941/2039 [04:59<00:15,  6.48it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1944/2039 [04:59<00:14,  6.48it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  95%|██▊| 1947/2039 [04:59<00:14,  6.49it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  96%|██▊| 1950/2039 [05:00<00:13,  6.50it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  96%|██▊| 1953/2039 [05:00<00:13,  6.50it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  96%|██▉| 1956/2039 [05:00<00:12,  6.51it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  96%|██▉| 1959/2039 [05:00<00:12,  6.52it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  96%|██▉| 1962/2039 [05:00<00:11,  6.53it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  96%|██▉| 1965/2039 [05:00<00:11,  6.53it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1968/2039 [05:00<00:10,  6.54it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1971/2039 [05:01<00:10,  6.55it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1974/2039 [05:01<00:09,  6.56it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1977/2039 [05:01<00:09,  6.56it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1980/2039 [05:01<00:08,  6.57it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1983/2039 [05:01<00:08,  6.58it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  97%|██▉| 1986/2039 [05:01<00:08,  6.58it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 1989/2039 [05:01<00:07,  6.59it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 1992/2039 [05:01<00:07,  6.60it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 1995/2039 [05:02<00:06,  6.61it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 1998/2039 [05:02<00:06,  6.61it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 2001/2039 [05:02<00:05,  6.62it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 2004/2039 [05:02<00:05,  6.63it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  98%|██▉| 2007/2039 [05:02<00:04,  6.63it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2010/2039 [05:02<00:04,  6.64it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2013/2039 [05:02<00:03,  6.65it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2016/2039 [05:02<00:03,  6.65it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2019/2039 [05:03<00:03,  6.66it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2022/2039 [05:03<00:02,  6.67it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2025/2039 [05:03<00:02,  6.68it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6:  99%|██▉| 2028/2039 [05:03<00:01,  6.68it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6: 100%|██▉| 2031/2039 [05:03<00:01,  6.69it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6: 100%|██▉| 2034/2039 [05:03<00:00,  6.70it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6: 100%|██▉| 2037/2039 [05:03<00:00,  6.70it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00133]\u001b[A\n",
      "Epoch 6: 100%|███| 2039/2039 [05:03<00:00,  6.71it/s, loss=0.000522, v_num=logs, train_loss=0.000643, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  80%|██▍| 1632/2039 [04:46<01:11,  5.70it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  80%|██▍| 1635/2039 [04:46<01:10,  5.71it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  80%|██▍| 1638/2039 [04:46<01:10,  5.71it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  80%|██▍| 1641/2039 [04:46<01:09,  5.72it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  81%|██▍| 1644/2039 [04:46<01:08,  5.73it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  81%|██▍| 1647/2039 [04:47<01:08,  5.74it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  81%|██▍| 1650/2039 [04:47<01:07,  5.75it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  81%|██▍| 1653/2039 [04:47<01:07,  5.75it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  81%|██▍| 1656/2039 [04:47<01:06,  5.76it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  81%|██▍| 1659/2039 [04:47<01:05,  5.77it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1662/2039 [04:47<01:05,  5.78it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1665/2039 [04:47<01:04,  5.78it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1668/2039 [04:47<01:04,  5.79it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1671/2039 [04:48<01:03,  5.80it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1674/2039 [04:48<01:02,  5.81it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1677/2039 [04:48<01:02,  5.82it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  82%|██▍| 1680/2039 [04:48<01:01,  5.82it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▍| 1683/2039 [04:48<01:01,  5.83it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▍| 1686/2039 [04:48<01:00,  5.84it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▍| 1689/2039 [04:48<00:59,  5.85it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▍| 1692/2039 [04:49<00:59,  5.85it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▍| 1695/2039 [04:49<00:58,  5.86it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▍| 1698/2039 [04:49<00:58,  5.87it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  83%|██▌| 1701/2039 [04:49<00:57,  5.88it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1704/2039 [04:49<00:56,  5.89it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1707/2039 [04:49<00:56,  5.89it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1710/2039 [04:49<00:55,  5.90it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1713/2039 [04:49<00:55,  5.91it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1716/2039 [04:50<00:54,  5.92it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1719/2039 [04:50<00:54,  5.92it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  84%|██▌| 1722/2039 [04:50<00:53,  5.93it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  85%|██▌| 1725/2039 [04:50<00:52,  5.94it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  85%|██▌| 1728/2039 [04:50<00:52,  5.95it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  85%|██▌| 1731/2039 [04:50<00:51,  5.95it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  85%|██▌| 1734/2039 [04:50<00:51,  5.96it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  85%|██▌| 1737/2039 [04:50<00:50,  5.97it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  85%|██▌| 1740/2039 [04:51<00:50,  5.98it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  85%|██▌| 1743/2039 [04:51<00:49,  5.99it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  86%|██▌| 1746/2039 [04:51<00:48,  5.99it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  86%|██▌| 1749/2039 [04:51<00:48,  6.00it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  86%|██▌| 1752/2039 [04:51<00:47,  6.01it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  86%|██▌| 1755/2039 [04:51<00:47,  6.02it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  86%|██▌| 1758/2039 [04:51<00:46,  6.02it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  86%|██▌| 1761/2039 [04:51<00:46,  6.03it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1764/2039 [04:52<00:45,  6.04it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1767/2039 [04:52<00:44,  6.05it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1770/2039 [04:52<00:44,  6.05it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1773/2039 [04:52<00:43,  6.06it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1776/2039 [04:52<00:43,  6.07it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1779/2039 [04:52<00:42,  6.08it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  87%|██▌| 1782/2039 [04:52<00:42,  6.08it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1785/2039 [04:53<00:41,  6.09it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1788/2039 [04:53<00:41,  6.10it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1791/2039 [04:53<00:40,  6.11it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1794/2039 [04:53<00:40,  6.11it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1797/2039 [04:53<00:39,  6.12it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1800/2039 [04:53<00:38,  6.13it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  88%|██▋| 1803/2039 [04:53<00:38,  6.14it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1806/2039 [04:53<00:37,  6.14it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1809/2039 [04:54<00:37,  6.15it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1812/2039 [04:54<00:36,  6.16it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1815/2039 [04:54<00:36,  6.17it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1818/2039 [04:54<00:35,  6.17it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1821/2039 [04:54<00:35,  6.18it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  89%|██▋| 1824/2039 [04:54<00:34,  6.19it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1827/2039 [04:54<00:34,  6.20it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1830/2039 [04:54<00:33,  6.20it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1833/2039 [04:55<00:33,  6.21it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1836/2039 [04:55<00:32,  6.22it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1839/2039 [04:55<00:32,  6.23it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1842/2039 [04:55<00:31,  6.23it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  90%|██▋| 1845/2039 [04:55<00:31,  6.24it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  91%|██▋| 1848/2039 [04:55<00:30,  6.25it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  91%|██▋| 1851/2039 [04:55<00:30,  6.26it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  91%|██▋| 1854/2039 [04:55<00:29,  6.26it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  91%|██▋| 1857/2039 [04:56<00:29,  6.27it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  91%|██▋| 1860/2039 [04:56<00:28,  6.28it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  91%|██▋| 1863/2039 [04:56<00:27,  6.29it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▋| 1866/2039 [04:56<00:27,  6.29it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▋| 1869/2039 [04:56<00:26,  6.30it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▊| 1872/2039 [04:56<00:26,  6.31it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▊| 1875/2039 [04:56<00:25,  6.32it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▊| 1878/2039 [04:57<00:25,  6.32it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▊| 1881/2039 [04:57<00:24,  6.33it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  92%|██▊| 1884/2039 [04:57<00:24,  6.34it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1887/2039 [04:57<00:23,  6.34it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1890/2039 [04:57<00:23,  6.35it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1893/2039 [04:57<00:22,  6.36it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1896/2039 [04:57<00:22,  6.37it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1899/2039 [04:57<00:21,  6.37it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1902/2039 [04:58<00:21,  6.38it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  93%|██▊| 1905/2039 [04:58<00:20,  6.39it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1908/2039 [04:58<00:20,  6.40it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1911/2039 [04:58<00:19,  6.40it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1914/2039 [04:58<00:19,  6.41it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1917/2039 [04:58<00:19,  6.42it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1920/2039 [04:58<00:18,  6.43it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1923/2039 [04:58<00:18,  6.43it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  94%|██▊| 1926/2039 [04:59<00:17,  6.44it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  95%|██▊| 1929/2039 [04:59<00:17,  6.45it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  95%|██▊| 1932/2039 [04:59<00:16,  6.45it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  95%|██▊| 1935/2039 [04:59<00:16,  6.46it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  95%|██▊| 1938/2039 [04:59<00:15,  6.47it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  95%|██▊| 1941/2039 [04:59<00:15,  6.48it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  95%|██▊| 1944/2039 [04:59<00:14,  6.48it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  95%|██▊| 1947/2039 [04:59<00:14,  6.49it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  96%|██▊| 1950/2039 [05:00<00:13,  6.50it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  96%|██▊| 1953/2039 [05:00<00:13,  6.50it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  96%|██▉| 1956/2039 [05:00<00:12,  6.51it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  96%|██▉| 1959/2039 [05:00<00:12,  6.52it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  96%|██▉| 1962/2039 [05:00<00:11,  6.53it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  96%|██▉| 1965/2039 [05:00<00:11,  6.53it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1968/2039 [05:00<00:10,  6.54it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1971/2039 [05:01<00:10,  6.55it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1974/2039 [05:01<00:09,  6.55it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1977/2039 [05:01<00:09,  6.56it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1980/2039 [05:01<00:08,  6.57it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1983/2039 [05:01<00:08,  6.58it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  97%|██▉| 1986/2039 [05:01<00:08,  6.58it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 1989/2039 [05:01<00:07,  6.59it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 1992/2039 [05:01<00:07,  6.60it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 1995/2039 [05:02<00:06,  6.60it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 1998/2039 [05:02<00:06,  6.61it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 2001/2039 [05:02<00:05,  6.62it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 2004/2039 [05:02<00:05,  6.63it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  98%|██▉| 2007/2039 [05:02<00:04,  6.63it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2010/2039 [05:02<00:04,  6.64it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2013/2039 [05:02<00:03,  6.65it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2016/2039 [05:02<00:03,  6.65it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2019/2039 [05:03<00:03,  6.66it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2022/2039 [05:03<00:02,  6.67it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2025/2039 [05:03<00:02,  6.68it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7:  99%|██▉| 2028/2039 [05:03<00:01,  6.68it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7: 100%|██▉| 2031/2039 [05:03<00:01,  6.69it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7: 100%|██▉| 2034/2039 [05:03<00:00,  6.70it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7: 100%|██▉| 2037/2039 [05:03<00:00,  6.70it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00119]\u001b[A\n",
      "Epoch 7: 100%|███| 2039/2039 [05:03<00:00,  6.71it/s, loss=0.000447, v_num=logs, train_loss=0.000398, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  80%|██▍| 1632/2039 [04:44<01:10,  5.74it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  80%|██▍| 1635/2039 [04:44<01:10,  5.75it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  80%|██▍| 1638/2039 [04:44<01:09,  5.76it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  80%|██▍| 1641/2039 [04:44<01:09,  5.77it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  81%|██▍| 1644/2039 [04:44<01:08,  5.77it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  81%|██▍| 1647/2039 [04:44<01:07,  5.78it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  81%|██▍| 1650/2039 [04:44<01:07,  5.79it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  81%|██▍| 1653/2039 [04:45<01:06,  5.80it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  81%|██▍| 1656/2039 [04:45<01:05,  5.81it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  81%|██▍| 1659/2039 [04:45<01:05,  5.81it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1662/2039 [04:45<01:04,  5.82it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1665/2039 [04:45<01:04,  5.83it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1668/2039 [04:45<01:03,  5.84it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1671/2039 [04:45<01:02,  5.84it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1674/2039 [04:46<01:02,  5.85it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1677/2039 [04:46<01:01,  5.86it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  82%|██▍| 1680/2039 [04:46<01:01,  5.87it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▍| 1683/2039 [04:46<01:00,  5.88it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▍| 1686/2039 [04:46<00:59,  5.88it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▍| 1689/2039 [04:46<00:59,  5.89it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▍| 1692/2039 [04:46<00:58,  5.90it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▍| 1695/2039 [04:46<00:58,  5.91it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▍| 1698/2039 [04:47<00:57,  5.91it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  83%|██▌| 1701/2039 [04:47<00:57,  5.92it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  84%|██▌| 1704/2039 [04:47<00:56,  5.93it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  84%|██▌| 1707/2039 [04:47<00:55,  5.94it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  84%|██▌| 1710/2039 [04:47<00:55,  5.95it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  84%|██▌| 1713/2039 [04:47<00:54,  5.95it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  84%|██▌| 1716/2039 [04:47<00:54,  5.96it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  84%|██▌| 1719/2039 [04:47<00:53,  5.97it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  84%|██▌| 1722/2039 [04:48<00:53,  5.98it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1725/2039 [04:48<00:52,  5.98it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1728/2039 [04:48<00:51,  5.99it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1731/2039 [04:48<00:51,  6.00it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1734/2039 [04:48<00:50,  6.01it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1737/2039 [04:48<00:50,  6.01it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1740/2039 [04:48<00:49,  6.02it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  85%|██▌| 1743/2039 [04:49<00:49,  6.03it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  86%|██▌| 1746/2039 [04:49<00:48,  6.04it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  86%|██▌| 1749/2039 [04:49<00:47,  6.05it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  86%|██▌| 1752/2039 [04:49<00:47,  6.05it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  86%|██▌| 1755/2039 [04:49<00:46,  6.06it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  86%|██▌| 1758/2039 [04:49<00:46,  6.07it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  86%|██▌| 1761/2039 [04:49<00:45,  6.08it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1764/2039 [04:49<00:45,  6.08it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1767/2039 [04:50<00:44,  6.09it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1770/2039 [04:50<00:44,  6.10it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1773/2039 [04:50<00:43,  6.11it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1776/2039 [04:50<00:43,  6.11it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1779/2039 [04:50<00:42,  6.12it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  87%|██▌| 1782/2039 [04:50<00:41,  6.13it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1785/2039 [04:50<00:41,  6.14it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1788/2039 [04:51<00:40,  6.14it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1791/2039 [04:51<00:40,  6.15it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1794/2039 [04:51<00:39,  6.16it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1797/2039 [04:51<00:39,  6.17it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1800/2039 [04:51<00:38,  6.17it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  88%|██▋| 1803/2039 [04:51<00:38,  6.18it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1806/2039 [04:51<00:37,  6.19it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1809/2039 [04:51<00:37,  6.20it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1812/2039 [04:52<00:36,  6.20it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1815/2039 [04:52<00:36,  6.21it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1818/2039 [04:52<00:35,  6.22it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1821/2039 [04:52<00:35,  6.23it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  89%|██▋| 1824/2039 [04:52<00:34,  6.23it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1827/2039 [04:52<00:33,  6.24it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1830/2039 [04:52<00:33,  6.25it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1833/2039 [04:52<00:32,  6.26it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1836/2039 [04:53<00:32,  6.26it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1839/2039 [04:53<00:31,  6.27it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1842/2039 [04:53<00:31,  6.28it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  90%|██▋| 1845/2039 [04:53<00:30,  6.29it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  91%|██▋| 1848/2039 [04:53<00:30,  6.29it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  91%|██▋| 1851/2039 [04:53<00:29,  6.30it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  91%|██▋| 1854/2039 [04:53<00:29,  6.31it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  91%|██▋| 1857/2039 [04:54<00:28,  6.32it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  91%|██▋| 1860/2039 [04:54<00:28,  6.32it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  91%|██▋| 1863/2039 [04:54<00:27,  6.33it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▋| 1866/2039 [04:54<00:27,  6.34it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▋| 1869/2039 [04:54<00:26,  6.34it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▊| 1872/2039 [04:54<00:26,  6.35it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▊| 1875/2039 [04:54<00:25,  6.36it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▊| 1878/2039 [04:54<00:25,  6.37it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▊| 1881/2039 [04:55<00:24,  6.37it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  92%|██▊| 1884/2039 [04:55<00:24,  6.38it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1887/2039 [04:55<00:23,  6.39it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1890/2039 [04:55<00:23,  6.40it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1893/2039 [04:55<00:22,  6.40it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1896/2039 [04:55<00:22,  6.41it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1899/2039 [04:55<00:21,  6.42it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1902/2039 [04:55<00:21,  6.43it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  93%|██▊| 1905/2039 [04:56<00:20,  6.43it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  94%|██▊| 1908/2039 [04:56<00:20,  6.44it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  94%|██▊| 1911/2039 [04:56<00:19,  6.45it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  94%|██▊| 1914/2039 [04:56<00:19,  6.45it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  94%|██▊| 1917/2039 [04:56<00:18,  6.46it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  94%|██▊| 1920/2039 [04:56<00:18,  6.47it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  94%|██▊| 1923/2039 [04:56<00:17,  6.48it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  94%|██▊| 1926/2039 [04:57<00:17,  6.48it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1929/2039 [04:57<00:16,  6.49it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1932/2039 [04:57<00:16,  6.50it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1935/2039 [04:57<00:15,  6.51it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1938/2039 [04:57<00:15,  6.51it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1941/2039 [04:57<00:15,  6.52it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1944/2039 [04:57<00:14,  6.53it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  95%|██▊| 1947/2039 [04:57<00:14,  6.53it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  96%|██▊| 1950/2039 [04:58<00:13,  6.54it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  96%|██▊| 1953/2039 [04:58<00:13,  6.55it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  96%|██▉| 1956/2039 [04:58<00:12,  6.56it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  96%|██▉| 1959/2039 [04:58<00:12,  6.56it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  96%|██▉| 1962/2039 [04:58<00:11,  6.57it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  96%|██▉| 1965/2039 [04:58<00:11,  6.58it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1968/2039 [04:58<00:10,  6.58it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1971/2039 [04:58<00:10,  6.59it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1974/2039 [04:59<00:09,  6.60it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1977/2039 [04:59<00:09,  6.61it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1980/2039 [04:59<00:08,  6.61it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1983/2039 [04:59<00:08,  6.62it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  97%|██▉| 1986/2039 [04:59<00:07,  6.63it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 1989/2039 [04:59<00:07,  6.64it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 1992/2039 [04:59<00:07,  6.64it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 1995/2039 [05:00<00:06,  6.65it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 1998/2039 [05:00<00:06,  6.66it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 2001/2039 [05:00<00:05,  6.66it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 2004/2039 [05:00<00:05,  6.67it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  98%|██▉| 2007/2039 [05:00<00:04,  6.68it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2010/2039 [05:00<00:04,  6.68it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2013/2039 [05:00<00:03,  6.69it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2016/2039 [05:00<00:03,  6.70it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2019/2039 [05:01<00:02,  6.71it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2022/2039 [05:01<00:02,  6.71it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2025/2039 [05:01<00:02,  6.72it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8:  99%|██▉| 2028/2039 [05:01<00:01,  6.73it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8: 100%|██▉| 2031/2039 [05:01<00:01,  6.73it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8: 100%|██▉| 2034/2039 [05:01<00:00,  6.74it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8: 100%|██▉| 2037/2039 [05:01<00:00,  6.75it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.00102]\u001b[A\n",
      "Epoch 8: 100%|██| 2039/2039 [05:01<00:00,  6.75it/s, loss=0.000455, v_num=logs, train_loss=0.000354, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  80%|█▌| 1632/2039 [04:49<01:12,  5.64it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  80%|█▌| 1635/2039 [04:49<01:11,  5.65it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  80%|█▌| 1638/2039 [04:49<01:10,  5.65it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  80%|█▌| 1641/2039 [04:49<01:10,  5.66it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  81%|█▌| 1644/2039 [04:49<01:09,  5.67it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  81%|█▌| 1647/2039 [04:50<01:09,  5.68it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  81%|█▌| 1650/2039 [04:50<01:08,  5.68it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  81%|█▌| 1653/2039 [04:50<01:07,  5.69it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  81%|█▌| 1656/2039 [04:50<01:07,  5.70it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  81%|█▋| 1659/2039 [04:50<01:06,  5.71it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1662/2039 [04:50<01:05,  5.72it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1665/2039 [04:50<01:05,  5.72it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1668/2039 [04:51<01:04,  5.73it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1671/2039 [04:51<01:04,  5.74it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1674/2039 [04:51<01:03,  5.75it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1677/2039 [04:51<01:02,  5.75it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  82%|█▋| 1680/2039 [04:51<01:02,  5.76it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  83%|█▋| 1683/2039 [04:51<01:01,  5.77it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  83%|█▋| 1686/2039 [04:51<01:01,  5.78it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  83%|█▋| 1689/2039 [04:51<01:00,  5.79it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  83%|█▋| 1692/2039 [04:52<00:59,  5.79it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  83%|█▋| 1695/2039 [04:52<00:59,  5.80it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  83%|█▋| 1698/2039 [04:52<00:58,  5.81it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  83%|█▋| 1701/2039 [04:52<00:58,  5.82it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1704/2039 [04:52<00:57,  5.82it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1707/2039 [04:52<00:56,  5.83it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1710/2039 [04:52<00:56,  5.84it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1713/2039 [04:52<00:55,  5.85it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1716/2039 [04:53<00:55,  5.85it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1719/2039 [04:53<00:54,  5.86it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  84%|█▋| 1722/2039 [04:53<00:54,  5.87it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1725/2039 [04:53<00:53,  5.88it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1728/2039 [04:53<00:52,  5.89it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1731/2039 [04:53<00:52,  5.89it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1734/2039 [04:53<00:51,  5.90it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1737/2039 [04:54<00:51,  5.91it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1740/2039 [04:54<00:50,  5.92it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  85%|█▋| 1743/2039 [04:54<00:49,  5.92it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  86%|█▋| 1746/2039 [04:54<00:49,  5.93it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  86%|█▋| 1749/2039 [04:54<00:48,  5.94it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  86%|█▋| 1752/2039 [04:54<00:48,  5.95it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  86%|█▋| 1755/2039 [04:54<00:47,  5.95it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  86%|█▋| 1758/2039 [04:54<00:47,  5.96it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  86%|█▋| 1761/2039 [04:55<00:46,  5.97it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1764/2039 [04:55<00:46,  5.98it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1767/2039 [04:55<00:45,  5.98it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1770/2039 [04:55<00:44,  5.99it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1773/2039 [04:55<00:44,  6.00it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1776/2039 [04:55<00:43,  6.01it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1779/2039 [04:55<00:43,  6.01it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  87%|█▋| 1782/2039 [04:55<00:42,  6.02it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1785/2039 [04:56<00:42,  6.03it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1788/2039 [04:56<00:41,  6.04it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1791/2039 [04:56<00:41,  6.04it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1794/2039 [04:56<00:40,  6.05it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1797/2039 [04:56<00:39,  6.06it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1800/2039 [04:56<00:39,  6.07it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  88%|█▊| 1803/2039 [04:56<00:38,  6.07it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1806/2039 [04:57<00:38,  6.08it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1809/2039 [04:57<00:37,  6.09it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1812/2039 [04:57<00:37,  6.10it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1815/2039 [04:57<00:36,  6.10it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1818/2039 [04:57<00:36,  6.11it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1821/2039 [04:57<00:35,  6.12it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  89%|█▊| 1824/2039 [04:57<00:35,  6.13it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1827/2039 [04:57<00:34,  6.13it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1830/2039 [04:58<00:34,  6.14it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1833/2039 [04:58<00:33,  6.15it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1836/2039 [04:58<00:32,  6.15it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1839/2039 [04:58<00:32,  6.16it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1842/2039 [04:58<00:31,  6.17it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  90%|█▊| 1845/2039 [04:58<00:31,  6.18it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  91%|█▊| 1848/2039 [04:58<00:30,  6.18it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  91%|█▊| 1851/2039 [04:58<00:30,  6.19it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  91%|█▊| 1854/2039 [04:59<00:29,  6.20it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  91%|█▊| 1857/2039 [04:59<00:29,  6.21it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  91%|█▊| 1860/2039 [04:59<00:28,  6.21it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  91%|█▊| 1863/2039 [04:59<00:28,  6.22it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1866/2039 [04:59<00:27,  6.23it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1869/2039 [04:59<00:27,  6.24it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1872/2039 [04:59<00:26,  6.24it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1875/2039 [04:59<00:26,  6.25it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1878/2039 [05:00<00:25,  6.26it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1881/2039 [05:00<00:25,  6.27it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  92%|█▊| 1884/2039 [05:00<00:24,  6.27it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  93%|█▊| 1887/2039 [05:00<00:24,  6.28it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  93%|█▊| 1890/2039 [05:00<00:23,  6.29it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  93%|█▊| 1893/2039 [05:00<00:23,  6.29it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  93%|█▊| 1896/2039 [05:00<00:22,  6.30it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  93%|█▊| 1899/2039 [05:01<00:22,  6.31it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  93%|█▊| 1902/2039 [05:01<00:21,  6.32it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  93%|█▊| 1905/2039 [05:01<00:21,  6.32it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▊| 1908/2039 [05:01<00:20,  6.33it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▊| 1911/2039 [05:01<00:20,  6.34it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▉| 1914/2039 [05:01<00:19,  6.34it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▉| 1917/2039 [05:01<00:19,  6.35it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▉| 1920/2039 [05:01<00:18,  6.36it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▉| 1923/2039 [05:02<00:18,  6.37it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  94%|█▉| 1926/2039 [05:02<00:17,  6.37it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1929/2039 [05:02<00:17,  6.38it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1932/2039 [05:02<00:16,  6.39it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1935/2039 [05:02<00:16,  6.40it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1938/2039 [05:02<00:15,  6.40it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1941/2039 [05:02<00:15,  6.41it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1944/2039 [05:02<00:14,  6.42it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  95%|█▉| 1947/2039 [05:03<00:14,  6.42it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  96%|█▉| 1950/2039 [05:03<00:13,  6.43it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  96%|█▉| 1953/2039 [05:03<00:13,  6.44it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  96%|█▉| 1956/2039 [05:03<00:12,  6.45it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  96%|█▉| 1959/2039 [05:03<00:12,  6.45it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  96%|█▉| 1962/2039 [05:03<00:11,  6.46it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  96%|█▉| 1965/2039 [05:03<00:11,  6.47it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1968/2039 [05:04<00:10,  6.47it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1971/2039 [05:04<00:10,  6.48it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1974/2039 [05:04<00:10,  6.49it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1977/2039 [05:04<00:09,  6.49it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1980/2039 [05:04<00:09,  6.50it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1983/2039 [05:04<00:08,  6.51it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  97%|█▉| 1986/2039 [05:04<00:08,  6.52it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 1989/2039 [05:04<00:07,  6.52it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 1992/2039 [05:05<00:07,  6.53it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 1995/2039 [05:05<00:06,  6.54it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 1998/2039 [05:05<00:06,  6.54it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 2001/2039 [05:05<00:05,  6.55it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 2004/2039 [05:05<00:05,  6.56it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  98%|█▉| 2007/2039 [05:05<00:04,  6.57it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2010/2039 [05:05<00:04,  6.57it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2013/2039 [05:05<00:03,  6.58it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2016/2039 [05:06<00:03,  6.59it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2019/2039 [05:06<00:03,  6.59it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2022/2039 [05:06<00:02,  6.60it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2025/2039 [05:06<00:02,  6.61it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9:  99%|█▉| 2028/2039 [05:06<00:01,  6.61it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9: 100%|█▉| 2031/2039 [05:06<00:01,  6.62it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9: 100%|█▉| 2034/2039 [05:06<00:00,  6.63it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9: 100%|█▉| 2037/2039 [05:06<00:00,  6.64it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000978]\u001b[A\n",
      "Epoch 9: 100%|██| 2039/2039 [05:07<00:00,  6.64it/s, loss=0.000439, v_num=logs, train_loss=0.000356, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  80%|█▌| 1632/2039 [04:46<01:11,  5.70it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  80%|█▌| 1635/2039 [04:46<01:10,  5.70it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  80%|█▌| 1638/2039 [04:46<01:10,  5.71it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  80%|█▌| 1641/2039 [04:46<01:09,  5.72it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  81%|█▌| 1644/2039 [04:47<01:08,  5.73it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  81%|█▌| 1647/2039 [04:47<01:08,  5.73it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  81%|█▌| 1650/2039 [04:47<01:07,  5.74it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  81%|█▌| 1653/2039 [04:47<01:07,  5.75it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  81%|█▌| 1656/2039 [04:47<01:06,  5.76it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  81%|█▋| 1659/2039 [04:47<01:05,  5.77it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1662/2039 [04:47<01:05,  5.77it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1665/2039 [04:47<01:04,  5.78it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1668/2039 [04:48<01:04,  5.79it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1671/2039 [04:48<01:03,  5.80it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1674/2039 [04:48<01:02,  5.81it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1677/2039 [04:48<01:02,  5.81it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  82%|█▋| 1680/2039 [04:48<01:01,  5.82it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  83%|█▋| 1683/2039 [04:48<01:01,  5.83it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  83%|█▋| 1686/2039 [04:48<01:00,  5.84it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  83%|█▋| 1689/2039 [04:49<00:59,  5.84it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  83%|█▋| 1692/2039 [04:49<00:59,  5.85it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  83%|█▋| 1695/2039 [04:49<00:58,  5.86it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  83%|█▋| 1698/2039 [04:49<00:58,  5.87it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  83%|█▋| 1701/2039 [04:49<00:57,  5.88it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1704/2039 [04:49<00:56,  5.88it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1707/2039 [04:49<00:56,  5.89it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1710/2039 [04:49<00:55,  5.90it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1713/2039 [04:50<00:55,  5.91it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1716/2039 [04:50<00:54,  5.91it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1719/2039 [04:50<00:54,  5.92it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  84%|█▋| 1722/2039 [04:50<00:53,  5.93it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1725/2039 [04:50<00:52,  5.94it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1728/2039 [04:50<00:52,  5.94it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1731/2039 [04:50<00:51,  5.95it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1734/2039 [04:50<00:51,  5.96it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1737/2039 [04:51<00:50,  5.97it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1740/2039 [04:51<00:50,  5.98it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  85%|█▋| 1743/2039 [04:51<00:49,  5.98it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  86%|█▋| 1746/2039 [04:51<00:48,  5.99it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  86%|█▋| 1749/2039 [04:51<00:48,  6.00it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  86%|█▋| 1752/2039 [04:51<00:47,  6.01it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  86%|█▋| 1755/2039 [04:51<00:47,  6.01it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  86%|█▋| 1758/2039 [04:51<00:46,  6.02it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  86%|█▋| 1761/2039 [04:52<00:46,  6.03it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1764/2039 [04:52<00:45,  6.04it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1767/2039 [04:52<00:45,  6.04it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1770/2039 [04:52<00:44,  6.05it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1773/2039 [04:52<00:43,  6.06it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1776/2039 [04:52<00:43,  6.07it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1779/2039 [04:52<00:42,  6.07it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  87%|█▋| 1782/2039 [04:53<00:42,  6.08it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1785/2039 [04:53<00:41,  6.09it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1788/2039 [04:53<00:41,  6.10it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1791/2039 [04:53<00:40,  6.10it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1794/2039 [04:53<00:40,  6.11it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1797/2039 [04:53<00:39,  6.12it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1800/2039 [04:53<00:39,  6.13it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  88%|█▊| 1803/2039 [04:53<00:38,  6.13it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1806/2039 [04:54<00:37,  6.14it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1809/2039 [04:54<00:37,  6.15it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1812/2039 [04:54<00:36,  6.16it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1815/2039 [04:54<00:36,  6.16it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1818/2039 [04:54<00:35,  6.17it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1821/2039 [04:54<00:35,  6.18it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  89%|█▊| 1824/2039 [04:54<00:34,  6.19it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1827/2039 [04:54<00:34,  6.19it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1830/2039 [04:55<00:33,  6.20it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1833/2039 [04:55<00:33,  6.21it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1836/2039 [04:55<00:32,  6.22it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1839/2039 [04:55<00:32,  6.22it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1842/2039 [04:55<00:31,  6.23it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  90%|█▊| 1845/2039 [04:55<00:31,  6.24it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  91%|█▊| 1848/2039 [04:55<00:30,  6.25it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  91%|█▊| 1851/2039 [04:55<00:30,  6.25it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  91%|█▊| 1854/2039 [04:56<00:29,  6.26it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  91%|█▊| 1857/2039 [04:56<00:29,  6.27it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  91%|█▊| 1860/2039 [04:56<00:28,  6.28it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  91%|█▊| 1863/2039 [04:56<00:28,  6.28it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  92%|█▊| 1866/2039 [04:56<00:27,  6.29it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  92%|█▊| 1869/2039 [04:56<00:26,  6.30it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  92%|█▊| 1872/2039 [04:56<00:26,  6.31it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  92%|█▊| 1875/2039 [04:57<00:25,  6.31it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  92%|█▊| 1878/2039 [04:57<00:25,  6.32it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  92%|█▊| 1881/2039 [04:57<00:24,  6.33it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  92%|█▊| 1884/2039 [04:57<00:24,  6.33it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1887/2039 [04:57<00:23,  6.34it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1890/2039 [04:57<00:23,  6.35it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1893/2039 [04:57<00:22,  6.36it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1896/2039 [04:57<00:22,  6.36it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1899/2039 [04:58<00:21,  6.37it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1902/2039 [04:58<00:21,  6.38it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  93%|█▊| 1905/2039 [04:58<00:20,  6.39it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▊| 1908/2039 [04:58<00:20,  6.39it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▊| 1911/2039 [04:58<00:19,  6.40it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▉| 1914/2039 [04:58<00:19,  6.41it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▉| 1917/2039 [04:58<00:19,  6.42it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▉| 1920/2039 [04:58<00:18,  6.42it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▉| 1923/2039 [04:59<00:18,  6.43it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  94%|█▉| 1926/2039 [04:59<00:17,  6.44it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1929/2039 [04:59<00:17,  6.44it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1932/2039 [04:59<00:16,  6.45it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1935/2039 [04:59<00:16,  6.46it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1938/2039 [04:59<00:15,  6.47it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1941/2039 [04:59<00:15,  6.47it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1944/2039 [04:59<00:14,  6.48it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  95%|█▉| 1947/2039 [05:00<00:14,  6.49it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  96%|█▉| 1950/2039 [05:00<00:13,  6.49it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  96%|█▉| 1953/2039 [05:00<00:13,  6.50it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  96%|█▉| 1956/2039 [05:00<00:12,  6.51it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  96%|█▉| 1959/2039 [05:00<00:12,  6.52it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  96%|█▉| 1962/2039 [05:00<00:11,  6.52it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  96%|█▉| 1965/2039 [05:00<00:11,  6.53it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1968/2039 [05:01<00:10,  6.54it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1971/2039 [05:01<00:10,  6.55it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1974/2039 [05:01<00:09,  6.55it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1977/2039 [05:01<00:09,  6.56it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1980/2039 [05:01<00:08,  6.57it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1983/2039 [05:01<00:08,  6.57it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  97%|█▉| 1986/2039 [05:01<00:08,  6.58it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 1989/2039 [05:01<00:07,  6.59it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 1992/2039 [05:02<00:07,  6.59it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 1995/2039 [05:02<00:06,  6.60it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 1998/2039 [05:02<00:06,  6.61it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 2001/2039 [05:02<00:05,  6.62it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 2004/2039 [05:02<00:05,  6.62it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  98%|█▉| 2007/2039 [05:02<00:04,  6.63it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2010/2039 [05:02<00:04,  6.64it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2013/2039 [05:02<00:03,  6.64it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2016/2039 [05:03<00:03,  6.65it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2019/2039 [05:03<00:03,  6.66it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2022/2039 [05:03<00:02,  6.67it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2025/2039 [05:03<00:02,  6.67it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10:  99%|█▉| 2028/2039 [05:03<00:01,  6.68it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10: 100%|█▉| 2031/2039 [05:03<00:01,  6.69it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10: 100%|█▉| 2034/2039 [05:03<00:00,  6.69it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10: 100%|█▉| 2037/2039 [05:03<00:00,  6.70it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.000916]\u001b[A\n",
      "Epoch 10: 100%|███| 2039/2039 [05:04<00:00,  6.71it/s, loss=0.000437, v_num=logs, train_loss=0.00048, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  80%|█▌| 1632/2039 [04:46<01:11,  5.70it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  80%|█▌| 1635/2039 [04:46<01:10,  5.70it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  80%|█▌| 1638/2039 [04:46<01:10,  5.71it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  80%|█▌| 1641/2039 [04:46<01:09,  5.72it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  81%|█▌| 1644/2039 [04:47<01:08,  5.73it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  81%|█▌| 1647/2039 [04:47<01:08,  5.74it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  81%|█▌| 1650/2039 [04:47<01:07,  5.74it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  81%|█▌| 1653/2039 [04:47<01:07,  5.75it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  81%|█▌| 1656/2039 [04:47<01:06,  5.76it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  81%|█▋| 1659/2039 [04:47<01:05,  5.77it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  82%|█▋| 1662/2039 [04:47<01:05,  5.78it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  82%|█▋| 1665/2039 [04:47<01:04,  5.78it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  82%|█▋| 1668/2039 [04:48<01:04,  5.79it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  82%|█▋| 1671/2039 [04:48<01:03,  5.80it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  82%|█▋| 1674/2039 [04:48<01:02,  5.81it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  82%|█▋| 1677/2039 [04:48<01:02,  5.81it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  82%|█▋| 1680/2039 [04:48<01:01,  5.82it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1683/2039 [04:48<01:01,  5.83it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1686/2039 [04:48<01:00,  5.84it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1689/2039 [04:48<00:59,  5.85it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1692/2039 [04:49<00:59,  5.85it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1695/2039 [04:49<00:58,  5.86it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1698/2039 [04:49<00:58,  5.87it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  83%|█▋| 1701/2039 [04:49<00:57,  5.88it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1704/2039 [04:49<00:56,  5.88it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1707/2039 [04:49<00:56,  5.89it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1710/2039 [04:49<00:55,  5.90it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1713/2039 [04:49<00:55,  5.91it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1716/2039 [04:50<00:54,  5.92it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1719/2039 [04:50<00:54,  5.92it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  84%|█▋| 1722/2039 [04:50<00:53,  5.93it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1725/2039 [04:50<00:52,  5.94it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1728/2039 [04:50<00:52,  5.95it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1731/2039 [04:50<00:51,  5.95it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1734/2039 [04:50<00:51,  5.96it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1737/2039 [04:51<00:50,  5.97it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1740/2039 [04:51<00:50,  5.98it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  85%|█▋| 1743/2039 [04:51<00:49,  5.98it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  86%|█▋| 1746/2039 [04:51<00:48,  5.99it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  86%|█▋| 1749/2039 [04:51<00:48,  6.00it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  86%|█▋| 1752/2039 [04:51<00:47,  6.01it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  86%|█▋| 1755/2039 [04:51<00:47,  6.01it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  86%|█▋| 1758/2039 [04:51<00:46,  6.02it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  86%|█▋| 1761/2039 [04:52<00:46,  6.03it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1764/2039 [04:52<00:45,  6.04it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1767/2039 [04:52<00:44,  6.05it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1770/2039 [04:52<00:44,  6.05it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1773/2039 [04:52<00:43,  6.06it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1776/2039 [04:52<00:43,  6.07it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1779/2039 [04:52<00:42,  6.08it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  87%|█▋| 1782/2039 [04:52<00:42,  6.08it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1785/2039 [04:53<00:41,  6.09it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1788/2039 [04:53<00:41,  6.10it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1791/2039 [04:53<00:40,  6.11it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1794/2039 [04:53<00:40,  6.11it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1797/2039 [04:53<00:39,  6.12it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1800/2039 [04:53<00:39,  6.13it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  88%|█▊| 1803/2039 [04:53<00:38,  6.14it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1806/2039 [04:53<00:37,  6.14it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1809/2039 [04:54<00:37,  6.15it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1812/2039 [04:54<00:36,  6.16it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1815/2039 [04:54<00:36,  6.17it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1818/2039 [04:54<00:35,  6.17it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1821/2039 [04:54<00:35,  6.18it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  89%|█▊| 1824/2039 [04:54<00:34,  6.19it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1827/2039 [04:54<00:34,  6.20it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1830/2039 [04:55<00:33,  6.20it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1833/2039 [04:55<00:33,  6.21it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1836/2039 [04:55<00:32,  6.22it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1839/2039 [04:55<00:32,  6.23it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1842/2039 [04:55<00:31,  6.23it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  90%|█▊| 1845/2039 [04:55<00:31,  6.24it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  91%|█▊| 1848/2039 [04:55<00:30,  6.25it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  91%|█▊| 1851/2039 [04:55<00:30,  6.26it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  91%|█▊| 1854/2039 [04:56<00:29,  6.26it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  91%|█▊| 1857/2039 [04:56<00:29,  6.27it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  91%|█▊| 1860/2039 [04:56<00:28,  6.28it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  91%|█▊| 1863/2039 [04:56<00:28,  6.28it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1866/2039 [04:56<00:27,  6.29it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1869/2039 [04:56<00:26,  6.30it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1872/2039 [04:56<00:26,  6.31it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1875/2039 [04:56<00:25,  6.31it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1878/2039 [04:57<00:25,  6.32it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1881/2039 [04:57<00:24,  6.33it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  92%|█▊| 1884/2039 [04:57<00:24,  6.34it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1887/2039 [04:57<00:23,  6.34it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1890/2039 [04:57<00:23,  6.35it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1893/2039 [04:57<00:22,  6.36it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1896/2039 [04:57<00:22,  6.37it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1899/2039 [04:58<00:21,  6.37it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1902/2039 [04:58<00:21,  6.38it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  93%|█▊| 1905/2039 [04:58<00:20,  6.39it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▊| 1908/2039 [04:58<00:20,  6.39it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▊| 1911/2039 [04:58<00:19,  6.40it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▉| 1914/2039 [04:58<00:19,  6.41it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▉| 1917/2039 [04:58<00:19,  6.42it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▉| 1920/2039 [04:58<00:18,  6.42it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▉| 1923/2039 [04:59<00:18,  6.43it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  94%|█▉| 1926/2039 [04:59<00:17,  6.44it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1929/2039 [04:59<00:17,  6.45it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1932/2039 [04:59<00:16,  6.45it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1935/2039 [04:59<00:16,  6.46it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1938/2039 [04:59<00:15,  6.47it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1941/2039 [04:59<00:15,  6.47it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1944/2039 [04:59<00:14,  6.48it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  95%|█▉| 1947/2039 [05:00<00:14,  6.49it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  96%|█▉| 1950/2039 [05:00<00:13,  6.50it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  96%|█▉| 1953/2039 [05:00<00:13,  6.50it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  96%|█▉| 1956/2039 [05:00<00:12,  6.51it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  96%|█▉| 1959/2039 [05:00<00:12,  6.52it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  96%|█▉| 1962/2039 [05:00<00:11,  6.52it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  96%|█▉| 1965/2039 [05:00<00:11,  6.53it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1968/2039 [05:00<00:10,  6.54it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1971/2039 [05:01<00:10,  6.55it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1974/2039 [05:01<00:09,  6.55it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1977/2039 [05:01<00:09,  6.56it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1980/2039 [05:01<00:08,  6.57it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1983/2039 [05:01<00:08,  6.57it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  97%|█▉| 1986/2039 [05:01<00:08,  6.58it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 1989/2039 [05:01<00:07,  6.59it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 1992/2039 [05:02<00:07,  6.60it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 1995/2039 [05:02<00:06,  6.60it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 1998/2039 [05:02<00:06,  6.61it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 2001/2039 [05:02<00:05,  6.62it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 2004/2039 [05:02<00:05,  6.62it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  98%|█▉| 2007/2039 [05:02<00:04,  6.63it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2010/2039 [05:02<00:04,  6.64it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2013/2039 [05:02<00:03,  6.65it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2016/2039 [05:03<00:03,  6.65it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2019/2039 [05:03<00:03,  6.66it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2022/2039 [05:03<00:02,  6.67it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2025/2039 [05:03<00:02,  6.67it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11:  99%|█▉| 2028/2039 [05:03<00:01,  6.68it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11: 100%|█▉| 2031/2039 [05:03<00:01,  6.69it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11: 100%|█▉| 2034/2039 [05:03<00:00,  6.69it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11: 100%|█▉| 2037/2039 [05:03<00:00,  6.70it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.00089]\u001b[A\n",
      "Epoch 11: 100%|█| 2039/2039 [05:04<00:00,  6.71it/s, loss=0.000429, v_num=logs, train_loss=0.000382, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  80%|▊| 1632/2039 [04:47<01:11,  5.67it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  80%|▊| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  80%|▊| 1641/2039 [04:48<01:09,  5.70it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  81%|▊| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  81%|▊| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  81%|▊| 1650/2039 [04:48<01:08,  5.72it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  81%|▊| 1659/2039 [04:48<01:06,  5.74it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1671/2039 [04:49<01:03,  5.77it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1686/2039 [04:50<01:00,  5.81it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  83%|▊| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1710/2039 [04:51<00:55,  5.88it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1734/2039 [04:52<00:51,  5.94it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  86%|▊| 1749/2039 [04:52<00:48,  5.97it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  86%|▊| 1752/2039 [04:52<00:47,  5.98it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  86%|▊| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  86%|▊| 1758/2039 [04:53<00:46,  6.00it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  86%|▊| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1776/2039 [04:53<00:43,  6.04it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1779/2039 [04:54<00:42,  6.05it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  87%|▊| 1782/2039 [04:54<00:42,  6.06it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1800/2039 [04:54<00:39,  6.10it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  88%|▉| 1803/2039 [04:55<00:38,  6.11it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1806/2039 [04:55<00:38,  6.12it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  89%|▉| 1824/2039 [04:55<00:34,  6.16it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  90%|▉| 1827/2039 [04:56<00:34,  6.17it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  90%|▉| 1830/2039 [04:56<00:33,  6.18it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  90%|▉| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  90%|▉| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  90%|▉| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  90%|▉| 1845/2039 [04:56<00:31,  6.21it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  91%|▉| 1848/2039 [04:57<00:30,  6.22it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  91%|▉| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  91%|▉| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  91%|▉| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  91%|▉| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1869/2039 [04:57<00:27,  6.27it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1872/2039 [04:58<00:26,  6.28it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  92%|▉| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1890/2039 [04:58<00:23,  6.32it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1893/2039 [04:58<00:23,  6.33it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1896/2039 [04:59<00:22,  6.34it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1899/2039 [04:59<00:22,  6.35it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  93%|▉| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1914/2039 [04:59<00:19,  6.38it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1917/2039 [04:59<00:19,  6.39it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1920/2039 [05:00<00:18,  6.40it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  94%|▉| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1935/2039 [05:00<00:16,  6.43it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1938/2039 [05:00<00:15,  6.44it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1941/2039 [05:01<00:15,  6.45it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1944/2039 [05:01<00:14,  6.45it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  95%|▉| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  96%|▉| 1956/2039 [05:01<00:12,  6.48it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  96%|▉| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  96%|▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  96%|▉| 1965/2039 [05:02<00:11,  6.51it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 1989/2039 [05:03<00:07,  6.56it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  98%|▉| 2007/2039 [05:03<00:04,  6.60it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2010/2039 [05:04<00:04,  6.61it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2013/2039 [05:04<00:03,  6.62it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12:  99%|▉| 2028/2039 [05:04<00:01,  6.65it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12: 100%|▉| 2031/2039 [05:04<00:01,  6.66it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12: 100%|▉| 2034/2039 [05:05<00:00,  6.67it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12: 100%|▉| 2037/2039 [05:05<00:00,  6.67it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000882]\u001b[A\n",
      "Epoch 12: 100%|█| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000456, v_num=logs, train_loss=0.000456, val_loss=0.000865]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  80%|▊| 1632/2039 [04:47<01:11,  5.67it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  80%|▊| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  80%|▊| 1641/2039 [04:48<01:09,  5.70it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  81%|▊| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  81%|▊| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  81%|▊| 1650/2039 [04:48<01:08,  5.72it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  81%|▊| 1659/2039 [04:48<01:06,  5.74it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1686/2039 [04:50<01:00,  5.81it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  83%|▊| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1710/2039 [04:51<00:55,  5.88it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1734/2039 [04:52<00:51,  5.94it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  86%|▊| 1752/2039 [04:52<00:47,  5.98it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  86%|▊| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  86%|▊| 1758/2039 [04:53<00:46,  6.00it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  86%|▊| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1776/2039 [04:53<00:43,  6.04it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1779/2039 [04:54<00:42,  6.05it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  87%|▊| 1782/2039 [04:54<00:42,  6.06it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1800/2039 [04:54<00:39,  6.10it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  88%|▉| 1803/2039 [04:55<00:38,  6.11it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1806/2039 [04:55<00:38,  6.12it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  89%|▉| 1824/2039 [04:55<00:34,  6.16it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  90%|▉| 1827/2039 [04:56<00:34,  6.17it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  90%|▉| 1830/2039 [04:56<00:33,  6.18it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  90%|▉| 1833/2039 [04:56<00:33,  6.18it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  90%|▉| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  90%|▉| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  90%|▉| 1845/2039 [04:56<00:31,  6.21it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  91%|▉| 1848/2039 [04:57<00:30,  6.22it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  91%|▉| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  91%|▉| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  91%|▉| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  91%|▉| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1869/2039 [04:57<00:27,  6.27it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1872/2039 [04:58<00:26,  6.28it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  92%|▉| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1890/2039 [04:58<00:23,  6.32it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1893/2039 [04:58<00:23,  6.33it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1896/2039 [04:59<00:22,  6.34it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1899/2039 [04:59<00:22,  6.35it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  93%|▉| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1914/2039 [04:59<00:19,  6.38it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1917/2039 [05:00<00:19,  6.39it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1920/2039 [05:00<00:18,  6.40it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  94%|▉| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1935/2039 [05:00<00:16,  6.43it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1938/2039 [05:00<00:15,  6.44it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1941/2039 [05:01<00:15,  6.45it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1944/2039 [05:01<00:14,  6.45it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  95%|▉| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  96%|▉| 1956/2039 [05:01<00:12,  6.48it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  96%|▉| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  96%|▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  96%|▉| 1965/2039 [05:02<00:11,  6.50it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  97%|▉| 1986/2039 [05:02<00:08,  6.55it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 1989/2039 [05:03<00:07,  6.56it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  98%|▉| 2007/2039 [05:03<00:04,  6.60it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  99%|▉| 2010/2039 [05:04<00:04,  6.61it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  99%|▉| 2013/2039 [05:04<00:03,  6.62it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  99%|▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  99%|▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  99%|▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13:  99%|▉| 2028/2039 [05:04<00:01,  6.65it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13: 100%|▉| 2031/2039 [05:04<00:01,  6.66it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13: 100%|▉| 2034/2039 [05:05<00:00,  6.67it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13: 100%|▉| 2037/2039 [05:05<00:00,  6.67it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.000865]\u001b[A\n",
      "Epoch 13: 100%|██| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000443, v_num=logs, train_loss=0.000459, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  80%|█▌| 1632/2039 [04:48<01:11,  5.67it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  80%|█▌| 1635/2039 [04:48<01:11,  5.67it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  80%|█▌| 1638/2039 [04:48<01:10,  5.68it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  80%|█▌| 1641/2039 [04:48<01:09,  5.69it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  81%|█▌| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  81%|█▌| 1647/2039 [04:48<01:08,  5.70it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  81%|█▌| 1650/2039 [04:48<01:08,  5.71it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  81%|█▌| 1653/2039 [04:48<01:07,  5.72it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  81%|█▌| 1656/2039 [04:49<01:06,  5.73it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  81%|█▋| 1659/2039 [04:49<01:06,  5.74it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1665/2039 [04:49<01:05,  5.75it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1668/2039 [04:49<01:04,  5.76it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1671/2039 [04:49<01:03,  5.77it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1677/2039 [04:50<01:02,  5.78it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  82%|█▋| 1680/2039 [04:50<01:01,  5.79it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1683/2039 [04:50<01:01,  5.80it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1686/2039 [04:50<01:00,  5.81it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1689/2039 [04:50<01:00,  5.81it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1692/2039 [04:50<00:59,  5.82it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1695/2039 [04:50<00:59,  5.83it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  83%|█▋| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1704/2039 [04:51<00:57,  5.85it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1707/2039 [04:51<00:56,  5.86it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1710/2039 [04:51<00:56,  5.87it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1716/2039 [04:51<00:54,  5.88it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1719/2039 [04:51<00:54,  5.89it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  84%|█▋| 1722/2039 [04:51<00:53,  5.90it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1725/2039 [04:52<00:53,  5.91it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1728/2039 [04:52<00:52,  5.91it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1731/2039 [04:52<00:52,  5.92it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1734/2039 [04:52<00:51,  5.93it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1740/2039 [04:52<00:50,  5.94it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  85%|█▋| 1743/2039 [04:52<00:49,  5.95it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  86%|█▋| 1746/2039 [04:52<00:49,  5.96it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  86%|█▋| 1749/2039 [04:53<00:48,  5.97it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  86%|█▋| 1752/2039 [04:53<00:48,  5.97it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  86%|█▋| 1755/2039 [04:53<00:47,  5.98it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  86%|█▋| 1758/2039 [04:53<00:46,  5.99it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  86%|█▋| 1761/2039 [04:53<00:46,  6.00it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1764/2039 [04:53<00:45,  6.00it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1767/2039 [04:53<00:45,  6.01it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1770/2039 [04:54<00:44,  6.02it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1773/2039 [04:54<00:44,  6.03it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1776/2039 [04:54<00:43,  6.04it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1779/2039 [04:54<00:43,  6.04it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  87%|█▋| 1782/2039 [04:54<00:42,  6.05it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1785/2039 [04:54<00:41,  6.06it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1791/2039 [04:54<00:40,  6.07it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1794/2039 [04:55<00:40,  6.08it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1797/2039 [04:55<00:39,  6.09it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1800/2039 [04:55<00:39,  6.10it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  88%|█▊| 1803/2039 [04:55<00:38,  6.10it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  89%|█▊| 1806/2039 [04:55<00:38,  6.11it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  89%|█▊| 1809/2039 [04:55<00:37,  6.12it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  89%|█▊| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  89%|█▊| 1815/2039 [04:55<00:36,  6.13it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  89%|█▊| 1818/2039 [04:56<00:35,  6.14it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  89%|█▊| 1821/2039 [04:56<00:35,  6.15it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  89%|█▊| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1827/2039 [04:56<00:34,  6.16it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1830/2039 [04:56<00:33,  6.17it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1833/2039 [04:56<00:33,  6.18it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1836/2039 [04:56<00:32,  6.18it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1839/2039 [04:56<00:32,  6.19it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1842/2039 [04:57<00:31,  6.20it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  90%|█▊| 1845/2039 [04:57<00:31,  6.21it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  91%|█▊| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  91%|█▊| 1851/2039 [04:57<00:30,  6.22it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  91%|█▊| 1854/2039 [04:57<00:29,  6.23it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  91%|█▊| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  91%|█▊| 1860/2039 [04:57<00:28,  6.24it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  91%|█▊| 1863/2039 [04:58<00:28,  6.25it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1866/2039 [04:58<00:27,  6.26it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1869/2039 [04:58<00:27,  6.27it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1872/2039 [04:58<00:26,  6.27it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1875/2039 [04:58<00:26,  6.28it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1878/2039 [04:58<00:25,  6.29it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1881/2039 [04:58<00:25,  6.29it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  92%|█▊| 1884/2039 [04:58<00:24,  6.30it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1887/2039 [04:59<00:24,  6.31it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1890/2039 [04:59<00:23,  6.32it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1896/2039 [04:59<00:22,  6.33it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1899/2039 [04:59<00:22,  6.34it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  93%|█▊| 1905/2039 [04:59<00:21,  6.35it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▊| 1908/2039 [04:59<00:20,  6.36it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▊| 1911/2039 [05:00<00:20,  6.37it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▉| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▉| 1917/2039 [05:00<00:19,  6.38it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▉| 1920/2039 [05:00<00:18,  6.39it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▉| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  94%|█▉| 1926/2039 [05:00<00:17,  6.40it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1929/2039 [05:00<00:17,  6.41it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1932/2039 [05:01<00:16,  6.42it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1935/2039 [05:01<00:16,  6.43it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1938/2039 [05:01<00:15,  6.43it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1941/2039 [05:01<00:15,  6.44it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1944/2039 [05:01<00:14,  6.45it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  95%|█▉| 1947/2039 [05:01<00:14,  6.45it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  96%|█▉| 1950/2039 [05:01<00:13,  6.46it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  96%|█▉| 1953/2039 [05:01<00:13,  6.47it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  96%|█▉| 1956/2039 [05:02<00:12,  6.48it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  96%|█▉| 1959/2039 [05:02<00:12,  6.48it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  96%|█▉| 1962/2039 [05:02<00:11,  6.49it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  96%|█▉| 1965/2039 [05:02<00:11,  6.50it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1971/2039 [05:02<00:10,  6.51it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1974/2039 [05:02<00:09,  6.52it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1980/2039 [05:03<00:09,  6.53it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1983/2039 [05:03<00:08,  6.54it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  97%|█▉| 1986/2039 [05:03<00:08,  6.55it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  98%|█▉| 1989/2039 [05:03<00:07,  6.55it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  98%|█▉| 1992/2039 [05:03<00:07,  6.56it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  98%|█▉| 1995/2039 [05:03<00:06,  6.57it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  98%|█▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  98%|█▉| 2001/2039 [05:03<00:05,  6.58it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  98%|█▉| 2004/2039 [05:04<00:05,  6.59it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  98%|█▉| 2007/2039 [05:04<00:04,  6.60it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2010/2039 [05:04<00:04,  6.60it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2013/2039 [05:04<00:03,  6.61it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2016/2039 [05:04<00:03,  6.62it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2019/2039 [05:04<00:03,  6.62it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2022/2039 [05:04<00:02,  6.63it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2025/2039 [05:05<00:02,  6.64it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14:  99%|█▉| 2028/2039 [05:05<00:01,  6.65it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14: 100%|█▉| 2031/2039 [05:05<00:01,  6.65it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14: 100%|█▉| 2034/2039 [05:05<00:00,  6.66it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14: 100%|█▉| 2037/2039 [05:05<00:00,  6.67it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.00083]\u001b[A\n",
      "Epoch 14: 100%|█| 2039/2039 [05:05<00:00,  6.67it/s, loss=0.000424, v_num=logs, train_loss=0.000169, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  80%|▊| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  81%|▊| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  81%|▊| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  81%|▊| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  81%|▊| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1674/2039 [04:48<01:03,  5.79it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  84%|▊| 1722/2039 [04:51<00:53,  5.92it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1725/2039 [04:51<00:52,  5.92it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  86%|▊| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  86%|▊| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  88%|▉| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  88%|▉| 1791/2039 [04:53<00:40,  6.09it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  88%|▉| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1836/2039 [04:55<00:32,  6.20it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  91%|▉| 1860/2039 [04:56<00:28,  6.26it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  91%|▉| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  92%|▉| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  93%|▉| 1905/2039 [04:58<00:21,  6.37it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  94%|▉| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  95%|▉| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  96%|▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  96%|▉| 1956/2039 [05:01<00:12,  6.50it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1977/2039 [05:02<00:09,  6.55it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  98%|▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2019/2039 [05:03<00:03,  6.64it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2022/2039 [05:03<00:02,  6.65it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000819]\u001b[A\n",
      "Epoch 15: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000421, v_num=logs, train_loss=0.000414, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  80%|▊| 1632/2039 [04:47<01:11,  5.67it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  80%|▊| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  80%|▊| 1638/2039 [04:48<01:10,  5.69it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  80%|▊| 1641/2039 [04:48<01:09,  5.69it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  81%|▊| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  81%|▊| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  81%|▊| 1650/2039 [04:48<01:08,  5.72it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  81%|▊| 1653/2039 [04:48<01:07,  5.72it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  81%|▊| 1656/2039 [04:48<01:06,  5.73it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  81%|▊| 1659/2039 [04:48<01:06,  5.74it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1662/2039 [04:49<01:05,  5.75it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1668/2039 [04:49<01:04,  5.76it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1671/2039 [04:49<01:03,  5.77it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  82%|▊| 1680/2039 [04:49<01:01,  5.79it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1683/2039 [04:50<01:01,  5.80it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1686/2039 [04:50<01:00,  5.81it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1695/2039 [04:50<00:58,  5.83it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  83%|▊| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1707/2039 [04:51<00:56,  5.86it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1710/2039 [04:51<00:56,  5.87it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  84%|▊| 1722/2039 [04:51<00:53,  5.90it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1731/2039 [04:52<00:51,  5.93it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1734/2039 [04:52<00:51,  5.93it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  86%|▊| 1746/2039 [04:52<00:49,  5.96it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  86%|▊| 1749/2039 [04:52<00:48,  5.97it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  86%|▊| 1752/2039 [04:53<00:48,  5.98it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  86%|▊| 1755/2039 [04:53<00:47,  5.99it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  86%|▊| 1758/2039 [04:53<00:46,  5.99it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  86%|▊| 1761/2039 [04:53<00:46,  6.00it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  87%|▊| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  87%|▊| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  87%|▊| 1770/2039 [04:53<00:44,  6.02it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  87%|▊| 1773/2039 [04:53<00:44,  6.03it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  87%|▊| 1776/2039 [04:54<00:43,  6.04it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  87%|▊| 1779/2039 [04:54<00:42,  6.05it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  87%|▊| 1782/2039 [04:54<00:42,  6.05it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1785/2039 [04:54<00:41,  6.06it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1794/2039 [04:54<00:40,  6.08it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1797/2039 [04:54<00:39,  6.09it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1800/2039 [04:55<00:39,  6.10it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  88%|▉| 1803/2039 [04:55<00:38,  6.11it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1806/2039 [04:55<00:38,  6.11it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1809/2039 [04:55<00:37,  6.12it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1818/2039 [04:55<00:35,  6.14it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1821/2039 [04:55<00:35,  6.15it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  89%|▉| 1824/2039 [04:56<00:34,  6.16it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1827/2039 [04:56<00:34,  6.17it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1830/2039 [04:56<00:33,  6.17it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1833/2039 [04:56<00:33,  6.18it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1842/2039 [04:56<00:31,  6.20it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  90%|▉| 1845/2039 [04:57<00:31,  6.21it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  91%|▉| 1848/2039 [04:57<00:30,  6.22it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  91%|▉| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  91%|▉| 1854/2039 [04:57<00:29,  6.23it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  91%|▉| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  91%|▉| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1866/2039 [04:57<00:27,  6.26it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1869/2039 [04:58<00:27,  6.27it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1872/2039 [04:58<00:26,  6.28it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1878/2039 [04:58<00:25,  6.29it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  92%|▉| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1887/2039 [04:58<00:24,  6.31it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1890/2039 [04:58<00:23,  6.32it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1893/2039 [04:59<00:23,  6.33it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1896/2039 [04:59<00:22,  6.34it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1899/2039 [04:59<00:22,  6.34it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  93%|▉| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1908/2039 [04:59<00:20,  6.36it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1911/2039 [04:59<00:20,  6.37it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1914/2039 [05:00<00:19,  6.38it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1917/2039 [05:00<00:19,  6.39it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1920/2039 [05:00<00:18,  6.39it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  94%|▉| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1932/2039 [05:00<00:16,  6.42it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1935/2039 [05:00<00:16,  6.43it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1938/2039 [05:01<00:15,  6.44it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1941/2039 [05:01<00:15,  6.44it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1944/2039 [05:01<00:14,  6.45it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  95%|▉| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  96%|▉| 1953/2039 [05:01<00:13,  6.47it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  96%|▉| 1956/2039 [05:01<00:12,  6.48it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  96%|▉| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  96%|▉| 1962/2039 [05:02<00:11,  6.49it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  96%|▉| 1965/2039 [05:02<00:11,  6.50it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  97%|▉| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  97%|▉| 1974/2039 [05:02<00:09,  6.52it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  97%|▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  97%|▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  97%|▉| 1983/2039 [05:03<00:08,  6.54it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  97%|▉| 1986/2039 [05:03<00:08,  6.55it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 1989/2039 [05:03<00:07,  6.56it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 1995/2039 [05:03<00:06,  6.57it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 2004/2039 [05:03<00:05,  6.59it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  98%|▉| 2007/2039 [05:04<00:04,  6.60it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2010/2039 [05:04<00:04,  6.61it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2013/2039 [05:04<00:03,  6.61it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2016/2039 [05:04<00:03,  6.62it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2025/2039 [05:04<00:02,  6.64it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16:  99%|▉| 2028/2039 [05:04<00:01,  6.65it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16: 100%|▉| 2031/2039 [05:05<00:01,  6.66it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16: 100%|▉| 2034/2039 [05:05<00:00,  6.66it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16: 100%|▉| 2037/2039 [05:05<00:00,  6.67it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000848]\u001b[A\n",
      "Epoch 16: 100%|█| 2039/2039 [05:05<00:00,  6.67it/s, loss=0.000382, v_num=logs, train_loss=0.000261, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  80%|▊| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  81%|▊| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  81%|▊| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  81%|▊| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  81%|▊| 1659/2039 [04:48<01:06,  5.76it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1674/2039 [04:48<01:02,  5.79it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  84%|▊| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1725/2039 [04:51<00:52,  5.93it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  86%|▊| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  86%|▊| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1791/2039 [04:53<00:40,  6.09it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1836/2039 [04:55<00:32,  6.20it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  91%|▉| 1860/2039 [04:56<00:28,  6.26it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  91%|▉| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  92%|▉| 1884/2039 [04:57<00:24,  6.32it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  93%|▉| 1905/2039 [04:58<00:21,  6.37it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  94%|▉| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  95%|▉| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  96%|▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  96%|▉| 1956/2039 [05:01<00:12,  6.50it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2022/2039 [05:03<00:02,  6.65it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000801]\u001b[A\n",
      "Epoch 17: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000395, v_num=logs, train_loss=0.000388, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  80%|▊| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  80%|▊| 1641/2039 [04:47<01:09,  5.70it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  81%|▊| 1644/2039 [04:48<01:09,  5.71it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  81%|▊| 1647/2039 [04:48<01:08,  5.72it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  81%|▊| 1650/2039 [04:48<01:07,  5.72it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1665/2039 [04:48<01:04,  5.76it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  83%|▊| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1713/2039 [04:51<00:55,  5.89it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  85%|▊| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  85%|▊| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  85%|▊| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  85%|▊| 1734/2039 [04:51<00:51,  5.94it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  85%|▊| 1737/2039 [04:52<00:50,  5.95it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  85%|▊| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  86%|▊| 1752/2039 [04:52<00:47,  5.98it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  86%|▊| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  86%|▊| 1758/2039 [04:53<00:46,  6.00it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  86%|▊| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1764/2039 [04:53<00:45,  6.02it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1779/2039 [04:53<00:42,  6.05it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  87%|▊| 1782/2039 [04:54<00:42,  6.06it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1788/2039 [04:54<00:41,  6.08it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  88%|▉| 1803/2039 [04:54<00:38,  6.11it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1806/2039 [04:55<00:38,  6.12it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1812/2039 [04:55<00:36,  6.14it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  89%|▉| 1824/2039 [04:55<00:34,  6.16it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1827/2039 [04:55<00:34,  6.17it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1830/2039 [04:56<00:33,  6.18it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  90%|▉| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  91%|▉| 1848/2039 [04:56<00:30,  6.22it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  91%|▉| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  91%|▉| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  91%|▉| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  91%|▉| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1872/2039 [04:57<00:26,  6.28it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  92%|▉| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1893/2039 [04:58<00:23,  6.33it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1896/2039 [04:58<00:22,  6.34it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1899/2039 [04:59<00:22,  6.35it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1902/2039 [04:59<00:21,  6.36it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  93%|▉| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1917/2039 [04:59<00:19,  6.39it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1920/2039 [05:00<00:18,  6.40it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1923/2039 [05:00<00:18,  6.41it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  94%|▉| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  95%|▉| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  95%|▉| 1938/2039 [05:00<00:15,  6.44it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  95%|▉| 1941/2039 [05:00<00:15,  6.45it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  95%|▉| 1944/2039 [05:01<00:14,  6.46it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  95%|▉| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  96%|▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  96%|▉| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  96%|▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  96%|▉| 1965/2039 [05:01<00:11,  6.51it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 1989/2039 [05:02<00:07,  6.56it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  98%|▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2010/2039 [05:03<00:04,  6.61it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2013/2039 [05:04<00:03,  6.62it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18:  99%|▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18: 100%|▉| 2031/2039 [05:04<00:01,  6.66it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18: 100%|▉| 2034/2039 [05:04<00:00,  6.67it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18: 100%|▉| 2037/2039 [05:05<00:00,  6.68it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000826]\u001b[A\n",
      "Epoch 18: 100%|█| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000376, v_num=logs, train_loss=0.000373, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  80%|▊| 1632/2039 [04:46<01:11,  5.69it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  80%|▊| 1635/2039 [04:47<01:10,  5.70it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  81%|▊| 1647/2039 [04:47<01:08,  5.73it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  81%|▊| 1653/2039 [04:47<01:07,  5.74it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  81%|▊| 1656/2039 [04:47<01:06,  5.75it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  81%|▊| 1659/2039 [04:48<01:05,  5.76it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1662/2039 [04:48<01:05,  5.77it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1674/2039 [04:48<01:02,  5.80it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1677/2039 [04:48<01:02,  5.80it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1689/2039 [04:49<00:59,  5.84it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  83%|▊| 1701/2039 [04:49<00:57,  5.87it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  84%|▊| 1713/2039 [04:50<00:55,  5.90it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  84%|▊| 1716/2039 [04:50<00:54,  5.91it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  84%|▊| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1725/2039 [04:50<00:52,  5.93it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1728/2039 [04:51<00:52,  5.94it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1740/2039 [04:51<00:50,  5.97it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  86%|▊| 1746/2039 [04:51<00:48,  5.98it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  86%|▊| 1749/2039 [04:51<00:48,  5.99it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  86%|▊| 1752/2039 [04:52<00:47,  6.00it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  86%|▊| 1755/2039 [04:52<00:47,  6.01it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1764/2039 [04:52<00:45,  6.03it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1767/2039 [04:52<00:45,  6.04it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1770/2039 [04:52<00:44,  6.04it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1776/2039 [04:53<00:43,  6.06it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1779/2039 [04:53<00:42,  6.07it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1788/2039 [04:53<00:41,  6.09it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1791/2039 [04:53<00:40,  6.10it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1794/2039 [04:53<00:40,  6.10it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1800/2039 [04:54<00:39,  6.12it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  88%|▉| 1803/2039 [04:54<00:38,  6.13it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1806/2039 [04:54<00:37,  6.13it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1812/2039 [04:54<00:36,  6.15it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1815/2039 [04:54<00:36,  6.16it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1818/2039 [04:54<00:35,  6.16it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  89%|▉| 1824/2039 [04:55<00:34,  6.18it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1827/2039 [04:55<00:34,  6.19it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1836/2039 [04:55<00:32,  6.21it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1839/2039 [04:55<00:32,  6.22it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1842/2039 [04:55<00:31,  6.22it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  91%|▉| 1848/2039 [04:56<00:30,  6.24it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  91%|▉| 1851/2039 [04:56<00:30,  6.25it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  91%|▉| 1860/2039 [04:56<00:28,  6.27it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  91%|▉| 1863/2039 [04:56<00:28,  6.28it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1872/2039 [04:57<00:26,  6.30it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1881/2039 [04:57<00:25,  6.32it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  92%|▉| 1884/2039 [04:57<00:24,  6.33it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1887/2039 [04:57<00:23,  6.33it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1893/2039 [04:58<00:22,  6.35it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1896/2039 [04:58<00:22,  6.36it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  93%|▉| 1905/2039 [04:58<00:21,  6.38it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  94%|▉| 1908/2039 [04:58<00:20,  6.39it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  94%|▉| 1911/2039 [04:58<00:20,  6.39it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  94%|▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  94%|▉| 1917/2039 [04:59<00:19,  6.41it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  94%|▉| 1926/2039 [04:59<00:17,  6.43it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1929/2039 [04:59<00:17,  6.44it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1932/2039 [04:59<00:16,  6.44it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1935/2039 [04:59<00:16,  6.45it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1938/2039 [05:00<00:15,  6.46it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  95%|▉| 1947/2039 [05:00<00:14,  6.48it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  96%|▉| 1950/2039 [05:00<00:13,  6.49it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  96%|▉| 1956/2039 [05:00<00:12,  6.50it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  96%|▉| 1959/2039 [05:01<00:12,  6.51it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  96%|▉| 1962/2039 [05:01<00:11,  6.52it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1971/2039 [05:01<00:10,  6.54it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1980/2039 [05:01<00:08,  6.56it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1983/2039 [05:02<00:08,  6.57it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 1992/2039 [05:02<00:07,  6.59it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 2001/2039 [05:02<00:05,  6.61it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 2004/2039 [05:02<00:05,  6.61it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2010/2039 [05:03<00:04,  6.63it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2013/2039 [05:03<00:03,  6.64it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2022/2039 [05:03<00:02,  6.66it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2025/2039 [05:03<00:02,  6.66it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19:  99%|▉| 2028/2039 [05:03<00:01,  6.67it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19: 100%|▉| 2031/2039 [05:04<00:01,  6.68it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19: 100%|▉| 2034/2039 [05:04<00:00,  6.69it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000757]\u001b[A\n",
      "Epoch 19: 100%|█| 2039/2039 [05:04<00:00,  6.70it/s, loss=0.000405, v_num=logs, train_loss=0.000315, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  80%|██▍| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  80%|██▍| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  80%|██▍| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  80%|██▍| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  81%|██▍| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  81%|██▍| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  81%|██▍| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  81%|██▍| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  81%|██▍| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  81%|██▍| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1674/2039 [04:48<01:03,  5.79it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  82%|██▍| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▍| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▍| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▍| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▍| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▍| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▍| 1698/2039 [04:50<00:58,  5.86it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  83%|██▌| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  84%|██▌| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  84%|██▌| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  84%|██▌| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  84%|██▌| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  84%|██▌| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  84%|██▌| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  84%|██▌| 1722/2039 [04:51<00:53,  5.92it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  85%|██▌| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  86%|██▌| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  86%|██▌| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  86%|██▌| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  86%|██▌| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  86%|██▌| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  86%|██▌| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  87%|██▌| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  88%|██▋| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  89%|██▋| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1836/2039 [04:55<00:32,  6.20it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  90%|██▋| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  91%|██▋| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  91%|██▋| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  91%|██▋| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  91%|██▋| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  91%|██▋| 1860/2039 [04:56<00:28,  6.26it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  91%|██▋| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▋| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▋| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▊| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▊| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▊| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▊| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  92%|██▊| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  93%|██▊| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  93%|██▊| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  93%|██▊| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  93%|██▊| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  93%|██▊| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  93%|██▊| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  93%|██▊| 1905/2039 [04:58<00:21,  6.37it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  94%|██▊| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  95%|██▊| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  96%|██▊| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  96%|██▊| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  96%|██▉| 1956/2039 [05:01<00:12,  6.50it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  96%|██▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  96%|██▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  96%|██▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1977/2039 [05:02<00:09,  6.55it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  97%|██▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  98%|██▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2022/2039 [05:03<00:02,  6.65it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20:  99%|██▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20: 100%|██▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20: 100%|██▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20: 100%|██▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000768]\u001b[A\n",
      "Epoch 20: 100%|███| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000408, v_num=logs, train_loss=0.0005, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  80%|▊| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  80%|▊| 1641/2039 [04:47<01:09,  5.70it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  81%|▊| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  81%|▊| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  81%|▊| 1650/2039 [04:48<01:07,  5.73it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  81%|▊| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1668/2039 [04:48<01:04,  5.77it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  83%|▊| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1719/2039 [04:51<00:54,  5.91it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1734/2039 [04:51<00:51,  5.94it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  85%|▊| 1743/2039 [04:52<00:49,  5.97it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  86%|▊| 1758/2039 [04:52<00:46,  6.00it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  86%|▊| 1761/2039 [04:52<00:46,  6.01it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1764/2039 [04:53<00:45,  6.02it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1785/2039 [04:53<00:41,  6.07it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1788/2039 [04:54<00:41,  6.08it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1809/2039 [04:54<00:37,  6.13it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1812/2039 [04:55<00:36,  6.14it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1833/2039 [04:55<00:33,  6.19it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  90%|▉| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  91%|▉| 1854/2039 [04:56<00:29,  6.24it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  91%|▉| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  91%|▉| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  91%|▉| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  92%|▉| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  92%|▉| 1878/2039 [04:57<00:25,  6.30it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  92%|▉| 1881/2039 [04:58<00:25,  6.31it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  92%|▉| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1899/2039 [04:58<00:22,  6.35it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1902/2039 [04:58<00:21,  6.36it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  93%|▉| 1905/2039 [04:59<00:21,  6.37it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1923/2039 [04:59<00:18,  6.41it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  94%|▉| 1926/2039 [05:00<00:17,  6.42it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1929/2039 [05:00<00:17,  6.43it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1944/2039 [05:00<00:14,  6.46it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  95%|▉| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  96%|▉| 1950/2039 [05:01<00:13,  6.48it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  96%|▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  96%|▉| 1965/2039 [05:01<00:11,  6.51it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 1995/2039 [05:02<00:06,  6.58it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  98%|▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2016/2039 [05:03<00:03,  6.63it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2019/2039 [05:03<00:03,  6.64it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2022/2039 [05:04<00:02,  6.65it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21:  99%|▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21: 100%|▉| 2037/2039 [05:04<00:00,  6.68it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000792]\u001b[A\n",
      "Epoch 21: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000381, v_num=logs, train_loss=0.000358, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  80%|█▌| 1632/2039 [04:47<01:11,  5.67it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  80%|█▌| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  80%|█▌| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  80%|█▌| 1641/2039 [04:48<01:09,  5.70it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  81%|█▌| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  81%|█▌| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  81%|█▌| 1650/2039 [04:48<01:08,  5.72it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  81%|█▌| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  81%|█▌| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  81%|█▋| 1659/2039 [04:48<01:06,  5.74it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  82%|█▋| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  82%|█▋| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  82%|█▋| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  82%|█▋| 1671/2039 [04:49<01:03,  5.77it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  82%|█▋| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  82%|█▋| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  82%|█▋| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1686/2039 [04:49<01:00,  5.81it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  83%|█▋| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1710/2039 [04:51<00:55,  5.88it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  84%|█▋| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1734/2039 [04:52<00:51,  5.94it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1737/2039 [04:52<00:50,  5.95it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  85%|█▋| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  86%|█▋| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  86%|█▋| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  86%|█▋| 1752/2039 [04:52<00:47,  5.98it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  86%|█▋| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  86%|█▋| 1758/2039 [04:53<00:46,  6.00it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  86%|█▋| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1776/2039 [04:53<00:43,  6.04it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1779/2039 [04:53<00:42,  6.05it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  87%|█▋| 1782/2039 [04:54<00:42,  6.06it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1800/2039 [04:54<00:39,  6.10it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  88%|█▊| 1803/2039 [04:55<00:38,  6.11it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1806/2039 [04:55<00:38,  6.12it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  89%|█▊| 1824/2039 [04:55<00:34,  6.16it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1827/2039 [04:56<00:34,  6.17it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1830/2039 [04:56<00:33,  6.18it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  90%|█▊| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  91%|█▊| 1848/2039 [04:56<00:30,  6.22it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  91%|█▊| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  91%|█▊| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  91%|█▊| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  91%|█▊| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  91%|█▊| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:  92%|█▊| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  92%|█▊| 1869/2039 [04:57<00:27,  6.27it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  92%|█▊| 1872/2039 [04:57<00:26,  6.28it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  92%|█▊| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  92%|█▊| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  92%|█▊| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  92%|█▊| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1893/2039 [04:58<00:23,  6.33it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1896/2039 [04:59<00:22,  6.34it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1899/2039 [04:59<00:22,  6.35it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1902/2039 [04:59<00:21,  6.36it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  93%|█▊| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▊| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▊| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▉| 1914/2039 [04:59<00:19,  6.38it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▉| 1917/2039 [04:59<00:19,  6.39it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▉| 1920/2039 [05:00<00:18,  6.40it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▉| 1923/2039 [05:00<00:18,  6.41it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  94%|█▉| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1935/2039 [05:00<00:16,  6.43it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1938/2039 [05:00<00:15,  6.44it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1941/2039 [05:00<00:15,  6.45it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1944/2039 [05:01<00:14,  6.46it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  95%|█▉| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  96%|█▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  96%|█▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  96%|█▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  96%|█▉| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  96%|█▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  96%|█▉| 1965/2039 [05:02<00:11,  6.51it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  97%|█▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 1989/2039 [05:03<00:07,  6.56it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  98%|█▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2010/2039 [05:03<00:04,  6.61it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2013/2039 [05:04<00:03,  6.62it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22:  99%|█▉| 2028/2039 [05:04<00:01,  6.65it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22: 100%|█▉| 2031/2039 [05:04<00:01,  6.66it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22: 100%|█▉| 2034/2039 [05:05<00:00,  6.67it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22: 100%|█▉| 2037/2039 [05:05<00:00,  6.68it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000776]\u001b[A\n",
      "Epoch 22: 100%|██| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000382, v_num=logs, train_loss=0.00039, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  80%|▊| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  80%|▊| 1641/2039 [04:47<01:09,  5.70it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  81%|▊| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  81%|▊| 1647/2039 [04:48<01:08,  5.72it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  81%|▊| 1650/2039 [04:48<01:07,  5.73it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1665/2039 [04:48<01:04,  5.76it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1668/2039 [04:48<01:04,  5.77it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1716/2039 [04:51<00:54,  5.90it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1734/2039 [04:51<00:51,  5.94it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1740/2039 [04:52<00:50,  5.96it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  86%|▊| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  86%|▊| 1758/2039 [04:52<00:46,  6.00it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  86%|▊| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1764/2039 [04:53<00:45,  6.02it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  87%|▊| 1782/2039 [04:53<00:42,  6.06it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1788/2039 [04:54<00:41,  6.08it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1806/2039 [04:54<00:38,  6.12it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1812/2039 [04:55<00:36,  6.14it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1830/2039 [04:55<00:33,  6.18it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  90%|▉| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  91%|▉| 1851/2039 [04:56<00:30,  6.23it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  91%|▉| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  91%|▉| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  91%|▉| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1875/2039 [04:57<00:26,  6.29it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1881/2039 [04:58<00:25,  6.31it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  92%|▉| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1896/2039 [04:58<00:22,  6.34it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1899/2039 [04:58<00:22,  6.35it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1902/2039 [04:59<00:21,  6.36it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  93%|▉| 1905/2039 [04:59<00:21,  6.37it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1920/2039 [04:59<00:18,  6.40it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1923/2039 [05:00<00:18,  6.41it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  94%|▉| 1926/2039 [05:00<00:17,  6.42it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1941/2039 [05:00<00:15,  6.45it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1944/2039 [05:00<00:14,  6.46it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  95%|▉| 1947/2039 [05:01<00:14,  6.47it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  96%|▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  96%|▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  96%|▉| 1965/2039 [05:01<00:11,  6.51it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  98%|▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2013/2039 [05:03<00:03,  6.62it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2019/2039 [05:04<00:03,  6.64it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23:  99%|▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23: 100%|▉| 2034/2039 [05:04<00:00,  6.67it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23: 100%|▉| 2037/2039 [05:04<00:00,  6.68it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000769]\u001b[A\n",
      "Epoch 23: 100%|█| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000415, v_num=logs, train_loss=0.000502, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  80%|▊| 1632/2039 [04:47<01:11,  5.67it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  80%|▊| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  80%|▊| 1641/2039 [04:48<01:09,  5.70it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  81%|▊| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  81%|▊| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  81%|▊| 1650/2039 [04:48<01:08,  5.72it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  81%|▊| 1659/2039 [04:48<01:06,  5.74it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1686/2039 [04:49<01:00,  5.81it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  83%|▊| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1710/2039 [04:51<00:55,  5.88it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1734/2039 [04:52<00:51,  5.94it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  86%|▊| 1752/2039 [04:52<00:47,  5.98it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  86%|▊| 1755/2039 [04:52<00:47,  5.99it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  86%|▊| 1758/2039 [04:53<00:46,  6.00it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  86%|▊| 1761/2039 [04:53<00:46,  6.01it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1767/2039 [04:53<00:45,  6.02it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1776/2039 [04:53<00:43,  6.04it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1779/2039 [04:54<00:42,  6.05it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  87%|▊| 1782/2039 [04:54<00:42,  6.06it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1791/2039 [04:54<00:40,  6.08it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1800/2039 [04:54<00:39,  6.10it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  88%|▉| 1803/2039 [04:55<00:38,  6.11it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1806/2039 [04:55<00:38,  6.12it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1815/2039 [04:55<00:36,  6.14it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  89%|▉| 1824/2039 [04:55<00:34,  6.16it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  90%|▉| 1827/2039 [04:56<00:34,  6.17it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  90%|▉| 1830/2039 [04:56<00:33,  6.18it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  90%|▉| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  90%|▉| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  90%|▉| 1839/2039 [04:56<00:32,  6.20it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  90%|▉| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  91%|▉| 1848/2039 [04:56<00:30,  6.22it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  91%|▉| 1851/2039 [04:57<00:30,  6.23it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  91%|▉| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  91%|▉| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  91%|▉| 1860/2039 [04:57<00:28,  6.25it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1869/2039 [04:57<00:27,  6.27it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1872/2039 [04:57<00:26,  6.28it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1875/2039 [04:58<00:26,  6.29it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  92%|▉| 1884/2039 [04:58<00:24,  6.31it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1893/2039 [04:58<00:23,  6.33it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1896/2039 [04:59<00:22,  6.34it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1899/2039 [04:59<00:22,  6.35it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  93%|▉| 1905/2039 [04:59<00:21,  6.36it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1914/2039 [04:59<00:19,  6.38it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1917/2039 [04:59<00:19,  6.39it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1920/2039 [05:00<00:18,  6.40it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1923/2039 [05:00<00:18,  6.41it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  94%|▉| 1926/2039 [05:00<00:17,  6.41it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1935/2039 [05:00<00:16,  6.43it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1938/2039 [05:00<00:15,  6.44it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1941/2039 [05:00<00:15,  6.45it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1944/2039 [05:01<00:14,  6.46it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  95%|▉| 1947/2039 [05:01<00:14,  6.46it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  96%|▉| 1956/2039 [05:01<00:12,  6.48it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  96%|▉| 1959/2039 [05:01<00:12,  6.49it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  96%|▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  96%|▉| 1965/2039 [05:01<00:11,  6.51it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1968/2039 [05:02<00:10,  6.51it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1980/2039 [05:02<00:09,  6.54it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 1989/2039 [05:03<00:07,  6.56it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 1992/2039 [05:03<00:07,  6.57it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 2001/2039 [05:03<00:05,  6.59it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  98%|▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  99%|▉| 2010/2039 [05:03<00:04,  6.61it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  99%|▉| 2013/2039 [05:04<00:03,  6.62it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  99%|▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  99%|▉| 2019/2039 [05:04<00:03,  6.63it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  99%|▉| 2022/2039 [05:04<00:02,  6.64it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  99%|▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24: 100%|▉| 2031/2039 [05:04<00:01,  6.66it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24: 100%|▉| 2034/2039 [05:04<00:00,  6.67it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24: 100%|▉| 2037/2039 [05:05<00:00,  6.68it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000755]\u001b[A\n",
      "Epoch 24: 100%|█| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000375, v_num=logs, train_loss=0.000489, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  80%|▊| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  80%|▊| 1641/2039 [04:47<01:09,  5.70it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  81%|▊| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  81%|▊| 1647/2039 [04:48<01:08,  5.72it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  81%|▊| 1650/2039 [04:48<01:07,  5.73it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1665/2039 [04:48<01:04,  5.76it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1668/2039 [04:48<01:04,  5.77it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1716/2039 [04:51<00:54,  5.90it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1734/2039 [04:51<00:51,  5.94it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1740/2039 [04:52<00:50,  5.96it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  85%|▊| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  86%|▊| 1758/2039 [04:52<00:46,  6.00it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  86%|▊| 1761/2039 [04:52<00:46,  6.01it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1764/2039 [04:53<00:45,  6.02it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  87%|▊| 1782/2039 [04:53<00:42,  6.06it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1785/2039 [04:54<00:41,  6.07it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1788/2039 [04:54<00:41,  6.08it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  89%|▉| 1806/2039 [04:54<00:38,  6.12it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  89%|▉| 1812/2039 [04:55<00:36,  6.14it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1830/2039 [04:55<00:33,  6.18it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  90%|▉| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  91%|▉| 1851/2039 [04:56<00:30,  6.23it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  91%|▉| 1854/2039 [04:57<00:29,  6.24it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  91%|▉| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  91%|▉| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  91%|▉| 1863/2039 [04:57<00:28,  6.26it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1875/2039 [04:57<00:26,  6.29it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1878/2039 [04:58<00:25,  6.30it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1881/2039 [04:58<00:25,  6.31it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  92%|▉| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1896/2039 [04:58<00:22,  6.34it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1899/2039 [04:58<00:22,  6.35it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1902/2039 [04:59<00:21,  6.36it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  93%|▉| 1905/2039 [04:59<00:21,  6.37it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1908/2039 [04:59<00:20,  6.37it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1920/2039 [04:59<00:18,  6.40it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1923/2039 [04:59<00:18,  6.41it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  94%|▉| 1926/2039 [05:00<00:17,  6.42it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1929/2039 [05:00<00:17,  6.42it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1941/2039 [05:00<00:15,  6.45it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1944/2039 [05:00<00:14,  6.46it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  95%|▉| 1947/2039 [05:01<00:14,  6.47it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  96%|▉| 1950/2039 [05:01<00:13,  6.47it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  96%|▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  96%|▉| 1962/2039 [05:01<00:11,  6.50it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  96%|▉| 1965/2039 [05:01<00:11,  6.51it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1971/2039 [05:02<00:10,  6.52it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 1992/2039 [05:02<00:07,  6.57it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  98%|▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  99%|▉| 2013/2039 [05:03<00:03,  6.62it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  99%|▉| 2016/2039 [05:04<00:03,  6.63it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  99%|▉| 2019/2039 [05:04<00:03,  6.64it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  99%|▉| 2022/2039 [05:04<00:02,  6.65it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25:  99%|▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25: 100%|▉| 2034/2039 [05:04<00:00,  6.67it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25: 100%|▉| 2037/2039 [05:04<00:00,  6.68it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000729]\u001b[A\n",
      "Epoch 25: 100%|█| 2039/2039 [05:05<00:00,  6.68it/s, loss=0.000413, v_num=logs, train_loss=0.000513, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  80%|▊| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  80%|▊| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  80%|▊| 1641/2039 [04:47<01:09,  5.70it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  81%|▊| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  81%|▊| 1647/2039 [04:48<01:08,  5.72it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  81%|▊| 1650/2039 [04:48<01:07,  5.73it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  81%|▊| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  81%|▊| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1665/2039 [04:48<01:04,  5.76it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1668/2039 [04:48<01:04,  5.77it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  82%|▊| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1716/2039 [04:51<00:54,  5.90it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  84%|▊| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1734/2039 [04:51<00:51,  5.94it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1740/2039 [04:52<00:50,  5.96it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  85%|▊| 1743/2039 [04:52<00:49,  5.97it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  86%|▊| 1746/2039 [04:52<00:49,  5.97it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  86%|▊| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  86%|▊| 1758/2039 [04:52<00:46,  6.00it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  86%|▊| 1761/2039 [04:52<00:46,  6.01it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1764/2039 [04:53<00:45,  6.02it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1770/2039 [04:53<00:44,  6.03it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  87%|▊| 1782/2039 [04:53<00:42,  6.06it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  88%|▉| 1785/2039 [04:53<00:41,  6.07it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  88%|▉| 1788/2039 [04:54<00:41,  6.08it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  88%|▉| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  88%|▉| 1794/2039 [04:54<00:40,  6.09it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  88%|▉| 1797/2039 [04:54<00:39,  6.10it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1806/2039 [04:54<00:38,  6.12it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1809/2039 [04:55<00:37,  6.13it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1812/2039 [04:55<00:36,  6.14it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1818/2039 [04:55<00:35,  6.15it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1821/2039 [04:55<00:35,  6.16it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1830/2039 [04:55<00:33,  6.18it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1833/2039 [04:56<00:33,  6.19it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1842/2039 [04:56<00:31,  6.21it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  90%|▉| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  91%|▉| 1854/2039 [04:56<00:29,  6.24it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  91%|▉| 1857/2039 [04:57<00:29,  6.25it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  91%|▉| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  91%|▉| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1866/2039 [04:57<00:27,  6.27it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1875/2039 [04:57<00:26,  6.29it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1878/2039 [04:57<00:25,  6.30it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1881/2039 [04:58<00:25,  6.31it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  92%|▉| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1887/2039 [04:58<00:24,  6.32it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1899/2039 [04:58<00:22,  6.35it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1902/2039 [04:59<00:21,  6.36it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  93%|▉| 1905/2039 [04:59<00:21,  6.37it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1911/2039 [04:59<00:20,  6.38it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1920/2039 [04:59<00:18,  6.40it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1923/2039 [04:59<00:18,  6.41it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  94%|▉| 1926/2039 [05:00<00:17,  6.42it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1929/2039 [05:00<00:17,  6.43it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1932/2039 [05:00<00:16,  6.43it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1941/2039 [05:00<00:15,  6.45it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1944/2039 [05:00<00:14,  6.46it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  95%|▉| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  96%|▉| 1950/2039 [05:01<00:13,  6.48it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  96%|▉| 1953/2039 [05:01<00:13,  6.48it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  96%|▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  96%|▉| 1965/2039 [05:01<00:11,  6.51it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1971/2039 [05:02<00:10,  6.53it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1974/2039 [05:02<00:09,  6.53it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1983/2039 [05:02<00:08,  6.55it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  97%|▉| 1986/2039 [05:02<00:08,  6.56it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  98%|▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  98%|▉| 1995/2039 [05:03<00:06,  6.58it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  98%|▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  98%|▉| 2004/2039 [05:03<00:05,  6.60it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  98%|▉| 2007/2039 [05:03<00:04,  6.61it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2016/2039 [05:03<00:03,  6.63it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2019/2039 [05:04<00:03,  6.64it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2022/2039 [05:04<00:02,  6.65it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2025/2039 [05:04<00:02,  6.65it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26:  99%|▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26: 100%|▉| 2034/2039 [05:04<00:00,  6.67it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26: 100%|▉| 2037/2039 [05:04<00:00,  6.68it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000733]\u001b[A\n",
      "Epoch 26: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000363, v_num=logs, train_loss=0.000201, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  80%|█▌| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  80%|█▌| 1635/2039 [04:47<01:11,  5.68it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  80%|█▌| 1638/2039 [04:47<01:10,  5.69it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  80%|█▌| 1641/2039 [04:47<01:09,  5.70it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  81%|█▌| 1644/2039 [04:48<01:09,  5.71it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  81%|█▌| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  81%|█▌| 1650/2039 [04:48<01:07,  5.72it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  81%|█▌| 1653/2039 [04:48<01:07,  5.73it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  81%|█▌| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  81%|█▋| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1662/2039 [04:48<01:05,  5.75it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1665/2039 [04:49<01:04,  5.76it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1668/2039 [04:49<01:04,  5.77it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1671/2039 [04:49<01:03,  5.78it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1677/2039 [04:49<01:02,  5.79it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  82%|█▋| 1680/2039 [04:49<01:01,  5.80it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1683/2039 [04:49<01:01,  5.81it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1689/2039 [04:50<01:00,  5.82it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1692/2039 [04:50<00:59,  5.83it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1695/2039 [04:50<00:58,  5.84it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  83%|█▋| 1701/2039 [04:50<00:57,  5.85it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1704/2039 [04:50<00:57,  5.86it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1707/2039 [04:50<00:56,  5.87it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1713/2039 [04:51<00:55,  5.89it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1716/2039 [04:51<00:54,  5.89it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1719/2039 [04:51<00:54,  5.90it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  84%|█▋| 1722/2039 [04:51<00:53,  5.91it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1725/2039 [04:51<00:53,  5.91it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1728/2039 [04:51<00:52,  5.92it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1731/2039 [04:51<00:51,  5.93it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1734/2039 [04:52<00:51,  5.94it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1740/2039 [04:52<00:50,  5.95it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Validating:  27%|██████████████████▏                                                 | 109/408 [00:04<00:16, 17.76it/s]\u001b[A\n",
      "Epoch 27:  85%|█▋| 1743/2039 [04:52<00:49,  5.96it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  86%|█▋| 1746/2039 [04:52<00:49,  5.96it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  86%|█▋| 1749/2039 [04:52<00:48,  5.97it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  86%|█▋| 1752/2039 [04:53<00:48,  5.98it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  86%|█▋| 1755/2039 [04:53<00:47,  5.98it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  86%|█▋| 1758/2039 [04:53<00:46,  5.99it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  86%|█▋| 1761/2039 [04:53<00:46,  6.00it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  87%|█▋| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  87%|█▋| 1767/2039 [04:53<00:45,  6.01it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  87%|█▋| 1770/2039 [04:53<00:44,  6.02it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  87%|█▋| 1773/2039 [04:54<00:44,  6.03it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  87%|█▋| 1776/2039 [04:54<00:43,  6.04it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  87%|█▋| 1779/2039 [04:54<00:43,  6.04it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  87%|█▋| 1782/2039 [04:54<00:42,  6.05it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1785/2039 [04:54<00:41,  6.06it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1791/2039 [04:54<00:40,  6.07it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1794/2039 [04:55<00:40,  6.08it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1797/2039 [04:55<00:39,  6.09it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1800/2039 [04:55<00:39,  6.09it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  88%|█▊| 1803/2039 [04:55<00:38,  6.10it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1806/2039 [04:55<00:38,  6.11it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1809/2039 [04:55<00:37,  6.12it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1812/2039 [04:55<00:37,  6.12it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1815/2039 [04:56<00:36,  6.13it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1818/2039 [04:56<00:36,  6.14it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1821/2039 [04:56<00:35,  6.15it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  89%|█▊| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1827/2039 [04:56<00:34,  6.16it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1830/2039 [04:56<00:33,  6.17it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1833/2039 [04:56<00:33,  6.17it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1836/2039 [04:57<00:32,  6.18it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1839/2039 [04:57<00:32,  6.19it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1842/2039 [04:57<00:31,  6.20it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  90%|█▊| 1845/2039 [04:57<00:31,  6.20it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  91%|█▊| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  91%|█▊| 1851/2039 [04:57<00:30,  6.22it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  91%|█▊| 1854/2039 [04:57<00:29,  6.22it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  91%|█▊| 1857/2039 [04:57<00:29,  6.23it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  91%|█▊| 1860/2039 [04:58<00:28,  6.24it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  91%|█▊| 1863/2039 [04:58<00:28,  6.25it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1866/2039 [04:58<00:27,  6.25it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1869/2039 [04:58<00:27,  6.26it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1872/2039 [04:58<00:26,  6.27it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1875/2039 [04:58<00:26,  6.27it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1878/2039 [04:58<00:25,  6.28it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1881/2039 [04:59<00:25,  6.29it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  92%|█▊| 1884/2039 [04:59<00:24,  6.30it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1887/2039 [04:59<00:24,  6.30it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1890/2039 [04:59<00:23,  6.31it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1896/2039 [04:59<00:22,  6.33it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1899/2039 [04:59<00:22,  6.33it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1902/2039 [05:00<00:21,  6.34it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  93%|█▊| 1905/2039 [05:00<00:21,  6.35it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▊| 1908/2039 [05:00<00:20,  6.35it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▊| 1911/2039 [05:00<00:20,  6.36it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▉| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▉| 1917/2039 [05:00<00:19,  6.38it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▉| 1920/2039 [05:00<00:18,  6.38it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▉| 1923/2039 [05:00<00:18,  6.39it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  94%|█▉| 1926/2039 [05:01<00:17,  6.40it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1929/2039 [05:01<00:17,  6.40it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1932/2039 [05:01<00:16,  6.41it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1935/2039 [05:01<00:16,  6.42it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1938/2039 [05:01<00:15,  6.43it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1941/2039 [05:01<00:15,  6.43it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1944/2039 [05:01<00:14,  6.44it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  95%|█▉| 1947/2039 [05:02<00:14,  6.45it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  96%|█▉| 1950/2039 [05:02<00:13,  6.45it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  96%|█▉| 1953/2039 [05:02<00:13,  6.46it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  96%|█▉| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  96%|█▉| 1959/2039 [05:02<00:12,  6.47it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  96%|█▉| 1962/2039 [05:02<00:11,  6.48it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  96%|█▉| 1965/2039 [05:02<00:11,  6.49it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  97%|█▉| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:  97%|█▉| 1971/2039 [05:03<00:10,  6.50it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  97%|█▉| 1974/2039 [05:03<00:09,  6.51it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  97%|█▉| 1977/2039 [05:03<00:09,  6.52it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  97%|█▉| 1980/2039 [05:03<00:09,  6.52it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  97%|█▉| 1983/2039 [05:03<00:08,  6.53it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  97%|█▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 1989/2039 [05:03<00:07,  6.55it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 1992/2039 [05:04<00:07,  6.55it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 1995/2039 [05:04<00:06,  6.56it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 1998/2039 [05:04<00:06,  6.57it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 2001/2039 [05:04<00:05,  6.57it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 2004/2039 [05:04<00:05,  6.58it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  98%|█▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2010/2039 [05:04<00:04,  6.59it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2013/2039 [05:04<00:03,  6.60it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2016/2039 [05:05<00:03,  6.61it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2019/2039 [05:05<00:03,  6.61it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2022/2039 [05:05<00:02,  6.62it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2025/2039 [05:05<00:02,  6.63it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27:  99%|█▉| 2028/2039 [05:05<00:01,  6.64it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27: 100%|█▉| 2031/2039 [05:05<00:01,  6.64it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27: 100%|█▉| 2034/2039 [05:05<00:00,  6.65it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27: 100%|█▉| 2037/2039 [05:06<00:00,  6.66it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000711]\u001b[A\n",
      "Epoch 27: 100%|██| 2039/2039 [05:06<00:00,  6.66it/s, loss=0.00038, v_num=logs, train_loss=0.000315, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  80%|▊| 1632/2039 [04:48<01:11,  5.67it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  80%|▊| 1635/2039 [04:48<01:11,  5.67it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  80%|▊| 1638/2039 [04:48<01:10,  5.68it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  80%|▊| 1641/2039 [04:48<01:09,  5.69it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  81%|▊| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  81%|▊| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  81%|▊| 1650/2039 [04:48<01:08,  5.71it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  81%|▊| 1653/2039 [04:48<01:07,  5.72it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  81%|▊| 1656/2039 [04:49<01:06,  5.73it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  81%|▊| 1659/2039 [04:49<01:06,  5.74it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1665/2039 [04:49<01:05,  5.75it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1668/2039 [04:49<01:04,  5.76it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1671/2039 [04:49<01:03,  5.77it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1677/2039 [04:49<01:02,  5.78it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  82%|▊| 1680/2039 [04:50<01:01,  5.79it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1683/2039 [04:50<01:01,  5.80it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1686/2039 [04:50<01:00,  5.81it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1689/2039 [04:50<01:00,  5.81it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1692/2039 [04:50<00:59,  5.82it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1695/2039 [04:50<00:59,  5.83it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  83%|▊| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1704/2039 [04:51<00:57,  5.85it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1707/2039 [04:51<00:56,  5.86it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1710/2039 [04:51<00:56,  5.87it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1716/2039 [04:51<00:54,  5.88it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1719/2039 [04:51<00:54,  5.89it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  84%|▊| 1722/2039 [04:51<00:53,  5.90it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1725/2039 [04:52<00:53,  5.91it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1728/2039 [04:52<00:52,  5.91it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1731/2039 [04:52<00:52,  5.92it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1734/2039 [04:52<00:51,  5.93it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1740/2039 [04:52<00:50,  5.94it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  85%|▊| 1743/2039 [04:52<00:49,  5.95it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  86%|▊| 1746/2039 [04:52<00:49,  5.96it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  86%|▊| 1749/2039 [04:53<00:48,  5.97it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  86%|▊| 1752/2039 [04:53<00:48,  5.97it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  86%|▊| 1755/2039 [04:53<00:47,  5.98it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  86%|▊| 1758/2039 [04:53<00:46,  5.99it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  86%|▊| 1761/2039 [04:53<00:46,  6.00it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1764/2039 [04:53<00:45,  6.00it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1767/2039 [04:53<00:45,  6.01it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1770/2039 [04:54<00:44,  6.02it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1773/2039 [04:54<00:44,  6.03it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1776/2039 [04:54<00:43,  6.03it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1779/2039 [04:54<00:43,  6.04it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  87%|▊| 1782/2039 [04:54<00:42,  6.05it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1785/2039 [04:54<00:41,  6.06it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1791/2039 [04:54<00:40,  6.07it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1794/2039 [04:55<00:40,  6.08it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1797/2039 [04:55<00:39,  6.09it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1800/2039 [04:55<00:39,  6.10it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  88%|▉| 1803/2039 [04:55<00:38,  6.10it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1806/2039 [04:55<00:38,  6.11it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1809/2039 [04:55<00:37,  6.12it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1812/2039 [04:55<00:37,  6.12it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1815/2039 [04:55<00:36,  6.13it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1818/2039 [04:56<00:35,  6.14it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1821/2039 [04:56<00:35,  6.15it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  89%|▉| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1827/2039 [04:56<00:34,  6.16it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1830/2039 [04:56<00:33,  6.17it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1833/2039 [04:56<00:33,  6.18it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1836/2039 [04:56<00:32,  6.18it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1839/2039 [04:57<00:32,  6.19it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1842/2039 [04:57<00:31,  6.20it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  90%|▉| 1845/2039 [04:57<00:31,  6.21it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  91%|▉| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  91%|▉| 1851/2039 [04:57<00:30,  6.22it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  91%|▉| 1854/2039 [04:57<00:29,  6.23it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  91%|▉| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  91%|▉| 1860/2039 [04:57<00:28,  6.24it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  91%|▉| 1863/2039 [04:58<00:28,  6.25it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1866/2039 [04:58<00:27,  6.26it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1869/2039 [04:58<00:27,  6.27it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1872/2039 [04:58<00:26,  6.27it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1875/2039 [04:58<00:26,  6.28it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1878/2039 [04:58<00:25,  6.29it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1881/2039 [04:58<00:25,  6.29it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  92%|▉| 1884/2039 [04:58<00:24,  6.30it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1887/2039 [04:59<00:24,  6.31it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1890/2039 [04:59<00:23,  6.32it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1896/2039 [04:59<00:22,  6.33it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1899/2039 [04:59<00:22,  6.34it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1902/2039 [04:59<00:21,  6.34it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  93%|▉| 1905/2039 [04:59<00:21,  6.35it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1908/2039 [05:00<00:20,  6.36it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1911/2039 [05:00<00:20,  6.37it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1917/2039 [05:00<00:19,  6.38it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1920/2039 [05:00<00:18,  6.39it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  94%|▉| 1926/2039 [05:00<00:17,  6.40it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1929/2039 [05:00<00:17,  6.41it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1932/2039 [05:01<00:16,  6.42it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1935/2039 [05:01<00:16,  6.42it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1938/2039 [05:01<00:15,  6.43it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1941/2039 [05:01<00:15,  6.44it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1944/2039 [05:01<00:14,  6.45it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  95%|▉| 1947/2039 [05:01<00:14,  6.45it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  96%|▉| 1950/2039 [05:01<00:13,  6.46it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  96%|▉| 1953/2039 [05:02<00:13,  6.47it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  96%|▉| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  96%|▉| 1959/2039 [05:02<00:12,  6.48it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  96%|▉| 1962/2039 [05:02<00:11,  6.49it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  96%|▉| 1965/2039 [05:02<00:11,  6.50it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1971/2039 [05:02<00:10,  6.51it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1974/2039 [05:02<00:09,  6.52it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1977/2039 [05:03<00:09,  6.52it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1980/2039 [05:03<00:09,  6.53it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1983/2039 [05:03<00:08,  6.54it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  97%|▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 1989/2039 [05:03<00:07,  6.55it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 1992/2039 [05:03<00:07,  6.56it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 1995/2039 [05:03<00:06,  6.57it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 1998/2039 [05:03<00:06,  6.57it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 2001/2039 [05:04<00:05,  6.58it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 2004/2039 [05:04<00:05,  6.59it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  98%|▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2010/2039 [05:04<00:04,  6.60it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2013/2039 [05:04<00:03,  6.61it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2016/2039 [05:04<00:03,  6.62it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2019/2039 [05:04<00:03,  6.62it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2022/2039 [05:04<00:02,  6.63it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2025/2039 [05:05<00:02,  6.64it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28:  99%|▉| 2028/2039 [05:05<00:01,  6.64it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28: 100%|▉| 2031/2039 [05:05<00:01,  6.65it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28: 100%|▉| 2034/2039 [05:05<00:00,  6.66it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28: 100%|▉| 2037/2039 [05:05<00:00,  6.66it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000707]\u001b[A\n",
      "Epoch 28: 100%|█| 2039/2039 [05:05<00:00,  6.67it/s, loss=0.000359, v_num=logs, train_loss=0.000362, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  80%|█▌| 1632/2039 [04:48<01:11,  5.66it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  80%|█▌| 1635/2039 [04:48<01:11,  5.66it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  80%|█▌| 1638/2039 [04:48<01:10,  5.67it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  80%|█▌| 1641/2039 [04:48<01:10,  5.68it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  81%|█▌| 1644/2039 [04:49<01:09,  5.69it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  81%|█▌| 1647/2039 [04:49<01:08,  5.69it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  81%|█▌| 1650/2039 [04:49<01:08,  5.70it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  81%|█▌| 1653/2039 [04:49<01:07,  5.71it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  81%|█▌| 1656/2039 [04:49<01:06,  5.72it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  81%|█▋| 1659/2039 [04:49<01:06,  5.73it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1662/2039 [04:49<01:05,  5.73it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1665/2039 [04:50<01:05,  5.74it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1668/2039 [04:50<01:04,  5.75it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1671/2039 [04:50<01:03,  5.76it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1674/2039 [04:50<01:03,  5.76it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1677/2039 [04:50<01:02,  5.77it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  82%|█▋| 1680/2039 [04:50<01:02,  5.78it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1683/2039 [04:50<01:01,  5.79it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1686/2039 [04:50<01:00,  5.79it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1689/2039 [04:51<01:00,  5.80it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1692/2039 [04:51<00:59,  5.81it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1695/2039 [04:51<00:59,  5.82it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1698/2039 [04:51<00:58,  5.82it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  83%|█▋| 1701/2039 [04:51<00:57,  5.83it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1704/2039 [04:51<00:57,  5.84it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1707/2039 [04:51<00:56,  5.85it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1710/2039 [04:52<00:56,  5.86it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1713/2039 [04:52<00:55,  5.86it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1716/2039 [04:52<00:55,  5.87it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1719/2039 [04:52<00:54,  5.88it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  84%|█▋| 1722/2039 [04:52<00:53,  5.89it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  85%|█▋| 1725/2039 [04:52<00:53,  5.89it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  85%|█▋| 1728/2039 [04:52<00:52,  5.90it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  85%|█▋| 1731/2039 [04:52<00:52,  5.91it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  85%|█▋| 1734/2039 [04:53<00:51,  5.92it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  85%|█▋| 1737/2039 [04:53<00:50,  5.92it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  85%|█▋| 1740/2039 [04:53<00:50,  5.93it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  85%|█▋| 1743/2039 [04:53<00:49,  5.94it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  86%|█▋| 1746/2039 [04:53<00:49,  5.95it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  86%|█▋| 1749/2039 [04:53<00:48,  5.95it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  86%|█▋| 1752/2039 [04:53<00:48,  5.96it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  86%|█▋| 1755/2039 [04:54<00:47,  5.97it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  86%|█▋| 1758/2039 [04:54<00:47,  5.98it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  86%|█▋| 1761/2039 [04:54<00:46,  5.98it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1764/2039 [04:54<00:45,  5.99it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1767/2039 [04:54<00:45,  6.00it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1770/2039 [04:54<00:44,  6.01it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1773/2039 [04:54<00:44,  6.01it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1776/2039 [04:54<00:43,  6.02it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1779/2039 [04:55<00:43,  6.03it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  87%|█▋| 1782/2039 [04:55<00:42,  6.04it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1785/2039 [04:55<00:42,  6.04it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1788/2039 [04:55<00:41,  6.05it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1791/2039 [04:55<00:40,  6.06it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1794/2039 [04:55<00:40,  6.07it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1797/2039 [04:55<00:39,  6.07it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1800/2039 [04:56<00:39,  6.08it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  88%|█▊| 1803/2039 [04:56<00:38,  6.09it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1806/2039 [04:56<00:38,  6.10it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1809/2039 [04:56<00:37,  6.10it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1812/2039 [04:56<00:37,  6.11it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1815/2039 [04:56<00:36,  6.12it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1818/2039 [04:56<00:36,  6.12it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1821/2039 [04:56<00:35,  6.13it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  89%|█▊| 1824/2039 [04:57<00:35,  6.14it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1827/2039 [04:57<00:34,  6.15it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1830/2039 [04:57<00:33,  6.15it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1833/2039 [04:57<00:33,  6.16it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1836/2039 [04:57<00:32,  6.17it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1839/2039 [04:57<00:32,  6.18it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1842/2039 [04:57<00:31,  6.18it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  90%|█▊| 1845/2039 [04:58<00:31,  6.19it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  91%|█▊| 1848/2039 [04:58<00:30,  6.20it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  91%|█▊| 1851/2039 [04:58<00:30,  6.20it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  91%|█▊| 1854/2039 [04:58<00:29,  6.21it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  91%|█▊| 1857/2039 [04:58<00:29,  6.22it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  91%|█▊| 1860/2039 [04:58<00:28,  6.23it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  91%|█▊| 1863/2039 [04:58<00:28,  6.23it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1866/2039 [04:59<00:27,  6.24it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1869/2039 [04:59<00:27,  6.25it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1872/2039 [04:59<00:26,  6.25it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1875/2039 [04:59<00:26,  6.26it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1878/2039 [04:59<00:25,  6.27it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1881/2039 [04:59<00:25,  6.28it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  92%|█▊| 1884/2039 [04:59<00:24,  6.28it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1887/2039 [04:59<00:24,  6.29it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1890/2039 [05:00<00:23,  6.30it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1893/2039 [05:00<00:23,  6.31it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1896/2039 [05:00<00:22,  6.31it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1899/2039 [05:00<00:22,  6.32it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1902/2039 [05:00<00:21,  6.33it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  93%|█▊| 1905/2039 [05:00<00:21,  6.33it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▊| 1908/2039 [05:00<00:20,  6.34it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▊| 1911/2039 [05:01<00:20,  6.35it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▉| 1914/2039 [05:01<00:19,  6.36it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▉| 1917/2039 [05:01<00:19,  6.36it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▉| 1920/2039 [05:01<00:18,  6.37it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▉| 1923/2039 [05:01<00:18,  6.38it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  94%|█▉| 1926/2039 [05:01<00:17,  6.38it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  95%|█▉| 1929/2039 [05:01<00:17,  6.39it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  95%|█▉| 1932/2039 [05:01<00:16,  6.40it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:  95%|█▉| 1935/2039 [05:02<00:16,  6.41it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  95%|█▉| 1938/2039 [05:02<00:15,  6.41it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  95%|█▉| 1941/2039 [05:02<00:15,  6.42it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  95%|█▉| 1944/2039 [05:02<00:14,  6.43it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  95%|█▉| 1947/2039 [05:02<00:14,  6.43it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  96%|█▉| 1950/2039 [05:02<00:13,  6.44it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  96%|█▉| 1953/2039 [05:02<00:13,  6.45it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  96%|█▉| 1956/2039 [05:02<00:12,  6.46it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  96%|█▉| 1959/2039 [05:03<00:12,  6.46it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  96%|█▉| 1962/2039 [05:03<00:11,  6.47it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  96%|█▉| 1965/2039 [05:03<00:11,  6.48it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1968/2039 [05:03<00:10,  6.48it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1971/2039 [05:03<00:10,  6.49it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1974/2039 [05:03<00:10,  6.50it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1977/2039 [05:03<00:09,  6.51it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1980/2039 [05:04<00:09,  6.51it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1983/2039 [05:04<00:08,  6.52it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  97%|█▉| 1986/2039 [05:04<00:08,  6.53it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 1989/2039 [05:04<00:07,  6.53it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 1992/2039 [05:04<00:07,  6.54it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 1995/2039 [05:04<00:06,  6.55it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 1998/2039 [05:04<00:06,  6.56it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 2001/2039 [05:04<00:05,  6.56it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 2004/2039 [05:05<00:05,  6.57it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  98%|█▉| 2007/2039 [05:05<00:04,  6.58it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2010/2039 [05:05<00:04,  6.58it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2013/2039 [05:05<00:03,  6.59it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2016/2039 [05:05<00:03,  6.60it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2019/2039 [05:05<00:03,  6.60it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2022/2039 [05:05<00:02,  6.61it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2025/2039 [05:05<00:02,  6.62it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29:  99%|█▉| 2028/2039 [05:06<00:01,  6.63it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29: 100%|█▉| 2031/2039 [05:06<00:01,  6.63it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29: 100%|█▉| 2034/2039 [05:06<00:00,  6.64it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29: 100%|█▉| 2037/2039 [05:06<00:00,  6.65it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000696]\u001b[A\n",
      "Epoch 29: 100%|██| 2039/2039 [05:06<00:00,  6.65it/s, loss=0.000372, v_num=logs, train_loss=0.00034, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  80%|▊| 1632/2039 [04:48<01:11,  5.67it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  80%|▊| 1635/2039 [04:48<01:11,  5.67it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  80%|▊| 1638/2039 [04:48<01:10,  5.68it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  80%|▊| 1641/2039 [04:48<01:09,  5.69it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  81%|▊| 1644/2039 [04:48<01:09,  5.70it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  81%|▊| 1647/2039 [04:48<01:08,  5.71it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  81%|▊| 1650/2039 [04:48<01:08,  5.71it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  81%|▊| 1653/2039 [04:48<01:07,  5.72it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  81%|▊| 1656/2039 [04:49<01:06,  5.73it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  81%|▊| 1659/2039 [04:49<01:06,  5.74it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1665/2039 [04:49<01:05,  5.75it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1668/2039 [04:49<01:04,  5.76it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1671/2039 [04:49<01:03,  5.77it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1674/2039 [04:49<01:03,  5.78it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1677/2039 [04:49<01:02,  5.78it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  82%|▊| 1680/2039 [04:50<01:01,  5.79it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1683/2039 [04:50<01:01,  5.80it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1686/2039 [04:50<01:00,  5.81it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1689/2039 [04:50<01:00,  5.81it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1692/2039 [04:50<00:59,  5.82it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1695/2039 [04:50<00:59,  5.83it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1698/2039 [04:50<00:58,  5.84it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  83%|▊| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  84%|▊| 1704/2039 [04:51<00:57,  5.85it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  84%|▊| 1707/2039 [04:51<00:56,  5.86it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  84%|▊| 1710/2039 [04:51<00:56,  5.87it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  84%|▊| 1713/2039 [04:51<00:55,  5.88it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  84%|▊| 1716/2039 [04:51<00:54,  5.88it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:  84%|▊| 1719/2039 [04:51<00:54,  5.89it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  84%|▊| 1722/2039 [04:51<00:53,  5.90it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1725/2039 [04:52<00:53,  5.91it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1728/2039 [04:52<00:52,  5.91it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1731/2039 [04:52<00:52,  5.92it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1734/2039 [04:52<00:51,  5.93it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1737/2039 [04:52<00:50,  5.94it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1740/2039 [04:52<00:50,  5.94it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  85%|▊| 1743/2039 [04:52<00:49,  5.95it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  86%|▊| 1746/2039 [04:52<00:49,  5.96it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  86%|▊| 1749/2039 [04:53<00:48,  5.97it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  86%|▊| 1752/2039 [04:53<00:48,  5.98it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  86%|▊| 1755/2039 [04:53<00:47,  5.98it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  86%|▊| 1758/2039 [04:53<00:46,  5.99it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  86%|▊| 1761/2039 [04:53<00:46,  6.00it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1764/2039 [04:53<00:45,  6.01it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1767/2039 [04:53<00:45,  6.01it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1770/2039 [04:54<00:44,  6.02it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1773/2039 [04:54<00:44,  6.03it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1776/2039 [04:54<00:43,  6.04it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1779/2039 [04:54<00:43,  6.04it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  87%|▊| 1782/2039 [04:54<00:42,  6.05it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1785/2039 [04:54<00:41,  6.06it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1788/2039 [04:54<00:41,  6.07it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1791/2039 [04:54<00:40,  6.07it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1794/2039 [04:55<00:40,  6.08it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1797/2039 [04:55<00:39,  6.09it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1800/2039 [04:55<00:39,  6.10it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  88%|▉| 1803/2039 [04:55<00:38,  6.10it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1806/2039 [04:55<00:38,  6.11it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1809/2039 [04:55<00:37,  6.12it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1812/2039 [04:55<00:37,  6.13it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1815/2039 [04:55<00:36,  6.13it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1818/2039 [04:56<00:35,  6.14it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1821/2039 [04:56<00:35,  6.15it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  89%|▉| 1824/2039 [04:56<00:34,  6.16it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1827/2039 [04:56<00:34,  6.16it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1830/2039 [04:56<00:33,  6.17it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1833/2039 [04:56<00:33,  6.18it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1836/2039 [04:56<00:32,  6.19it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1839/2039 [04:56<00:32,  6.19it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1842/2039 [04:57<00:31,  6.20it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  90%|▉| 1845/2039 [04:57<00:31,  6.21it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  91%|▉| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  91%|▉| 1851/2039 [04:57<00:30,  6.22it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  91%|▉| 1854/2039 [04:57<00:29,  6.23it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  91%|▉| 1857/2039 [04:57<00:29,  6.24it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  91%|▉| 1860/2039 [04:57<00:28,  6.24it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  91%|▉| 1863/2039 [04:58<00:28,  6.25it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1866/2039 [04:58<00:27,  6.26it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1869/2039 [04:58<00:27,  6.27it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1872/2039 [04:58<00:26,  6.27it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1875/2039 [04:58<00:26,  6.28it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1878/2039 [04:58<00:25,  6.29it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1881/2039 [04:58<00:25,  6.30it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  92%|▉| 1884/2039 [04:58<00:24,  6.30it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1887/2039 [04:59<00:24,  6.31it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1890/2039 [04:59<00:23,  6.32it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1896/2039 [04:59<00:22,  6.33it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1899/2039 [04:59<00:22,  6.34it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1902/2039 [04:59<00:21,  6.35it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  93%|▉| 1905/2039 [04:59<00:21,  6.35it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  94%|▉| 1908/2039 [04:59<00:20,  6.36it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  94%|▉| 1911/2039 [05:00<00:20,  6.37it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  94%|▉| 1914/2039 [05:00<00:19,  6.38it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:  94%|▉| 1917/2039 [05:00<00:19,  6.38it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  94%|▉| 1920/2039 [05:00<00:18,  6.39it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  94%|▉| 1923/2039 [05:00<00:18,  6.40it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  94%|▉| 1926/2039 [05:00<00:17,  6.40it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1929/2039 [05:00<00:17,  6.41it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1932/2039 [05:01<00:16,  6.42it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1935/2039 [05:01<00:16,  6.43it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1938/2039 [05:01<00:15,  6.43it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1941/2039 [05:01<00:15,  6.44it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1944/2039 [05:01<00:14,  6.45it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  95%|▉| 1947/2039 [05:01<00:14,  6.45it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  96%|▉| 1950/2039 [05:01<00:13,  6.46it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  96%|▉| 1953/2039 [05:01<00:13,  6.47it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  96%|▉| 1956/2039 [05:02<00:12,  6.48it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  96%|▉| 1959/2039 [05:02<00:12,  6.48it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  96%|▉| 1962/2039 [05:02<00:11,  6.49it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  96%|▉| 1965/2039 [05:02<00:11,  6.50it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1971/2039 [05:02<00:10,  6.51it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1974/2039 [05:02<00:09,  6.52it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1977/2039 [05:02<00:09,  6.53it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1980/2039 [05:03<00:09,  6.53it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1983/2039 [05:03<00:08,  6.54it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  97%|▉| 1986/2039 [05:03<00:08,  6.55it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 1989/2039 [05:03<00:07,  6.55it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 1992/2039 [05:03<00:07,  6.56it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 1995/2039 [05:03<00:06,  6.57it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 1998/2039 [05:03<00:06,  6.58it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 2001/2039 [05:03<00:05,  6.58it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 2004/2039 [05:04<00:05,  6.59it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  98%|▉| 2007/2039 [05:04<00:04,  6.60it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2010/2039 [05:04<00:04,  6.60it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2013/2039 [05:04<00:03,  6.61it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2016/2039 [05:04<00:03,  6.62it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2019/2039 [05:04<00:03,  6.62it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2022/2039 [05:04<00:02,  6.63it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2025/2039 [05:05<00:02,  6.64it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30:  99%|▉| 2028/2039 [05:05<00:01,  6.65it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30: 100%|▉| 2031/2039 [05:05<00:01,  6.65it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30: 100%|▉| 2034/2039 [05:05<00:00,  6.66it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30: 100%|▉| 2037/2039 [05:05<00:00,  6.67it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000703]\u001b[A\n",
      "Epoch 30: 100%|█| 2039/2039 [05:05<00:00,  6.67it/s, loss=0.000352, v_num=logs, train_loss=0.000448, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  80%|▊| 1632/2039 [04:48<01:11,  5.66it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  80%|▊| 1635/2039 [04:48<01:11,  5.67it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  80%|▊| 1638/2039 [04:48<01:10,  5.68it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  80%|▊| 1641/2039 [04:48<01:10,  5.69it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  81%|▊| 1644/2039 [04:48<01:09,  5.69it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  81%|▊| 1647/2039 [04:48<01:08,  5.70it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  81%|▊| 1650/2039 [04:49<01:08,  5.71it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  81%|▊| 1653/2039 [04:49<01:07,  5.72it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  81%|▊| 1656/2039 [04:49<01:06,  5.72it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  81%|▊| 1659/2039 [04:49<01:06,  5.73it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1665/2039 [04:49<01:05,  5.75it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1668/2039 [04:49<01:04,  5.76it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1671/2039 [04:49<01:03,  5.76it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1674/2039 [04:50<01:03,  5.77it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1677/2039 [04:50<01:02,  5.78it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  82%|▊| 1680/2039 [04:50<01:02,  5.79it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  83%|▊| 1683/2039 [04:50<01:01,  5.79it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  83%|▊| 1686/2039 [04:50<01:00,  5.80it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  83%|▊| 1689/2039 [04:50<01:00,  5.81it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  83%|▊| 1692/2039 [04:50<00:59,  5.82it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  83%|▊| 1695/2039 [04:50<00:59,  5.83it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  83%|▊| 1698/2039 [04:51<00:58,  5.83it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  83%|▊| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1704/2039 [04:51<00:57,  5.85it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1707/2039 [04:51<00:56,  5.86it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1710/2039 [04:51<00:56,  5.86it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1713/2039 [04:51<00:55,  5.87it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1716/2039 [04:51<00:54,  5.88it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1719/2039 [04:52<00:54,  5.89it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  84%|▊| 1722/2039 [04:52<00:53,  5.89it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1725/2039 [04:52<00:53,  5.90it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1728/2039 [04:52<00:52,  5.91it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1731/2039 [04:52<00:52,  5.92it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1734/2039 [04:52<00:51,  5.93it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1737/2039 [04:52<00:50,  5.93it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1740/2039 [04:52<00:50,  5.94it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  85%|▊| 1743/2039 [04:53<00:49,  5.95it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  86%|▊| 1746/2039 [04:53<00:49,  5.96it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  86%|▊| 1749/2039 [04:53<00:48,  5.96it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  86%|▊| 1752/2039 [04:53<00:48,  5.97it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  86%|▊| 1755/2039 [04:53<00:47,  5.98it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  86%|▊| 1758/2039 [04:53<00:46,  5.99it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  86%|▊| 1761/2039 [04:53<00:46,  5.99it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1764/2039 [04:53<00:45,  6.00it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1767/2039 [04:54<00:45,  6.01it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1770/2039 [04:54<00:44,  6.02it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1773/2039 [04:54<00:44,  6.02it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1776/2039 [04:54<00:43,  6.03it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1779/2039 [04:54<00:43,  6.04it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  87%|▊| 1782/2039 [04:54<00:42,  6.05it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1785/2039 [04:54<00:41,  6.05it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1788/2039 [04:54<00:41,  6.06it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1791/2039 [04:55<00:40,  6.07it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1794/2039 [04:55<00:40,  6.08it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1797/2039 [04:55<00:39,  6.08it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1800/2039 [04:55<00:39,  6.09it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  88%|▉| 1803/2039 [04:55<00:38,  6.10it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1806/2039 [04:55<00:38,  6.11it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1809/2039 [04:55<00:37,  6.11it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1812/2039 [04:56<00:37,  6.12it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1815/2039 [04:56<00:36,  6.13it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1818/2039 [04:56<00:36,  6.14it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1821/2039 [04:56<00:35,  6.14it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  89%|▉| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1827/2039 [04:56<00:34,  6.16it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1830/2039 [04:56<00:33,  6.17it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1833/2039 [04:56<00:33,  6.17it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1836/2039 [04:57<00:32,  6.18it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1839/2039 [04:57<00:32,  6.19it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1842/2039 [04:57<00:31,  6.20it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  90%|▉| 1845/2039 [04:57<00:31,  6.20it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  91%|▉| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  91%|▉| 1851/2039 [04:57<00:30,  6.22it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  91%|▉| 1854/2039 [04:57<00:29,  6.22it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  91%|▉| 1857/2039 [04:57<00:29,  6.23it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  91%|▉| 1860/2039 [04:58<00:28,  6.24it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  91%|▉| 1863/2039 [04:58<00:28,  6.25it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1866/2039 [04:58<00:27,  6.25it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1869/2039 [04:58<00:27,  6.26it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1872/2039 [04:58<00:26,  6.27it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1875/2039 [04:58<00:26,  6.28it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1878/2039 [04:58<00:25,  6.28it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1881/2039 [04:59<00:25,  6.29it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  92%|▉| 1884/2039 [04:59<00:24,  6.30it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  93%|▉| 1887/2039 [04:59<00:24,  6.31it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  93%|▉| 1890/2039 [04:59<00:23,  6.31it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  93%|▉| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  93%|▉| 1896/2039 [04:59<00:22,  6.33it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  93%|▉| 1899/2039 [04:59<00:22,  6.33it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  93%|▉| 1902/2039 [04:59<00:21,  6.34it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  93%|▉| 1905/2039 [05:00<00:21,  6.35it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1908/2039 [05:00<00:20,  6.36it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1911/2039 [05:00<00:20,  6.36it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1917/2039 [05:00<00:19,  6.38it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1920/2039 [05:00<00:18,  6.39it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1923/2039 [05:00<00:18,  6.39it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  94%|▉| 1926/2039 [05:00<00:17,  6.40it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1929/2039 [05:01<00:17,  6.41it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1932/2039 [05:01<00:16,  6.41it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1935/2039 [05:01<00:16,  6.42it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1938/2039 [05:01<00:15,  6.43it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1941/2039 [05:01<00:15,  6.44it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1944/2039 [05:01<00:14,  6.44it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  95%|▉| 1947/2039 [05:01<00:14,  6.45it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  96%|▉| 1950/2039 [05:01<00:13,  6.46it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  96%|▉| 1953/2039 [05:02<00:13,  6.46it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  96%|▉| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  96%|▉| 1959/2039 [05:02<00:12,  6.48it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  96%|▉| 1962/2039 [05:02<00:11,  6.49it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  96%|▉| 1965/2039 [05:02<00:11,  6.49it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1971/2039 [05:02<00:10,  6.51it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1974/2039 [05:03<00:09,  6.51it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1977/2039 [05:03<00:09,  6.52it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1980/2039 [05:03<00:09,  6.53it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1983/2039 [05:03<00:08,  6.54it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  97%|▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 1989/2039 [05:03<00:07,  6.55it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 1992/2039 [05:03<00:07,  6.56it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 1995/2039 [05:03<00:06,  6.56it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 1998/2039 [05:04<00:06,  6.57it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 2001/2039 [05:04<00:05,  6.58it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 2004/2039 [05:04<00:05,  6.58it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  98%|▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2010/2039 [05:04<00:04,  6.60it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2013/2039 [05:04<00:03,  6.61it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2016/2039 [05:04<00:03,  6.61it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2019/2039 [05:04<00:03,  6.62it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2022/2039 [05:05<00:02,  6.63it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2025/2039 [05:05<00:02,  6.63it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31:  99%|▉| 2028/2039 [05:05<00:01,  6.64it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31: 100%|▉| 2031/2039 [05:05<00:01,  6.65it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31: 100%|▉| 2034/2039 [05:05<00:00,  6.65it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31: 100%|▉| 2037/2039 [05:05<00:00,  6.66it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000707]\u001b[A\n",
      "Epoch 31: 100%|█| 2039/2039 [05:05<00:00,  6.67it/s, loss=0.000341, v_num=logs, train_loss=0.000289, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  80%|▊| 1632/2039 [04:48<01:11,  5.66it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  80%|▊| 1635/2039 [04:48<01:11,  5.66it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  80%|▊| 1638/2039 [04:48<01:10,  5.67it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  80%|▊| 1641/2039 [04:48<01:10,  5.68it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  81%|▊| 1644/2039 [04:49<01:09,  5.69it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  81%|▊| 1647/2039 [04:49<01:08,  5.70it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  81%|▊| 1650/2039 [04:49<01:08,  5.70it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  81%|▊| 1653/2039 [04:49<01:07,  5.71it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  81%|▊| 1656/2039 [04:49<01:06,  5.72it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  81%|▊| 1659/2039 [04:49<01:06,  5.73it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1662/2039 [04:49<01:05,  5.73it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1665/2039 [04:49<01:05,  5.74it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1668/2039 [04:50<01:04,  5.75it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1671/2039 [04:50<01:03,  5.76it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1674/2039 [04:50<01:03,  5.77it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1677/2039 [04:50<01:02,  5.77it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  82%|▊| 1680/2039 [04:50<01:02,  5.78it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:  83%|▊| 1683/2039 [04:50<01:01,  5.79it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  83%|▊| 1686/2039 [04:50<01:00,  5.80it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  83%|▊| 1689/2039 [04:50<01:00,  5.80it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  83%|▊| 1692/2039 [04:51<00:59,  5.81it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  83%|▊| 1695/2039 [04:51<00:59,  5.82it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  83%|▊| 1698/2039 [04:51<00:58,  5.83it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  83%|▊| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1704/2039 [04:51<00:57,  5.84it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1707/2039 [04:51<00:56,  5.85it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1710/2039 [04:51<00:56,  5.86it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1713/2039 [04:52<00:55,  5.87it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1716/2039 [04:52<00:54,  5.87it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1719/2039 [04:52<00:54,  5.88it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  84%|▊| 1722/2039 [04:52<00:53,  5.89it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1725/2039 [04:52<00:53,  5.90it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1728/2039 [04:52<00:52,  5.90it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1731/2039 [04:52<00:52,  5.91it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1734/2039 [04:52<00:51,  5.92it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1737/2039 [04:53<00:50,  5.93it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1740/2039 [04:53<00:50,  5.93it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  85%|▊| 1743/2039 [04:53<00:49,  5.94it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  86%|▊| 1746/2039 [04:53<00:49,  5.95it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  86%|▊| 1749/2039 [04:53<00:48,  5.96it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  86%|▊| 1752/2039 [04:53<00:48,  5.96it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  86%|▊| 1755/2039 [04:53<00:47,  5.97it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  86%|▊| 1758/2039 [04:53<00:46,  5.98it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  86%|▊| 1761/2039 [04:54<00:46,  5.99it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1764/2039 [04:54<00:45,  6.00it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1767/2039 [04:54<00:45,  6.00it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1770/2039 [04:54<00:44,  6.01it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1773/2039 [04:54<00:44,  6.02it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1776/2039 [04:54<00:43,  6.03it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1779/2039 [04:54<00:43,  6.03it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  87%|▊| 1782/2039 [04:55<00:42,  6.04it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1785/2039 [04:55<00:41,  6.05it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1788/2039 [04:55<00:41,  6.06it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1791/2039 [04:55<00:40,  6.06it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1794/2039 [04:55<00:40,  6.07it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1797/2039 [04:55<00:39,  6.08it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1800/2039 [04:55<00:39,  6.09it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  88%|▉| 1803/2039 [04:55<00:38,  6.09it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1806/2039 [04:56<00:38,  6.10it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1809/2039 [04:56<00:37,  6.11it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1812/2039 [04:56<00:37,  6.12it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1815/2039 [04:56<00:36,  6.12it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1818/2039 [04:56<00:36,  6.13it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1821/2039 [04:56<00:35,  6.14it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  89%|▉| 1824/2039 [04:56<00:34,  6.14it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1827/2039 [04:56<00:34,  6.15it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1830/2039 [04:57<00:33,  6.16it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1833/2039 [04:57<00:33,  6.17it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1836/2039 [04:57<00:32,  6.17it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1839/2039 [04:57<00:32,  6.18it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1842/2039 [04:57<00:31,  6.19it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  90%|▉| 1845/2039 [04:57<00:31,  6.20it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  91%|▉| 1848/2039 [04:57<00:30,  6.20it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  91%|▉| 1851/2039 [04:58<00:30,  6.21it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  91%|▉| 1854/2039 [04:58<00:29,  6.22it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  91%|▉| 1857/2039 [04:58<00:29,  6.23it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  91%|▉| 1860/2039 [04:58<00:28,  6.23it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  91%|▉| 1863/2039 [04:58<00:28,  6.24it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  92%|▉| 1866/2039 [04:58<00:27,  6.25it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  92%|▉| 1869/2039 [04:58<00:27,  6.26it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  92%|▉| 1872/2039 [04:58<00:26,  6.26it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  92%|▉| 1875/2039 [04:59<00:26,  6.27it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  92%|▉| 1878/2039 [04:59<00:25,  6.28it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:  92%|▉| 1881/2039 [04:59<00:25,  6.28it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  92%|▉| 1884/2039 [04:59<00:24,  6.29it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1887/2039 [04:59<00:24,  6.30it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1890/2039 [04:59<00:23,  6.31it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1893/2039 [04:59<00:23,  6.31it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1896/2039 [04:59<00:22,  6.32it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1899/2039 [05:00<00:22,  6.33it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1902/2039 [05:00<00:21,  6.34it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  93%|▉| 1905/2039 [05:00<00:21,  6.34it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1908/2039 [05:00<00:20,  6.35it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1911/2039 [05:00<00:20,  6.36it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1914/2039 [05:00<00:19,  6.36it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1917/2039 [05:00<00:19,  6.37it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1920/2039 [05:00<00:18,  6.38it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1923/2039 [05:01<00:18,  6.39it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  94%|▉| 1926/2039 [05:01<00:17,  6.39it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1929/2039 [05:01<00:17,  6.40it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1932/2039 [05:01<00:16,  6.41it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1935/2039 [05:01<00:16,  6.41it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1938/2039 [05:01<00:15,  6.42it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1941/2039 [05:01<00:15,  6.43it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1944/2039 [05:02<00:14,  6.44it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  95%|▉| 1947/2039 [05:02<00:14,  6.44it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  96%|▉| 1950/2039 [05:02<00:13,  6.45it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  96%|▉| 1953/2039 [05:02<00:13,  6.46it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  96%|▉| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  96%|▉| 1959/2039 [05:02<00:12,  6.47it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  96%|▉| 1962/2039 [05:02<00:11,  6.48it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  96%|▉| 1965/2039 [05:02<00:11,  6.49it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1968/2039 [05:03<00:10,  6.49it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1971/2039 [05:03<00:10,  6.50it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1974/2039 [05:03<00:09,  6.51it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1977/2039 [05:03<00:09,  6.51it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1980/2039 [05:03<00:09,  6.52it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1983/2039 [05:03<00:08,  6.53it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  97%|▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 1989/2039 [05:04<00:07,  6.54it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 1992/2039 [05:04<00:07,  6.55it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 1995/2039 [05:04<00:06,  6.56it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 1998/2039 [05:04<00:06,  6.56it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 2001/2039 [05:04<00:05,  6.57it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 2004/2039 [05:04<00:05,  6.58it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  98%|▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2010/2039 [05:04<00:04,  6.59it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2013/2039 [05:05<00:03,  6.60it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2016/2039 [05:05<00:03,  6.61it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2019/2039 [05:05<00:03,  6.61it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2022/2039 [05:05<00:02,  6.62it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2025/2039 [05:05<00:02,  6.63it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32:  99%|▉| 2028/2039 [05:05<00:01,  6.63it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32: 100%|▉| 2031/2039 [05:05<00:01,  6.64it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32: 100%|▉| 2034/2039 [05:05<00:00,  6.65it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32: 100%|▉| 2037/2039 [05:06<00:00,  6.65it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.000672]\u001b[A\n",
      "Epoch 32: 100%|██| 2039/2039 [05:06<00:00,  6.66it/s, loss=0.000335, v_num=logs, train_loss=0.000261, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  80%|██▍| 1632/2039 [04:48<01:11,  5.66it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  80%|██▍| 1635/2039 [04:48<01:11,  5.67it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  80%|██▍| 1638/2039 [04:48<01:10,  5.67it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  80%|██▍| 1641/2039 [04:48<01:10,  5.68it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  81%|██▍| 1644/2039 [04:48<01:09,  5.69it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  81%|██▍| 1647/2039 [04:49<01:08,  5.70it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  81%|██▍| 1650/2039 [04:49<01:08,  5.71it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  81%|██▍| 1653/2039 [04:49<01:07,  5.71it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  81%|██▍| 1656/2039 [04:49<01:06,  5.72it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  81%|██▍| 1659/2039 [04:49<01:06,  5.73it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  82%|██▍| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  82%|██▍| 1665/2039 [04:49<01:05,  5.74it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  82%|██▍| 1668/2039 [04:49<01:04,  5.75it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  82%|██▍| 1671/2039 [04:50<01:03,  5.76it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  82%|██▍| 1674/2039 [04:50<01:03,  5.77it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  82%|██▍| 1677/2039 [04:50<01:02,  5.78it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  82%|██▍| 1680/2039 [04:50<01:02,  5.78it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▍| 1683/2039 [04:50<01:01,  5.79it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▍| 1686/2039 [04:50<01:00,  5.80it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▍| 1689/2039 [04:50<01:00,  5.81it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▍| 1692/2039 [04:51<00:59,  5.81it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▍| 1695/2039 [04:51<00:59,  5.82it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▍| 1698/2039 [04:51<00:58,  5.83it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  83%|██▌| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1704/2039 [04:51<00:57,  5.84it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1707/2039 [04:51<00:56,  5.85it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1710/2039 [04:51<00:56,  5.86it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1713/2039 [04:51<00:55,  5.87it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1716/2039 [04:52<00:54,  5.88it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1719/2039 [04:52<00:54,  5.88it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  84%|██▌| 1722/2039 [04:52<00:53,  5.89it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1725/2039 [04:52<00:53,  5.90it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1728/2039 [04:52<00:52,  5.91it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1731/2039 [04:52<00:52,  5.91it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1734/2039 [04:52<00:51,  5.92it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1737/2039 [04:52<00:50,  5.93it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1740/2039 [04:53<00:50,  5.94it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  85%|██▌| 1743/2039 [04:53<00:49,  5.94it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  86%|██▌| 1746/2039 [04:53<00:49,  5.95it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  86%|██▌| 1749/2039 [04:53<00:48,  5.96it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  86%|██▌| 1752/2039 [04:53<00:48,  5.97it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  86%|██▌| 1755/2039 [04:53<00:47,  5.97it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  86%|██▌| 1758/2039 [04:53<00:46,  5.98it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  86%|██▌| 1761/2039 [04:54<00:46,  5.99it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1764/2039 [04:54<00:45,  6.00it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1767/2039 [04:54<00:45,  6.00it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1770/2039 [04:54<00:44,  6.01it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1773/2039 [04:54<00:44,  6.02it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1776/2039 [04:54<00:43,  6.03it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1779/2039 [04:54<00:43,  6.03it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  87%|██▌| 1782/2039 [04:54<00:42,  6.04it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1785/2039 [04:55<00:41,  6.05it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1788/2039 [04:55<00:41,  6.06it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1791/2039 [04:55<00:40,  6.06it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1794/2039 [04:55<00:40,  6.07it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1797/2039 [04:55<00:39,  6.08it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1800/2039 [04:55<00:39,  6.09it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  88%|██▋| 1803/2039 [04:55<00:38,  6.09it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1806/2039 [04:55<00:38,  6.10it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1809/2039 [04:56<00:37,  6.11it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1812/2039 [04:56<00:37,  6.12it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1815/2039 [04:56<00:36,  6.12it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1818/2039 [04:56<00:36,  6.13it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1821/2039 [04:56<00:35,  6.14it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  89%|██▋| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1827/2039 [04:56<00:34,  6.15it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1830/2039 [04:57<00:33,  6.16it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1833/2039 [04:57<00:33,  6.17it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1836/2039 [04:57<00:32,  6.18it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1839/2039 [04:57<00:32,  6.18it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1842/2039 [04:57<00:31,  6.19it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  90%|██▋| 1845/2039 [04:57<00:31,  6.20it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  91%|██▋| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  91%|██▋| 1851/2039 [04:57<00:30,  6.21it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  91%|██▋| 1854/2039 [04:58<00:29,  6.22it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  91%|██▋| 1857/2039 [04:58<00:29,  6.23it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  91%|██▋| 1860/2039 [04:58<00:28,  6.24it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  91%|██▋| 1863/2039 [04:58<00:28,  6.24it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▋| 1866/2039 [04:58<00:27,  6.25it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▋| 1869/2039 [04:58<00:27,  6.26it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▊| 1872/2039 [04:58<00:26,  6.26it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▊| 1875/2039 [04:58<00:26,  6.27it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▊| 1878/2039 [04:59<00:25,  6.28it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▊| 1881/2039 [04:59<00:25,  6.29it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  92%|██▊| 1884/2039 [04:59<00:24,  6.29it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1887/2039 [04:59<00:24,  6.30it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1890/2039 [04:59<00:23,  6.31it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1893/2039 [04:59<00:23,  6.32it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1896/2039 [04:59<00:22,  6.32it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1899/2039 [05:00<00:22,  6.33it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1902/2039 [05:00<00:21,  6.34it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  93%|██▊| 1905/2039 [05:00<00:21,  6.34it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1908/2039 [05:00<00:20,  6.35it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1911/2039 [05:00<00:20,  6.36it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1917/2039 [05:00<00:19,  6.37it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1920/2039 [05:00<00:18,  6.38it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1923/2039 [05:01<00:18,  6.39it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  94%|██▊| 1926/2039 [05:01<00:17,  6.39it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1929/2039 [05:01<00:17,  6.40it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1932/2039 [05:01<00:16,  6.41it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1935/2039 [05:01<00:16,  6.42it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1938/2039 [05:01<00:15,  6.42it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1941/2039 [05:01<00:15,  6.43it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1944/2039 [05:01<00:14,  6.44it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  95%|██▊| 1947/2039 [05:02<00:14,  6.44it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  96%|██▊| 1950/2039 [05:02<00:13,  6.45it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  96%|██▊| 1953/2039 [05:02<00:13,  6.46it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  96%|██▉| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  96%|██▉| 1959/2039 [05:02<00:12,  6.47it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  96%|██▉| 1962/2039 [05:02<00:11,  6.48it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  96%|██▉| 1965/2039 [05:02<00:11,  6.49it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1968/2039 [05:03<00:10,  6.49it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1971/2039 [05:03<00:10,  6.50it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1974/2039 [05:03<00:09,  6.51it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1977/2039 [05:03<00:09,  6.52it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1980/2039 [05:03<00:09,  6.52it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1983/2039 [05:03<00:08,  6.53it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  97%|██▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 1989/2039 [05:03<00:07,  6.54it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 1992/2039 [05:04<00:07,  6.55it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 1995/2039 [05:04<00:06,  6.56it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 1998/2039 [05:04<00:06,  6.57it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 2001/2039 [05:04<00:05,  6.57it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 2004/2039 [05:04<00:05,  6.58it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  98%|██▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2010/2039 [05:04<00:04,  6.59it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2013/2039 [05:04<00:03,  6.60it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2016/2039 [05:05<00:03,  6.61it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2019/2039 [05:05<00:03,  6.61it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2022/2039 [05:05<00:02,  6.62it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2025/2039 [05:05<00:02,  6.63it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33:  99%|██▉| 2028/2039 [05:05<00:01,  6.64it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33: 100%|██▉| 2031/2039 [05:05<00:01,  6.64it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33: 100%|██▉| 2034/2039 [05:05<00:00,  6.65it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33: 100%|██▉| 2037/2039 [05:06<00:00,  6.66it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.00067]\u001b[A\n",
      "Epoch 33: 100%|██| 2039/2039 [05:06<00:00,  6.66it/s, loss=0.000353, v_num=logs, train_loss=0.00037, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  80%|▊| 1632/2039 [04:48<01:11,  5.66it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  80%|▊| 1635/2039 [04:48<01:11,  5.66it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  80%|▊| 1638/2039 [04:48<01:10,  5.67it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  80%|▊| 1641/2039 [04:48<01:10,  5.68it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  81%|▊| 1644/2039 [04:49<01:09,  5.69it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:  81%|▊| 1647/2039 [04:49<01:08,  5.70it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  81%|▊| 1650/2039 [04:49<01:08,  5.70it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  81%|▊| 1653/2039 [04:49<01:07,  5.71it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  81%|▊| 1656/2039 [04:49<01:06,  5.72it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  81%|▊| 1659/2039 [04:49<01:06,  5.73it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1662/2039 [04:49<01:05,  5.74it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1665/2039 [04:49<01:05,  5.74it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1668/2039 [04:50<01:04,  5.75it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1671/2039 [04:50<01:03,  5.76it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1674/2039 [04:50<01:03,  5.77it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1677/2039 [04:50<01:02,  5.77it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  82%|▊| 1680/2039 [04:50<01:02,  5.78it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1683/2039 [04:50<01:01,  5.79it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1686/2039 [04:50<01:00,  5.80it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1689/2039 [04:50<01:00,  5.80it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1692/2039 [04:51<00:59,  5.81it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1695/2039 [04:51<00:59,  5.82it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1698/2039 [04:51<00:58,  5.83it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  83%|▊| 1701/2039 [04:51<00:57,  5.84it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1704/2039 [04:51<00:57,  5.84it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1707/2039 [04:51<00:56,  5.85it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1710/2039 [04:51<00:56,  5.86it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1713/2039 [04:52<00:55,  5.87it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1716/2039 [04:52<00:54,  5.87it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1719/2039 [04:52<00:54,  5.88it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  84%|▊| 1722/2039 [04:52<00:53,  5.89it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1725/2039 [04:52<00:53,  5.90it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1728/2039 [04:52<00:52,  5.90it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1731/2039 [04:52<00:52,  5.91it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1734/2039 [04:52<00:51,  5.92it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1737/2039 [04:53<00:50,  5.93it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1740/2039 [04:53<00:50,  5.94it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  85%|▊| 1743/2039 [04:53<00:49,  5.94it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  86%|▊| 1746/2039 [04:53<00:49,  5.95it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  86%|▊| 1749/2039 [04:53<00:48,  5.96it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  86%|▊| 1752/2039 [04:53<00:48,  5.97it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  86%|▊| 1755/2039 [04:53<00:47,  5.97it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  86%|▊| 1758/2039 [04:53<00:46,  5.98it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  86%|▊| 1761/2039 [04:54<00:46,  5.99it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1764/2039 [04:54<00:45,  6.00it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1767/2039 [04:54<00:45,  6.00it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1770/2039 [04:54<00:44,  6.01it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1773/2039 [04:54<00:44,  6.02it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1776/2039 [04:54<00:43,  6.03it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1779/2039 [04:54<00:43,  6.03it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  87%|▊| 1782/2039 [04:54<00:42,  6.04it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1785/2039 [04:55<00:41,  6.05it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1788/2039 [04:55<00:41,  6.06it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1791/2039 [04:55<00:40,  6.06it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1794/2039 [04:55<00:40,  6.07it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1797/2039 [04:55<00:39,  6.08it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1800/2039 [04:55<00:39,  6.09it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  88%|▉| 1803/2039 [04:55<00:38,  6.09it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1806/2039 [04:56<00:38,  6.10it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1809/2039 [04:56<00:37,  6.11it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1812/2039 [04:56<00:37,  6.12it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1815/2039 [04:56<00:36,  6.12it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1818/2039 [04:56<00:36,  6.13it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1821/2039 [04:56<00:35,  6.14it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  89%|▉| 1824/2039 [04:56<00:34,  6.15it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  90%|▉| 1827/2039 [04:56<00:34,  6.15it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  90%|▉| 1830/2039 [04:57<00:33,  6.16it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  90%|▉| 1833/2039 [04:57<00:33,  6.17it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  90%|▉| 1836/2039 [04:57<00:32,  6.18it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  90%|▉| 1839/2039 [04:57<00:32,  6.18it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  90%|▉| 1842/2039 [04:57<00:31,  6.19it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:  90%|▉| 1845/2039 [04:57<00:31,  6.20it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  91%|▉| 1848/2039 [04:57<00:30,  6.21it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  91%|▉| 1851/2039 [04:57<00:30,  6.21it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  91%|▉| 1854/2039 [04:58<00:29,  6.22it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  91%|▉| 1857/2039 [04:58<00:29,  6.23it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  91%|▉| 1860/2039 [04:58<00:28,  6.23it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  91%|▉| 1863/2039 [04:58<00:28,  6.24it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1866/2039 [04:58<00:27,  6.25it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1869/2039 [04:58<00:27,  6.26it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1872/2039 [04:58<00:26,  6.26it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1875/2039 [04:58<00:26,  6.27it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1878/2039 [04:59<00:25,  6.28it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1881/2039 [04:59<00:25,  6.29it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  92%|▉| 1884/2039 [04:59<00:24,  6.29it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1887/2039 [04:59<00:24,  6.30it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1890/2039 [04:59<00:23,  6.31it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1893/2039 [04:59<00:23,  6.31it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1896/2039 [04:59<00:22,  6.32it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1899/2039 [05:00<00:22,  6.33it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1902/2039 [05:00<00:21,  6.34it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  93%|▉| 1905/2039 [05:00<00:21,  6.34it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1908/2039 [05:00<00:20,  6.35it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1911/2039 [05:00<00:20,  6.36it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1914/2039 [05:00<00:19,  6.37it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1917/2039 [05:00<00:19,  6.37it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1920/2039 [05:00<00:18,  6.38it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1923/2039 [05:01<00:18,  6.39it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  94%|▉| 1926/2039 [05:01<00:17,  6.39it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1929/2039 [05:01<00:17,  6.40it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1932/2039 [05:01<00:16,  6.41it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1935/2039 [05:01<00:16,  6.42it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1938/2039 [05:01<00:15,  6.42it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1941/2039 [05:01<00:15,  6.43it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1944/2039 [05:01<00:14,  6.44it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  95%|▉| 1947/2039 [05:02<00:14,  6.45it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  96%|▉| 1950/2039 [05:02<00:13,  6.45it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  96%|▉| 1953/2039 [05:02<00:13,  6.46it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  96%|▉| 1956/2039 [05:02<00:12,  6.47it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  96%|▉| 1959/2039 [05:02<00:12,  6.47it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  96%|▉| 1962/2039 [05:02<00:11,  6.48it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  96%|▉| 1965/2039 [05:02<00:11,  6.49it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1968/2039 [05:02<00:10,  6.50it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1971/2039 [05:03<00:10,  6.50it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1974/2039 [05:03<00:09,  6.51it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1977/2039 [05:03<00:09,  6.52it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1980/2039 [05:03<00:09,  6.52it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1983/2039 [05:03<00:08,  6.53it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  97%|▉| 1986/2039 [05:03<00:08,  6.54it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 1989/2039 [05:03<00:07,  6.54it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 1992/2039 [05:04<00:07,  6.55it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 1995/2039 [05:04<00:06,  6.56it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 1998/2039 [05:04<00:06,  6.57it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 2001/2039 [05:04<00:05,  6.57it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 2004/2039 [05:04<00:05,  6.58it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  98%|▉| 2007/2039 [05:04<00:04,  6.59it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2010/2039 [05:04<00:04,  6.59it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2013/2039 [05:04<00:03,  6.60it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2016/2039 [05:05<00:03,  6.61it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2019/2039 [05:05<00:03,  6.62it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2022/2039 [05:05<00:02,  6.62it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2025/2039 [05:05<00:02,  6.63it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34:  99%|▉| 2028/2039 [05:05<00:01,  6.64it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34: 100%|▉| 2031/2039 [05:05<00:01,  6.64it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34: 100%|▉| 2034/2039 [05:05<00:00,  6.65it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34: 100%|▉| 2037/2039 [05:05<00:00,  6.66it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000648]\u001b[A\n",
      "Epoch 34: 100%|█| 2039/2039 [05:06<00:00,  6.66it/s, loss=0.000359, v_num=logs, train_loss=0.000329, val_loss=0.000647]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  80%|▊| 1632/2039 [04:47<01:11,  5.69it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  80%|▊| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  81%|▊| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  81%|▊| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  81%|▊| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  81%|▊| 1659/2039 [04:48<01:06,  5.76it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1674/2039 [04:48<01:02,  5.79it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1713/2039 [04:50<00:55,  5.90it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  84%|▊| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1725/2039 [04:51<00:52,  5.93it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  86%|▊| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  86%|▊| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1764/2039 [04:52<00:45,  6.03it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1776/2039 [04:53<00:43,  6.06it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1788/2039 [04:53<00:41,  6.09it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1791/2039 [04:53<00:40,  6.09it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1800/2039 [04:54<00:39,  6.12it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1812/2039 [04:54<00:36,  6.15it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1815/2039 [04:54<00:36,  6.15it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  89%|▉| 1824/2039 [04:55<00:34,  6.18it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  90%|▉| 1836/2039 [04:55<00:32,  6.21it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  91%|▉| 1860/2039 [04:56<00:28,  6.26it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  91%|▉| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1881/2039 [04:57<00:25,  6.32it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  92%|▉| 1884/2039 [04:57<00:24,  6.32it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1893/2039 [04:58<00:23,  6.35it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  93%|▉| 1905/2039 [04:58<00:21,  6.37it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1908/2039 [04:58<00:20,  6.38it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  94%|▉| 1926/2039 [04:59<00:17,  6.43it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  95%|▉| 1947/2039 [05:00<00:14,  6.48it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  96%|▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  96%|▉| 1956/2039 [05:01<00:12,  6.50it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 2001/2039 [05:02<00:05,  6.60it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  99%|▉| 2010/2039 [05:03<00:04,  6.63it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  99%|▉| 2022/2039 [05:03<00:02,  6.65it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  99%|▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000647]\u001b[A\n",
      "Epoch 35: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000329, v_num=logs, train_loss=0.000349, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  80%|█▌| 1632/2039 [04:46<01:11,  5.69it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  80%|█▌| 1635/2039 [04:47<01:10,  5.70it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  80%|█▌| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  80%|█▌| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  81%|█▌| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  81%|█▌| 1647/2039 [04:47<01:08,  5.73it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  81%|█▌| 1650/2039 [04:47<01:07,  5.74it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  81%|█▌| 1653/2039 [04:47<01:07,  5.74it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  81%|█▌| 1656/2039 [04:47<01:06,  5.75it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  81%|█▋| 1659/2039 [04:48<01:05,  5.76it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1662/2039 [04:48<01:05,  5.77it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1674/2039 [04:48<01:02,  5.80it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1677/2039 [04:48<01:02,  5.81it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  82%|█▋| 1680/2039 [04:48<01:01,  5.81it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1689/2039 [04:49<00:59,  5.84it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  83%|█▋| 1701/2039 [04:49<00:57,  5.87it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1704/2039 [04:50<00:57,  5.88it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1713/2039 [04:50<00:55,  5.90it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1716/2039 [04:50<00:54,  5.91it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  84%|█▋| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1725/2039 [04:50<00:52,  5.93it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1728/2039 [04:51<00:52,  5.94it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1740/2039 [04:51<00:50,  5.97it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  85%|█▋| 1743/2039 [04:51<00:49,  5.98it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  86%|█▋| 1746/2039 [04:51<00:48,  5.98it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  86%|█▋| 1749/2039 [04:51<00:48,  5.99it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  86%|█▋| 1752/2039 [04:52<00:47,  6.00it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  86%|█▋| 1755/2039 [04:52<00:47,  6.01it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  86%|█▋| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  86%|█▋| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1764/2039 [04:52<00:45,  6.03it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1767/2039 [04:52<00:45,  6.04it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1770/2039 [04:52<00:44,  6.04it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1773/2039 [04:52<00:43,  6.05it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1776/2039 [04:53<00:43,  6.06it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1779/2039 [04:53<00:42,  6.07it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  87%|█▋| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1788/2039 [04:53<00:41,  6.09it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1791/2039 [04:53<00:40,  6.10it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1794/2039 [04:53<00:40,  6.10it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1800/2039 [04:54<00:39,  6.12it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  88%|█▊| 1803/2039 [04:54<00:38,  6.13it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  89%|█▊| 1806/2039 [04:54<00:37,  6.13it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:  89%|█▊| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  89%|█▊| 1812/2039 [04:54<00:36,  6.15it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  89%|█▊| 1815/2039 [04:54<00:36,  6.16it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  89%|█▊| 1818/2039 [04:54<00:35,  6.16it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  89%|█▊| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  89%|█▊| 1824/2039 [04:55<00:34,  6.18it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1827/2039 [04:55<00:34,  6.19it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1836/2039 [04:55<00:32,  6.21it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1839/2039 [04:55<00:32,  6.22it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1842/2039 [04:55<00:31,  6.22it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  90%|█▊| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  91%|█▊| 1848/2039 [04:56<00:30,  6.24it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  91%|█▊| 1851/2039 [04:56<00:30,  6.25it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  91%|█▊| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  91%|█▊| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  91%|█▊| 1860/2039 [04:56<00:28,  6.27it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  91%|█▊| 1863/2039 [04:56<00:28,  6.27it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1872/2039 [04:57<00:26,  6.30it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1881/2039 [04:57<00:25,  6.32it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  92%|█▊| 1884/2039 [04:57<00:24,  6.33it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1887/2039 [04:57<00:23,  6.33it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1893/2039 [04:58<00:22,  6.35it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1896/2039 [04:58<00:22,  6.36it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  93%|█▊| 1905/2039 [04:58<00:21,  6.38it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▊| 1908/2039 [04:58<00:20,  6.38it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▊| 1911/2039 [04:58<00:20,  6.39it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▉| 1917/2039 [04:59<00:19,  6.41it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  94%|█▉| 1926/2039 [04:59<00:17,  6.43it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1929/2039 [04:59<00:17,  6.44it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1932/2039 [04:59<00:16,  6.44it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1938/2039 [05:00<00:15,  6.46it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  95%|█▉| 1947/2039 [05:00<00:14,  6.48it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  96%|█▉| 1950/2039 [05:00<00:13,  6.49it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  96%|█▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  96%|█▉| 1956/2039 [05:00<00:12,  6.50it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  96%|█▉| 1959/2039 [05:01<00:12,  6.51it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  96%|█▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  96%|█▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1971/2039 [05:01<00:10,  6.54it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1980/2039 [05:01<00:08,  6.56it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  97%|█▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  98%|█▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  98%|█▉| 1992/2039 [05:02<00:07,  6.59it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  98%|█▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  98%|█▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  98%|█▉| 2001/2039 [05:02<00:05,  6.61it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  98%|█▉| 2004/2039 [05:02<00:05,  6.61it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:  98%|█▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2010/2039 [05:03<00:04,  6.63it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2013/2039 [05:03<00:03,  6.64it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2022/2039 [05:03<00:02,  6.66it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2025/2039 [05:03<00:02,  6.66it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36:  99%|█▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36: 100%|█▉| 2031/2039 [05:04<00:01,  6.68it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36: 100%|█▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36: 100%|█▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000653]\u001b[A\n",
      "Epoch 36: 100%|██| 2039/2039 [05:04<00:00,  6.70it/s, loss=0.000299, v_num=logs, train_loss=0.00021, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  80%|▊| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  80%|▊| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  81%|▊| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  81%|▊| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  81%|▊| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  81%|▊| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1674/2039 [04:48<01:03,  5.79it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  83%|▊| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  84%|▊| 1722/2039 [04:51<00:53,  5.92it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1725/2039 [04:51<00:52,  5.92it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  86%|▊| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  86%|▊| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  86%|▊| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  88%|▉| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  88%|▉| 1791/2039 [04:53<00:40,  6.09it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  88%|▉| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  88%|▉| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  89%|▉| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1836/2039 [04:55<00:32,  6.20it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  91%|▉| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  91%|▉| 1860/2039 [04:56<00:28,  6.26it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  91%|▉| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  92%|▉| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  93%|▉| 1905/2039 [04:58<00:21,  6.37it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  94%|▉| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  95%|▉| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  96%|▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  96%|▉| 1956/2039 [05:01<00:12,  6.50it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  96%|▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1977/2039 [05:02<00:09,  6.55it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  98%|▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  98%|▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2022/2039 [05:03<00:02,  6.65it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37: 100%|▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000658]\u001b[A\n",
      "Epoch 37: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000318, v_num=logs, train_loss=0.000265, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  80%|▊| 1632/2039 [04:46<01:11,  5.69it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  80%|▊| 1635/2039 [04:47<01:10,  5.70it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  81%|▊| 1647/2039 [04:47<01:08,  5.73it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  81%|▊| 1650/2039 [04:47<01:07,  5.74it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  81%|▊| 1653/2039 [04:47<01:07,  5.74it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  81%|▊| 1656/2039 [04:47<01:06,  5.75it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  81%|▊| 1659/2039 [04:48<01:05,  5.76it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1662/2039 [04:48<01:05,  5.77it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1674/2039 [04:48<01:02,  5.80it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1677/2039 [04:48<01:02,  5.81it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  82%|▊| 1680/2039 [04:48<01:01,  5.81it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1689/2039 [04:49<00:59,  5.84it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  83%|▊| 1701/2039 [04:49<00:57,  5.87it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1704/2039 [04:50<00:57,  5.88it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1713/2039 [04:50<00:55,  5.90it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1716/2039 [04:50<00:54,  5.91it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  84%|▊| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1725/2039 [04:50<00:52,  5.93it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1728/2039 [04:51<00:52,  5.94it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1740/2039 [04:51<00:50,  5.97it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  85%|▊| 1743/2039 [04:51<00:49,  5.98it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  86%|▊| 1746/2039 [04:51<00:48,  5.98it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  86%|▊| 1749/2039 [04:51<00:48,  5.99it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  86%|▊| 1752/2039 [04:52<00:47,  6.00it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  86%|▊| 1755/2039 [04:52<00:47,  6.01it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  87%|▊| 1764/2039 [04:52<00:45,  6.03it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  87%|▊| 1767/2039 [04:52<00:45,  6.04it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  87%|▊| 1770/2039 [04:52<00:44,  6.04it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  87%|▊| 1776/2039 [04:53<00:43,  6.06it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  87%|▊| 1779/2039 [04:53<00:42,  6.07it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1788/2039 [04:53<00:41,  6.09it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1791/2039 [04:53<00:40,  6.10it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1794/2039 [04:53<00:40,  6.10it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1800/2039 [04:54<00:39,  6.12it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  88%|▉| 1803/2039 [04:54<00:38,  6.13it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1806/2039 [04:54<00:37,  6.13it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1812/2039 [04:54<00:36,  6.15it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1815/2039 [04:54<00:36,  6.16it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1818/2039 [04:54<00:35,  6.16it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  89%|▉| 1824/2039 [04:55<00:34,  6.18it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1827/2039 [04:55<00:34,  6.19it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1836/2039 [04:55<00:32,  6.21it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1839/2039 [04:55<00:32,  6.22it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1842/2039 [04:55<00:31,  6.22it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  91%|▉| 1848/2039 [04:56<00:30,  6.24it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  91%|▉| 1851/2039 [04:56<00:30,  6.25it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  91%|▉| 1860/2039 [04:56<00:28,  6.27it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  91%|▉| 1863/2039 [04:56<00:28,  6.28it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1872/2039 [04:57<00:26,  6.30it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1881/2039 [04:57<00:25,  6.32it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  92%|▉| 1884/2039 [04:57<00:24,  6.33it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1887/2039 [04:57<00:23,  6.33it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1893/2039 [04:58<00:22,  6.35it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1896/2039 [04:58<00:22,  6.36it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  93%|▉| 1905/2039 [04:58<00:21,  6.38it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1908/2039 [04:58<00:20,  6.38it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1911/2039 [04:58<00:20,  6.39it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1917/2039 [04:59<00:19,  6.41it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  94%|▉| 1926/2039 [04:59<00:17,  6.43it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1929/2039 [04:59<00:17,  6.44it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1932/2039 [04:59<00:16,  6.44it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1938/2039 [05:00<00:15,  6.46it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  95%|▉| 1947/2039 [05:00<00:14,  6.48it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  96%|▉| 1950/2039 [05:00<00:13,  6.49it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  96%|▉| 1956/2039 [05:00<00:12,  6.50it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  96%|▉| 1959/2039 [05:01<00:12,  6.51it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  97%|▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:  97%|▉| 1971/2039 [05:01<00:10,  6.54it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  97%|▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  97%|▉| 1980/2039 [05:01<00:08,  6.56it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 1992/2039 [05:02<00:07,  6.59it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 2001/2039 [05:02<00:05,  6.61it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 2004/2039 [05:02<00:05,  6.61it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2010/2039 [05:03<00:04,  6.63it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2013/2039 [05:03<00:03,  6.64it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2022/2039 [05:03<00:02,  6.66it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2025/2039 [05:03<00:02,  6.66it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38: 100%|▉| 2031/2039 [05:04<00:01,  6.68it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000632]\u001b[A\n",
      "Epoch 38: 100%|█| 2039/2039 [05:04<00:00,  6.70it/s, loss=0.000297, v_num=logs, train_loss=0.000285, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  80%|▊| 1632/2039 [04:46<01:11,  5.69it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  80%|▊| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  81%|▊| 1647/2039 [04:47<01:08,  5.73it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  81%|▊| 1653/2039 [04:47<01:07,  5.74it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  81%|▊| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  81%|▊| 1659/2039 [04:48<01:06,  5.76it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1674/2039 [04:48<01:02,  5.80it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1677/2039 [04:48<01:02,  5.80it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1689/2039 [04:49<00:59,  5.84it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  83%|▊| 1701/2039 [04:49<00:57,  5.87it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1713/2039 [04:50<00:55,  5.90it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  84%|▊| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1725/2039 [04:51<00:52,  5.93it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1728/2039 [04:51<00:52,  5.94it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1740/2039 [04:51<00:50,  5.97it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  86%|▊| 1746/2039 [04:51<00:48,  5.98it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  86%|▊| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  86%|▊| 1752/2039 [04:52<00:47,  6.00it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1764/2039 [04:52<00:45,  6.03it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1770/2039 [04:52<00:44,  6.04it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1776/2039 [04:53<00:43,  6.06it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1788/2039 [04:53<00:41,  6.09it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1791/2039 [04:53<00:40,  6.09it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1794/2039 [04:53<00:40,  6.10it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1800/2039 [04:54<00:39,  6.12it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1806/2039 [04:54<00:37,  6.13it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1812/2039 [04:54<00:36,  6.15it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1815/2039 [04:54<00:36,  6.16it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  89%|▉| 1824/2039 [04:55<00:34,  6.18it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1836/2039 [04:55<00:32,  6.21it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1839/2039 [04:55<00:32,  6.21it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  91%|▉| 1848/2039 [04:56<00:30,  6.24it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  91%|▉| 1860/2039 [04:56<00:28,  6.27it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  91%|▉| 1863/2039 [04:56<00:28,  6.27it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1872/2039 [04:57<00:26,  6.30it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1881/2039 [04:57<00:25,  6.32it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  92%|▉| 1884/2039 [04:57<00:24,  6.33it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1887/2039 [04:57<00:24,  6.33it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1893/2039 [04:58<00:23,  6.35it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  93%|▉| 1905/2039 [04:58<00:21,  6.38it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1908/2039 [04:58<00:20,  6.38it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1917/2039 [04:59<00:19,  6.41it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  94%|▉| 1926/2039 [04:59<00:17,  6.43it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1932/2039 [04:59<00:16,  6.44it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1938/2039 [05:00<00:15,  6.46it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  95%|▉| 1947/2039 [05:00<00:14,  6.48it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  96%|▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  96%|▉| 1956/2039 [05:00<00:12,  6.50it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  96%|▉| 1959/2039 [05:01<00:12,  6.51it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1971/2039 [05:01<00:10,  6.54it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1980/2039 [05:01<00:08,  6.56it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 1992/2039 [05:02<00:07,  6.59it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 2001/2039 [05:02<00:05,  6.61it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2010/2039 [05:03<00:04,  6.63it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2022/2039 [05:03<00:02,  6.66it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2025/2039 [05:03<00:02,  6.66it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39: 100%|▉| 2031/2039 [05:04<00:01,  6.68it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.000639]\u001b[A\n",
      "Epoch 39: 100%|██| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000323, v_num=logs, train_loss=0.000359, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  80%|██▍| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  80%|██▍| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  80%|██▍| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  80%|██▍| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  81%|██▍| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  81%|██▍| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  81%|██▍| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  81%|██▍| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  81%|██▍| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  81%|██▍| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1671/2039 [04:48<01:03,  5.78it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  82%|██▍| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▍| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▍| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▍| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▍| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▍| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▍| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  83%|██▌| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  84%|██▌| 1722/2039 [04:51<00:53,  5.92it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  85%|██▌| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  85%|██▌| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  85%|██▌| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  85%|██▌| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:  85%|██▌| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  85%|██▌| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  85%|██▌| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  86%|██▌| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  86%|██▌| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  86%|██▌| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  86%|██▌| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  86%|██▌| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  86%|██▌| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1773/2039 [04:53<00:44,  6.05it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  87%|██▌| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  88%|██▋| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  89%|██▋| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1833/2039 [04:55<00:33,  6.19it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  90%|██▋| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  91%|██▋| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  91%|██▋| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  91%|██▋| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  91%|██▋| 1857/2039 [04:56<00:29,  6.25it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  91%|██▋| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  91%|██▋| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▋| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▋| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▊| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▊| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▊| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▊| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  92%|██▊| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1902/2039 [04:58<00:21,  6.36it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  93%|██▊| 1905/2039 [04:58<00:21,  6.37it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1923/2039 [04:59<00:18,  6.41it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  94%|██▊| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  95%|██▊| 1929/2039 [05:00<00:17,  6.43it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  95%|██▊| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:  95%|██▊| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  95%|██▊| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  95%|██▊| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  95%|██▊| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  95%|██▊| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  96%|██▊| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  96%|██▊| 1953/2039 [05:01<00:13,  6.49it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  96%|██▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  96%|██▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  96%|██▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  96%|██▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  97%|██▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 1998/2039 [05:02<00:06,  6.59it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  98%|██▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2019/2039 [05:03<00:03,  6.64it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2022/2039 [05:04<00:02,  6.65it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40:  99%|██▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40: 100%|██▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40: 100%|██▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40: 100%|██▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.00063]\u001b[A\n",
      "Epoch 40: 100%|██| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000301, v_num=logs, train_loss=0.00023, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  80%|▊| 1632/2039 [04:46<01:11,  5.69it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  80%|▊| 1635/2039 [04:47<01:10,  5.69it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  80%|▊| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  80%|▊| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  81%|▊| 1644/2039 [04:47<01:09,  5.72it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  81%|▊| 1647/2039 [04:47<01:08,  5.73it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  81%|▊| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  81%|▊| 1653/2039 [04:47<01:07,  5.74it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  81%|▊| 1656/2039 [04:48<01:06,  5.75it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  81%|▊| 1659/2039 [04:48<01:06,  5.76it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1662/2039 [04:48<01:05,  5.77it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1671/2039 [04:48<01:03,  5.79it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1674/2039 [04:48<01:02,  5.80it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1677/2039 [04:48<01:02,  5.80it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  82%|▊| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1686/2039 [04:49<01:00,  5.83it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1689/2039 [04:49<00:59,  5.84it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1698/2039 [04:49<00:58,  5.86it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  83%|▊| 1701/2039 [04:49<00:57,  5.87it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  84%|▊| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  84%|▊| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  84%|▊| 1710/2039 [04:50<00:55,  5.89it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  84%|▊| 1713/2039 [04:50<00:55,  5.90it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  84%|▊| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:  84%|▊| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  84%|▊| 1722/2039 [04:50<00:53,  5.92it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1725/2039 [04:51<00:52,  5.93it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1728/2039 [04:51<00:52,  5.94it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1737/2039 [04:51<00:50,  5.96it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1740/2039 [04:51<00:50,  5.97it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  85%|▊| 1743/2039 [04:51<00:49,  5.97it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  86%|▊| 1746/2039 [04:51<00:48,  5.98it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  86%|▊| 1749/2039 [04:52<00:48,  5.99it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  86%|▊| 1752/2039 [04:52<00:47,  6.00it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  86%|▊| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  86%|▊| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  86%|▊| 1761/2039 [04:52<00:46,  6.02it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1764/2039 [04:52<00:45,  6.03it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1767/2039 [04:52<00:45,  6.03it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1770/2039 [04:52<00:44,  6.04it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1773/2039 [04:53<00:43,  6.05it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1776/2039 [04:53<00:43,  6.06it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  87%|▊| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1788/2039 [04:53<00:41,  6.09it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1791/2039 [04:53<00:40,  6.09it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1794/2039 [04:53<00:40,  6.10it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1800/2039 [04:54<00:39,  6.12it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  88%|▉| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1806/2039 [04:54<00:37,  6.13it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1812/2039 [04:54<00:36,  6.15it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1815/2039 [04:54<00:36,  6.15it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  89%|▉| 1824/2039 [04:55<00:34,  6.18it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1833/2039 [04:55<00:33,  6.20it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1836/2039 [04:55<00:32,  6.21it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1839/2039 [04:55<00:32,  6.21it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  90%|▉| 1845/2039 [04:56<00:31,  6.23it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  91%|▉| 1848/2039 [04:56<00:30,  6.24it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  91%|▉| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  91%|▉| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  91%|▉| 1857/2039 [04:56<00:29,  6.26it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  91%|▉| 1860/2039 [04:56<00:28,  6.27it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  91%|▉| 1863/2039 [04:56<00:28,  6.27it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1869/2039 [04:57<00:27,  6.29it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1872/2039 [04:57<00:26,  6.30it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1881/2039 [04:57<00:25,  6.32it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  92%|▉| 1884/2039 [04:57<00:24,  6.32it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1890/2039 [04:58<00:23,  6.34it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1893/2039 [04:58<00:23,  6.35it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1902/2039 [04:58<00:21,  6.37it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  93%|▉| 1905/2039 [04:58<00:21,  6.38it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  94%|▉| 1908/2039 [04:58<00:20,  6.38it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  94%|▉| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  94%|▉| 1914/2039 [04:59<00:19,  6.40it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:  94%|▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  94%|▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  94%|▉| 1923/2039 [04:59<00:18,  6.42it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  94%|▉| 1926/2039 [04:59<00:17,  6.43it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1929/2039 [04:59<00:17,  6.43it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1932/2039 [04:59<00:16,  6.44it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1935/2039 [05:00<00:16,  6.45it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1938/2039 [05:00<00:15,  6.46it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  95%|▉| 1947/2039 [05:00<00:14,  6.48it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  96%|▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  96%|▉| 1953/2039 [05:00<00:13,  6.49it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  96%|▉| 1956/2039 [05:00<00:12,  6.50it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  96%|▉| 1959/2039 [05:01<00:12,  6.51it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  96%|▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  96%|▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1968/2039 [05:01<00:10,  6.53it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1977/2039 [05:01<00:09,  6.55it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1980/2039 [05:02<00:08,  6.56it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  97%|▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 1989/2039 [05:02<00:07,  6.58it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 1998/2039 [05:02<00:06,  6.60it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 2001/2039 [05:02<00:05,  6.61it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  98%|▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2010/2039 [05:03<00:04,  6.63it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2019/2039 [05:03<00:03,  6.65it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2022/2039 [05:03<00:02,  6.65it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2025/2039 [05:03<00:02,  6.66it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41:  99%|▉| 2028/2039 [05:04<00:01,  6.67it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41: 100%|▉| 2031/2039 [05:04<00:01,  6.68it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41: 100%|▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41: 100%|▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000588]\u001b[A\n",
      "Epoch 41: 100%|█| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000279, v_num=logs, train_loss=0.000293, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  80%|█▌| 1632/2039 [04:47<01:11,  5.68it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  80%|█▌| 1635/2039 [04:47<01:11,  5.69it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  80%|█▌| 1638/2039 [04:47<01:10,  5.70it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  80%|█▌| 1641/2039 [04:47<01:09,  5.71it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  81%|█▌| 1644/2039 [04:47<01:09,  5.71it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  81%|█▌| 1647/2039 [04:47<01:08,  5.72it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  81%|█▌| 1650/2039 [04:47<01:07,  5.73it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  81%|█▌| 1653/2039 [04:48<01:07,  5.74it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  81%|█▌| 1656/2039 [04:48<01:06,  5.74it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  81%|█▋| 1659/2039 [04:48<01:06,  5.75it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1662/2039 [04:48<01:05,  5.76it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1665/2039 [04:48<01:04,  5.77it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1668/2039 [04:48<01:04,  5.78it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1671/2039 [04:48<01:03,  5.78it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1674/2039 [04:49<01:03,  5.79it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1677/2039 [04:49<01:02,  5.80it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  82%|█▋| 1680/2039 [04:49<01:01,  5.81it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  83%|█▋| 1683/2039 [04:49<01:01,  5.82it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  83%|█▋| 1686/2039 [04:49<01:00,  5.82it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  83%|█▋| 1689/2039 [04:49<01:00,  5.83it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  83%|█▋| 1692/2039 [04:49<00:59,  5.84it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  83%|█▋| 1695/2039 [04:49<00:58,  5.85it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  83%|█▋| 1698/2039 [04:50<00:58,  5.85it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:  83%|█▋| 1701/2039 [04:50<00:57,  5.86it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1704/2039 [04:50<00:57,  5.87it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1707/2039 [04:50<00:56,  5.88it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1710/2039 [04:50<00:55,  5.88it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1713/2039 [04:50<00:55,  5.89it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1716/2039 [04:50<00:54,  5.90it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1719/2039 [04:50<00:54,  5.91it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  84%|█▋| 1722/2039 [04:51<00:53,  5.92it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1725/2039 [04:51<00:53,  5.92it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1728/2039 [04:51<00:52,  5.93it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1731/2039 [04:51<00:51,  5.94it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1734/2039 [04:51<00:51,  5.95it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1737/2039 [04:51<00:50,  5.95it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1740/2039 [04:51<00:50,  5.96it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  85%|█▋| 1743/2039 [04:52<00:49,  5.97it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  86%|█▋| 1746/2039 [04:52<00:49,  5.98it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  86%|█▋| 1749/2039 [04:52<00:48,  5.98it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  86%|█▋| 1752/2039 [04:52<00:47,  5.99it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  86%|█▋| 1755/2039 [04:52<00:47,  6.00it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  86%|█▋| 1758/2039 [04:52<00:46,  6.01it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  86%|█▋| 1761/2039 [04:52<00:46,  6.01it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1764/2039 [04:52<00:45,  6.02it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1767/2039 [04:53<00:45,  6.03it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1770/2039 [04:53<00:44,  6.04it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1773/2039 [04:53<00:44,  6.04it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1776/2039 [04:53<00:43,  6.05it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1779/2039 [04:53<00:42,  6.06it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  87%|█▋| 1782/2039 [04:53<00:42,  6.07it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1785/2039 [04:53<00:41,  6.08it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1788/2039 [04:53<00:41,  6.08it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1791/2039 [04:54<00:40,  6.09it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1794/2039 [04:54<00:40,  6.10it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1797/2039 [04:54<00:39,  6.11it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1800/2039 [04:54<00:39,  6.11it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  88%|█▊| 1803/2039 [04:54<00:38,  6.12it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1806/2039 [04:54<00:38,  6.13it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1809/2039 [04:54<00:37,  6.14it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1812/2039 [04:54<00:36,  6.14it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1815/2039 [04:55<00:36,  6.15it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1818/2039 [04:55<00:35,  6.16it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1821/2039 [04:55<00:35,  6.17it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  89%|█▊| 1824/2039 [04:55<00:34,  6.17it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1827/2039 [04:55<00:34,  6.18it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1830/2039 [04:55<00:33,  6.19it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1833/2039 [04:55<00:33,  6.19it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1836/2039 [04:56<00:32,  6.20it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1839/2039 [04:56<00:32,  6.21it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1842/2039 [04:56<00:31,  6.22it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  90%|█▊| 1845/2039 [04:56<00:31,  6.22it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  91%|█▊| 1848/2039 [04:56<00:30,  6.23it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  91%|█▊| 1851/2039 [04:56<00:30,  6.24it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  91%|█▊| 1854/2039 [04:56<00:29,  6.25it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  91%|█▊| 1857/2039 [04:56<00:29,  6.25it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  91%|█▊| 1860/2039 [04:57<00:28,  6.26it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  91%|█▊| 1863/2039 [04:57<00:28,  6.27it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1866/2039 [04:57<00:27,  6.28it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1869/2039 [04:57<00:27,  6.28it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1872/2039 [04:57<00:26,  6.29it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1875/2039 [04:57<00:26,  6.30it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1878/2039 [04:57<00:25,  6.31it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1881/2039 [04:57<00:25,  6.31it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  92%|█▊| 1884/2039 [04:58<00:24,  6.32it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  93%|█▊| 1887/2039 [04:58<00:24,  6.33it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  93%|█▊| 1890/2039 [04:58<00:23,  6.33it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  93%|█▊| 1893/2039 [04:58<00:23,  6.34it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  93%|█▊| 1896/2039 [04:58<00:22,  6.35it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:  93%|█▊| 1899/2039 [04:58<00:22,  6.36it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  93%|█▊| 1902/2039 [04:58<00:21,  6.36it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  93%|█▊| 1905/2039 [04:59<00:21,  6.37it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▊| 1908/2039 [04:59<00:20,  6.38it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▊| 1911/2039 [04:59<00:20,  6.39it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▉| 1914/2039 [04:59<00:19,  6.39it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▉| 1917/2039 [04:59<00:19,  6.40it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▉| 1920/2039 [04:59<00:18,  6.41it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▉| 1923/2039 [04:59<00:18,  6.41it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  94%|█▉| 1926/2039 [04:59<00:17,  6.42it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1929/2039 [05:00<00:17,  6.43it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1932/2039 [05:00<00:16,  6.44it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1935/2039 [05:00<00:16,  6.44it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1938/2039 [05:00<00:15,  6.45it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1941/2039 [05:00<00:15,  6.46it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1944/2039 [05:00<00:14,  6.47it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  95%|█▉| 1947/2039 [05:00<00:14,  6.47it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  96%|█▉| 1950/2039 [05:00<00:13,  6.48it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  96%|█▉| 1953/2039 [05:01<00:13,  6.49it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  96%|█▉| 1956/2039 [05:01<00:12,  6.49it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  96%|█▉| 1959/2039 [05:01<00:12,  6.50it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  96%|█▉| 1962/2039 [05:01<00:11,  6.51it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  96%|█▉| 1965/2039 [05:01<00:11,  6.52it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1968/2039 [05:01<00:10,  6.52it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1971/2039 [05:01<00:10,  6.53it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1974/2039 [05:01<00:09,  6.54it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1977/2039 [05:02<00:09,  6.54it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1980/2039 [05:02<00:09,  6.55it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1983/2039 [05:02<00:08,  6.56it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  97%|█▉| 1986/2039 [05:02<00:08,  6.57it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 1989/2039 [05:02<00:07,  6.57it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 1992/2039 [05:02<00:07,  6.58it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 1995/2039 [05:02<00:06,  6.59it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 1998/2039 [05:03<00:06,  6.59it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 2001/2039 [05:03<00:05,  6.60it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 2004/2039 [05:03<00:05,  6.61it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  98%|█▉| 2007/2039 [05:03<00:04,  6.62it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2010/2039 [05:03<00:04,  6.62it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2013/2039 [05:03<00:03,  6.63it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2016/2039 [05:03<00:03,  6.64it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2019/2039 [05:03<00:03,  6.64it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2022/2039 [05:04<00:02,  6.65it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2025/2039 [05:04<00:02,  6.66it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42:  99%|█▉| 2028/2039 [05:04<00:01,  6.66it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42: 100%|█▉| 2031/2039 [05:04<00:01,  6.67it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42: 100%|█▉| 2034/2039 [05:04<00:00,  6.68it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42: 100%|█▉| 2037/2039 [05:04<00:00,  6.69it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000587]\u001b[A\n",
      "Epoch 42: 100%|██| 2039/2039 [05:04<00:00,  6.69it/s, loss=0.000283, v_num=logs, train_loss=0.00035, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  80%|█▌| 1632/2039 [04:46<01:11,  5.70it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                              | 0/408 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  80%|█▌| 1635/2039 [04:46<01:10,  5.71it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  80%|█▌| 1638/2039 [04:46<01:10,  5.72it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  80%|█▌| 1641/2039 [04:46<01:09,  5.73it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  81%|█▌| 1644/2039 [04:46<01:08,  5.73it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  81%|█▌| 1647/2039 [04:46<01:08,  5.74it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  81%|█▌| 1650/2039 [04:46<01:07,  5.75it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  81%|█▌| 1653/2039 [04:47<01:07,  5.76it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  81%|█▌| 1656/2039 [04:47<01:06,  5.77it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  81%|█▋| 1659/2039 [04:47<01:05,  5.77it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1662/2039 [04:47<01:05,  5.78it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1665/2039 [04:47<01:04,  5.79it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1668/2039 [04:47<01:03,  5.80it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1671/2039 [04:47<01:03,  5.81it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1674/2039 [04:47<01:02,  5.81it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1677/2039 [04:48<01:02,  5.82it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  82%|█▋| 1680/2039 [04:48<01:01,  5.83it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  83%|█▋| 1683/2039 [04:48<01:00,  5.84it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  83%|█▋| 1686/2039 [04:48<01:00,  5.84it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  83%|█▋| 1689/2039 [04:48<00:59,  5.85it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  83%|█▋| 1692/2039 [04:48<00:59,  5.86it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  83%|█▋| 1695/2039 [04:48<00:58,  5.87it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  83%|█▋| 1698/2039 [04:48<00:58,  5.88it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  83%|█▋| 1701/2039 [04:49<00:57,  5.88it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1704/2039 [04:49<00:56,  5.89it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1707/2039 [04:49<00:56,  5.90it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1710/2039 [04:49<00:55,  5.91it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1713/2039 [04:49<00:55,  5.91it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1716/2039 [04:49<00:54,  5.92it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1719/2039 [04:49<00:53,  5.93it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  84%|█▋| 1722/2039 [04:50<00:53,  5.94it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1725/2039 [04:50<00:52,  5.95it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1728/2039 [04:50<00:52,  5.95it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1731/2039 [04:50<00:51,  5.96it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1734/2039 [04:50<00:51,  5.97it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1737/2039 [04:50<00:50,  5.98it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1740/2039 [04:50<00:49,  5.98it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  85%|█▋| 1743/2039 [04:50<00:49,  5.99it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  86%|█▋| 1746/2039 [04:51<00:48,  6.00it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  86%|█▋| 1749/2039 [04:51<00:48,  6.01it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  86%|█▋| 1752/2039 [04:51<00:47,  6.01it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  86%|█▋| 1755/2039 [04:51<00:47,  6.02it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  86%|█▋| 1758/2039 [04:51<00:46,  6.03it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  86%|█▋| 1761/2039 [04:51<00:46,  6.04it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1764/2039 [04:51<00:45,  6.04it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1767/2039 [04:51<00:44,  6.05it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1770/2039 [04:52<00:44,  6.06it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1773/2039 [04:52<00:43,  6.07it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1776/2039 [04:52<00:43,  6.08it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1779/2039 [04:52<00:42,  6.08it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  87%|█▋| 1782/2039 [04:52<00:42,  6.09it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1785/2039 [04:52<00:41,  6.10it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1788/2039 [04:52<00:41,  6.11it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1791/2039 [04:52<00:40,  6.11it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1794/2039 [04:53<00:40,  6.12it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1797/2039 [04:53<00:39,  6.13it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1800/2039 [04:53<00:38,  6.14it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  88%|█▊| 1803/2039 [04:53<00:38,  6.14it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1806/2039 [04:53<00:37,  6.15it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1809/2039 [04:53<00:37,  6.16it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1812/2039 [04:53<00:36,  6.17it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1815/2039 [04:54<00:36,  6.17it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1818/2039 [04:54<00:35,  6.18it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1821/2039 [04:54<00:35,  6.19it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  89%|█▊| 1824/2039 [04:54<00:34,  6.20it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1827/2039 [04:54<00:34,  6.20it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1830/2039 [04:54<00:33,  6.21it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1833/2039 [04:54<00:33,  6.22it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1836/2039 [04:54<00:32,  6.23it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1839/2039 [04:55<00:32,  6.23it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1842/2039 [04:55<00:31,  6.24it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  90%|█▊| 1845/2039 [04:55<00:31,  6.25it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  91%|█▊| 1848/2039 [04:55<00:30,  6.26it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  91%|█▊| 1851/2039 [04:55<00:30,  6.26it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  91%|█▊| 1854/2039 [04:55<00:29,  6.27it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  91%|█▊| 1857/2039 [04:55<00:28,  6.28it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  91%|█▊| 1860/2039 [04:55<00:28,  6.28it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  91%|█▊| 1863/2039 [04:56<00:27,  6.29it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  92%|█▊| 1866/2039 [04:56<00:27,  6.30it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  92%|█▊| 1869/2039 [04:56<00:26,  6.31it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  92%|█▊| 1872/2039 [04:56<00:26,  6.31it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  92%|█▊| 1875/2039 [04:56<00:25,  6.32it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  92%|█▊| 1878/2039 [04:56<00:25,  6.33it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:  92%|█▊| 1881/2039 [04:56<00:24,  6.34it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  92%|█▊| 1884/2039 [04:56<00:24,  6.34it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1887/2039 [04:57<00:23,  6.35it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1890/2039 [04:57<00:23,  6.36it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1893/2039 [04:57<00:22,  6.37it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1896/2039 [04:57<00:22,  6.37it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1899/2039 [04:57<00:21,  6.38it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1902/2039 [04:57<00:21,  6.39it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  93%|█▊| 1905/2039 [04:57<00:20,  6.40it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▊| 1908/2039 [04:58<00:20,  6.40it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▊| 1911/2039 [04:58<00:19,  6.41it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▉| 1914/2039 [04:58<00:19,  6.42it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▉| 1917/2039 [04:58<00:18,  6.42it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▉| 1920/2039 [04:58<00:18,  6.43it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▉| 1923/2039 [04:58<00:18,  6.44it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  94%|█▉| 1926/2039 [04:58<00:17,  6.45it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1929/2039 [04:58<00:17,  6.45it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1932/2039 [04:59<00:16,  6.46it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1935/2039 [04:59<00:16,  6.47it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1938/2039 [04:59<00:15,  6.47it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1941/2039 [04:59<00:15,  6.48it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1944/2039 [04:59<00:14,  6.49it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  95%|█▉| 1947/2039 [04:59<00:14,  6.50it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Epoch 43:  96%|█▉| 1950/2039 [04:59<00:13,  6.50it/s, loss=0.000278, v_num=logs, train_loss=0.00024, val_loss=0.000584]\u001b[A\n",
      "Validating:  79%|█████████████████████████████████████████████████████▌              | 321/408 [00:13<00:03, 23.12it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "model = NBEATSModel(input_chunk_length=50, output_chunk_length=60, random_state=42,\n",
    "                    torch_device_str='cuda',\n",
    "                    num_stacks=30,\n",
    "                    num_blocks=2,\n",
    "                    num_layers=4,\n",
    "                    layer_widths=256,\n",
    "                    n_epochs=1000,\n",
    "                    nr_epochs_val_period=1,\n",
    "                    batch_size=100,\n",
    "                    log_tensorboard=True,\n",
    "                    optimizer_kwargs={'lr': 1e-6},\n",
    "                   )\n",
    "\n",
    "model.fit(posX_train, past_covariates=posY_train, val_series=posX_test, val_past_covariates=posY_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(model_path)\n",
    "loaded_model = model.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05cadec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-02 10:29:51,266] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: `torch_device_str` is deprecated and will be removed in a coming Darts version. For full support of all torch devices, use PyTorch-Lightnings trainer flags and pass them inside `pl_trainer_kwargs`. Flags of interest are {`accelerator`, `gpus`, `auto_select_gpus`, `devices`}. For more information, visit https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags\n",
      "[2022-04-02 10:29:51,266] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: `torch_device_str` is deprecated and will be removed in a coming Darts version. For full support of all torch devices, use PyTorch-Lightnings trainer flags and pass them inside `pl_trainer_kwargs`. Flags of interest are {`accelerator`, `gpus`, `auto_select_gpus`, `devices`}. For more information, visit https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags\n",
      "[2022-04-02 10:29:51,299] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 9594 samples.\n",
      "[2022-04-02 10:29:51,299] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 9594 samples.\n",
      "[2022-04-02 10:29:51,316] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 32-bits; casting model to float32.\n",
      "[2022-04-02 10:29:51,316] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 32-bits; casting model to float32.\n",
      "[2022-04-02 10:29:51,317] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-04-02 10:29:51,317] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "1  | encoder_vsn                       | _VariableSelectionNetwork        | 9.8 K \n",
      "2  | decoder_vsn                       | _VariableSelectionNetwork        | 3.1 K \n",
      "3  | static_context_grn                | _GatedResidualNetwork            | 66.3 K\n",
      "4  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 66.3 K\n",
      "5  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 66.3 K\n",
      "6  | static_context_enrichment         | _GatedResidualNetwork            | 66.3 K\n",
      "7  | lstm_encoder                      | LSTM                             | 132 K \n",
      "8  | lstm_decoder                      | LSTM                             | 132 K \n",
      "9  | post_lstm_gan                     | _GateAddNorm                     | 33.3 K\n",
      "10 | static_enrichment_grn             | _GatedResidualNetwork            | 82.7 K\n",
      "11 | multihead_attn                    | _InterpretableMultiHeadAttention | 41.2 K\n",
      "12 | post_attn_gan                     | _GateAddNorm                     | 33.3 K\n",
      "13 | positionwise_feedforward_grn      | _GatedResidualNetwork            | 66.3 K\n",
      "14 | pre_output_gan                    | _GateAddNorm                     | 33.3 K\n",
      "15 | output_layer                      | Linear                           | 2.2 K \n",
      "----------------------------------------------------------------------------------------\n",
      "834 K     Trainable params\n",
      "0         Non-trainable params\n",
      "834 K     Total params\n",
      "3.338     Total estimated model params size (MB)\n",
      "C:\\Users\\sky\\anaconda3\\envs\\darts\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:433: UserWarning: The number of training samples (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156:  90%|████████████████████████████▊   | 9/10 [00:05<00:00,  1.62it/s, loss=6.2, v_num=logs, train_loss=6.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313:  50%|███████████████▌               | 5/10 [00:03<00:03,  1.45it/s, loss=5.69, v_num=logs, train_loss=5.820]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sky\\anaconda3\\envs\\darts\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<darts.models.forecasting.tft_model.TFTModel at 0x2ca723733c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default quantiles for QuantileRegression\n",
    "quantiles = [\n",
    "    0.01,\n",
    "    0.05,\n",
    "    0.1,\n",
    "    0.15,\n",
    "    0.2,\n",
    "    0.25,\n",
    "    0.3,\n",
    "    0.4,\n",
    "    0.5,\n",
    "    0.6,\n",
    "    0.7,\n",
    "    0.75,\n",
    "    0.8,\n",
    "    0.85,\n",
    "    0.9,\n",
    "    0.95,\n",
    "    0.99,\n",
    "]\n",
    "\n",
    "model = TFTModel(\n",
    "    input_chunk_length=50,\n",
    "    output_chunk_length=60,\n",
    "    torch_device_str='cuda',\n",
    "    hidden_size=128,\n",
    "    lstm_layers=1,\n",
    "    num_attention_heads=4,\n",
    "    dropout=0.1,\n",
    "    batch_size=1000,\n",
    "    n_epochs=30000,\n",
    "    add_relative_index=True,\n",
    "    add_encoders=None,\n",
    "    likelihood=QuantileRegression(\n",
    "        quantiles=quantiles\n",
    "    ),  # QuantileRegression is set per default\n",
    "    # loss_fn=MSELoss(),\n",
    "    random_state=42,\n",
    "    optimizer_kwargs={'lr': 1e-7},\n",
    "    log_tensorboard=True,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(posX_train, past_covariates=posY_train, val_series=posX_test, val_past_covariates=posY_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "193e96ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n",
      "Predicting: 67it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAFyCAYAAADLZb9oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACJ7klEQVR4nO2dd5hU5fXHP3d7b/RdOiIICgIXxE5UbFE0KvaGiSVKfrGlWWJJYkzUWGILGnvDaKyosaNUvXaRIggIQ2d7b/f3xzt35s7s9L675/M8+9zdO3fuvPPO7NzvnPM959VM00QQBEEQBEFIDGnJHoAgCIIgCEJvQsSXIAiCIAhCAhHxJQiCIAiCkEBEfAmCIAiCICQQEV+CIAiCIAgJJCPZAwiDhJRlbtu2jYEDBybioQQnMueJR+Y88cicJx6Z88Qjc+6B5u8GiXx50dHRkewh9DpkzhOPzHnikTlPPDLniUfmPDREfAmCIAiCICQQEV+CIAiCIAgJRMSXIAiCIAhCAhHxJQiCIAiCkEBEfAmCIAiCICQQEV+CIAiCIAgJRMSXIAiCIAhCAhHxJQiCIAiCkEBEfAmCIAiC0G358MMPWbJkSbKHERYivgRBEARB6LaI+BIEQRAEQYgBJ554IlOmTGH8+PHMmzcPgLfeeovJkyczceJEDj/8cDZs2MCDDz7InXfeyb777svHH3/M+eefzwsvvOA6T0FBAQD19fUcfvjhTJ48mX322YdXXnklKc8LutfC2nGnqakp2UMQBEEQhJRC0/yuDx0VpmkGvP2RRx6hrKyMpqYmpk6dygknnMCFF17IRx99xIgRI6isrKSsrIxLLrmEgoICrr76agD+/e9/+zxfTk4OL730EkVFRezatYvp06cza9asuD2/QEjky8lnn33G0KFDeeKJJ2RhUEEQBEFIMvfccw8TJ05k+vTpbNq0iXnz5nHIIYcwYsQIAMrKysI6n2maXHPNNUyYMIEjjjgCh8PB9u3b4zH0oIj4cvLMM8+wa9currnmGnRd73b5Y0EQBEGIB6ZphvyzefPmkI8NxIcffsi7777L0qVL+eqrr5g0aRITJ04MKUqVkZFBZ2ena+ytra0APP300+zcuZPPPvuML7/8kgEDBtDc3Bz9BEWAiC8nt99+Oy+88ALl5eV8+eWXHHjggZx33nls27Yt2UMTBEEImeo6kyOu6OTZdwNf3AQhlampqaG0tJS8vDxWrVrFsmXLaGlpYeHChaxfvx6AyspKAAoLC6mrq3Pdd/jw4Xz22WcAvPLKK7S1tbnO2b9/fzIzM/nggw/YuHFjgp+VGxFfTjRN4+STT+bDDz/kuuuuIysriyeeeIIxY8bw3HPPJXt4giAIIbH4W3jvM3j0DRFfQvfl6KOPpr29nQkTJnD99dczffp0+vXrx7x58zjppJOYOHEip512GgDHH388L730kstwf+GFF7Jw4UKmTZvG8uXLyc/PB+Css87CMAx0Xefpp59m7NixSXt+WrDQXwqRkIE6HA4qKipYt24dv/71r1mwYAEAc+bM4Z577nFVTQixw5pzIXHInCeeRM35fz4wOfUGk4MnwEf39u7v1/I+Tzwy5x74zZH27v/MAIwaNYrXXnuNBx98kJycHB599FGmTJnC559/nuyhCYIg+KVZ2VtoaUvuOARB8I+IrwBomsbFF1+MYRjsvfferFmzhunTp/PPf/4zqFlQEAQhGTS1qK0lwgRBSD1EfIXA+PHj+eSTT7j00ktpa2vj//7v/7jssstob29P9tAEQRA8kMiXIKQ+Ir5CJDc3l/vuu49nnnmG7OxsHnjgAY477jhqa2uTPTRBEAQXVuSrRSJfgpCyiPgKkzPOOIP333+fvn378r///Y8DDzwwqeWqgiAIdppalCVC0o6CkLqI+IqAAw44gGXLljF27Fi+/fZb9ttvPzHiC4KQEkjaURBSHxFfETJq1CiWLFnCYYcdxvbt2znssMNYtmxZsoclCEIvx5V2FPEldHPuuece9tprL84666xkD4WXX36Z7777LmbnE/EVBaWlpbz55pucfPLJ1NTUMHPmTD7++ONkD0sQhF6MFfmStKPQ3bn//vt54403ePrpp4MeG+8COBFfKUZWVhbPPfccZ555JvX19Rx99NG89957yR6WIAi9lCan6OrshPZ2aYkjdE8uueQSfvjhB2bNmsUdd9zBiSeeyIQJE5g+fTpff/01ADfeeCMXXXQRRx55JOeeey47d+7k5JNPZurUqUydOpXFixcDUF9fz5w5c9hnn32YMGECL774IgC//OUv0XWd8ePHc8MNN7ge+/e//z3jxo1jwoQJXH311SxZsoRXX32V3/zmN+y7776sW7cu6ueXEfUZBDIyMnjiiSfIysriscce46c//SkvvfQSxxxzTLKHJghCL8Me8Wppgwz5lBeiRDukM4yjBwGhHW9+5D/+8+CDD/LWW2/xwQcfcNNNNzFp0iRefvll3n//fc4991y+/PJLAD777DMWLVpEbm4uZ555JldccQUHHXQQP/74I0cddRQrV67kT3/6E8XFxXzzzTcAVFVVAfCXv/yFsrIyOjo6OPzww/n6668ZPHgwL730EqtWrULTNKqrqykpKWHWrFkcd9xxnHLKKWHMhX/k3zJGpKen8+9//5vs7Gz+9a9/ccIJJ/D6669z5JFHJntogiD0IizPFyghlp+bvLEIQixYtGiRK1p12GGHsXv3bmpqagCYNWsWubnqTf7uu+96pAZra2upq6vj3Xff9VijubS0FIDnn3+eefPm0d7eztatW/nuu+8YN24cOTk5/OIXv+CnP/0pxx13XFyek4ivGJKWlsYDDzxAZmYm9957Lz/72c945513OOCAA5I9NEEQegl28SWmeyEWBIpQeROPtR19rSijaWrZRGvRbIDOzk6WLl3qEmP2+1vHW6xfv57bb7+dTz/9lNLSUs4//3yam5vJyMjgk08+4b333uO5557j3nvv5f3334/p8wHxfMUcTdO4++67Of/882lsbOSnP/0pX331VbKHJQhCL8Ej7Sime6EHcMghh7hM9x9++CF9+/alqKioy3FHHnkk9957r+tvKzXpvb+qqora2lry8/MpLi5m+/btvPnmm4Dyh9XU1HDsscdy1113uc5RWFhIXV1dzJ6TiK84kJaWxkMPPcTPfvYzqqurOfLII/n++++TPSxBEHoB3mlHQeju3HjjjRiGwYQJE/j973/P448/7vO4e+65x3XcuHHjePDBBwG47rrrqKqqYu+992bixIl88MEHTJw4kUmTJjF+/HguuOACDjzwQADq6uo47rjjmDBhAoceeih33nknAKeffjq33XYbkyZNionhXutGC0QnZKCxDJm2tLRw3HHH8e677zJ06FAWLVrEkCFDYnLunkQ8wtRCYGTOE0+i5nz8uZ18t0H9/sW/NfYdrQU8vicj7/PEI3Pugd9/Pol8xZHs7Gxeeuklpk+f7qq8sKosBEEQ4oF4vgQh9RHxFWcKCgpYsGAB48ePZ+XKlZx00km0tLQEv6MgCEIE2FONknYUhNRExFcCKCsr44033mDQoEF8+OGHXHDBBT6rNwRBEKLFI/Il4ksQUhIRXwli6NChLFiwgIKCAp555hmuu+66ZA9JEIQeSJNXk1VBEFIPEV8JZNKkSTz//POkp6dzyy23MG/evGQPSRCEHoRpmh7RLkk7CkJqIuIrwRxzzDE88MADAFx66aW89dZbSR6RIAg9BW+xJZEvQUhNRHwlgQsvvJBrr72Wjo4OTj31VFasWJHsIQmC0APoIr4k8iUIKYmIryRx8803M3v2bOrq6jj++OPZuXNnsockCEI3p8mrkFrSjoKQmoj4ShJpaWk89thj6LrO+vXrpQWFIAhR4y2+JO0oCKlJxAtr67o+BbgL6AS2A2cZhtGm6/ppwK+BZuA8wzA2OY9PA74F7jcM415d188HrgUcgMMwjLOieSLdkby8PF555RWmTZvGokWLuPjii3n00Ue7LAAqCIIQCuL5EoTuQTSRLwdwlGEYhwJrgRN1Xc8ErgRmANc7fyzOAH70OsfdhmHM6I3Cy6K8vJxXX32VvLw8Hn/8cf7+978ne0iCIHRTuqYdpZ+gIKQiEUe+DMPYZvuzDWgHRgMrDMNoBRbrun47gK7r6cBs4Hkgz3a/S52RsvsMw3jO+zF0Xb8IuAhg7ty5zJw5M9LhhkxbWxsOhyPuj2NnwIAB3HXXXVx00UX84Q9/oF+/fhx11FEJHUMyScac93ZkzhNPIuZ8kyMT6Ov6e1dlPQ5HXVwfM5WR93nikTl3E2iNy4jFl4Wu60OBI4A/A1OBWtvN6c7tWcB/gEzbbS8DTwD5wHu6ri80DGOr/dyGYcwDrGZY3W5h7XC48MIL2blzJ9deey3/93//x5IlS5gwYULCx5EMZCHWxCNznngSMecFW0zsH5VZ2QVUVBTF9TFTGXmfJx6Z89AIKr50XR8IvODjplmoaNeTwByn36sKsP+ndzijXqc5jz/HusEwjGrnr3W6rn8A7AV4iK/exh/+8AdWrFjBM888w6xZs/jkk0/o379/soclCEI3wdvzJdWOgpCaBBVfzvTiQd77naLqZeBmwzDWOHevBcbpup6FioJ9DQwEBgALgAogXdf1pcD3hmHUOs+zH/BA9E+ne6NpGg8//DBr167lk08+4eSTT+bdd98lOzs72UMTBKEbINWOgtA9iMZwfypwAHC9rusf6rp+mmEYbcCdwEJUGvLPhmE4DMPQDcM4GrgDVe34GXCFruvLgCXAy4ZhbIjqmfQQcnNzefnll6moqGDRokX88pe/lEW4BUEICUt8pTk/2aXJqiCkJtEY7p8FnvWxfz4w3899HrP9fhNwU6SP35MZNGgQr7zyCgcffDCPPvooe++9N1deeWWyhyUIQopjpRmL86GqTtKOgpCqSJPVFGXKlCk8/vjjAFx99dW89tprSR6RIAipjhX5KilQW0k7CkJqIuIrhZk9ezY333wzpmlyxhln8OWXXyZ7SIIgpDBWpEvElyCkNiK+UpzrrruOs88+m4aGBo4//ni2bu3VBaGCIASgydlU1SW+JO0oCCmJiK8Ux6qAPPDAA9m8eTOzZs2isbEx2cMSBCEFafZKO4rnSxBSExFf3YDs7GxeeuklRowYgWEYnHPOOXR2diZ7WIIgpBhNVtqxUG0l7SgIqYmIr25Cv379eP311ykqKuK///0vv/3tb5M9JEEQUgwx3AtC90DEVzdi3LhxvPjii2RkZHDHHXfwj3/8I9lDEgQhhXAb7jWPvwVBSC1EfHUzjjjiCB599FEArrrqKp59tkurNUEQeilW5Ks4X23FcC8IqYmIr27I2Wefzd///ncAzjvvPN57770kj0gQhFRAWk0IQvdAxFc35eqrr+byyy+nra2Nn/3sZ9IDTBCELp4vSTsKQmoi4qubomkad9xxB6eddhp1dXUcffTRrF27NtnDEgQhiTRLtaMgdAtEfHVj0tLSePzxxznssMPYvn07M2fOxOFwJHtYgiAkCSvyVZAL6enQ2Qnt7WZyByUIQhdEfHVzsrOzefnll5k2bRobNmxg5syZ7Nq1K9nDEgQhCVjiKzcbsjPV75J69E9Lq8m23SJOhcQj4qsHUFhYyJtvvsnee+/NypUrOfroo6mtrU32sARBSDCW0MrJcosvST3659QbTIadarKzWgSYkFhEfPUQysrKePvttxk5ciSfffYZxx9/PE1NTckeliAICcTqcJ+bpQQYiPgKxJpN0NoGm3ckeyRCb0PEVw9i0KBBvPvuu5SXl/PRRx9xyimn0NoqOQdB6A5c91AnJ/yhk87OyKMwrsiXpB1DwhKmbe3JHYfQ+xDx1cMYMWIE77zzDn369OGNN97g7LPPpqOjI9nDEgQhCA+9Dq8uhs07Iz+Hy/OVBdlW5EvEl19c4ks+IoUEI+KrBzJu3Dj+97//UVRUxH/+8x8uvPBCWYhbEFKcxma1jVQsdXSYtDrFRLakHUNCIl9CshDx1UOZMmUKCxYsIDc3l0cffZTLL78c0xRTqSCkKpZfK9I0oSUkcrJUH0BJOwanVcSXkCREfPVgDjroIF555RWysrL45z//yfXXX5/sIQmC4IO2dhPLHRBppMreZgKk2jEUJPIlJAsRXz2cmTNn8vzzz5Oens5f/vIX/vrXvyZ7SIIgeGGlHCHySJW9zYR9K54v35imO03bLp4vIcGI+OoFnHDCCTzxxBNomsY111zDXXfdlewhCYJgw4paQQwjX07xJWlH37Ta5lkiX0KiEfHVSzjzzDN56KGHALjiiit48MEHkzwiQRAsPMRXjCJfknYMjH1epNpRSDQivnoRP//5z7n33nsB+OUvf8ljjz2W3AEJggC4zfYQeaRKPF/h0SKRLyGJiPjqZVx22WXcfvvtgBJjzz77bJJHJAhCLNOO3p4vSTv6RtKOQjIR8dULueqqq/jTn/5EZ2cn55xzDi+++GKyhyQIvRq74T5S8WWJLG/PlxjufSORLyGZiPjqpVx33XVce+21dHR0cPrpp/PKK68ke0iC0GuxR76iTjuK5ysk7KJUqh2FRCPiqxfzpz/9id/+9re0t7cze/ZsXn/99WQPSRB6JTE13DsjX5J2DExPi3ztqDJ55h2TtnZppt0dEPHVi9E0jVtvvZUrrriCtrY2Tj75ZN56661kD0sQeh0xMdxbaccukS+5GPuip1U73vyYyVl/Mnl1UbJHIoSCiK9ejqZp3HHHHfzqV7+itbWVE088kXfeeSfZwxKEXkUsDPddWk1kaep8EvnyiX1eekLka8su53Z3cschhIaILwFN07j77rv55S9/SUtLC7NmzRIBJggJxNNwH1mkyrvVhKQdA9NqE1w9QXzVNqptXWNyxyGEhogvAVAC7N577+Xiiy+mubmZWbNm8fbbbyd7WILQK/Aw3Lf4Py6Uc0iT1dDw9Hx1/9RsbYO17f7PpTcg4ktwkZaWxv333y8CTBASjN3zFXnaUV10c7NVulHEV2B6WrWjFfmqlchXt0DEl+CBJcAuueQSVwpSBJggxJemFne0IlYd7iXtGJieVu1opRutCJiQ2oj4ErqQlpbGfffd5yHApApS6OlU1iYvXRMfw73zfCK+fNLTqh3dacfkjiOZrNxgcsxvOvl8deqnXkV8CT6xBJhlwj/hhBN47bXXkj0sQYgLL35o0uc4k8feTM6Hdiw63MvajuHRk6odOzpM6pvU77057fjCQnhrOTz5togvoRtjCTCrDcVJJ53Ef//732QPSxBizlfr1If1Z0n6xuzR5ytCw7135EvSjoHpSWlHS3hB7652rKlX/7/bKpM8kBAQ8SUExGpDcdVVV9He3s6pp57K/Pnzkz0sQYgpDc6LV1Vdch4/lgtrS+QrNHrSwtp2wdWb0441zue+vRuIr4xI76jr+hTgLqAT2A6cZRhGm67rpwG/BpqB8wzD2KTr+mPAeKABWGAYxm26rhcATwL9gNcNw7g1qmcixA1N07jtttvIzs7mlltu4cwzz6S1tZVzzjkn2UMThJjQ4Ez7VdYm5/FjurajLKwdEnZR2t2rHe2pxt6cdrSEZ0+PfDmAowzDOBRYC5yo63omcCUwA7je+WMxxzCMGYZh3Ob8+0KUEDsImKHr+uAoxiLEGU3T+POf/8yNN95IZ2cn5513HvPmzUv2sAQhJrjEVzeOfEnaMTzszWy7u+HeHu2SyBdsr0ruOEIhYvFlGMY2wzAsjd0GtAOjgRWGYbQahrEY2Md5uwk8pOv6O7quT3Tu2x+wehi8A0yPdCxCYtA0jRtuuIFbb70V0zS5+OKLueOOO5I9LEGIGivtmKzIV2Ms0o5+13aMfFw9mZ5kuLcLruZWaO2l63la81BZm/pzEHHa0ULX9aHAEcCfgamA/eMr3bm92jCM3bqujwUeQwmtEtuxNUCZj3NfBFwEMHfuXGbOnBntcIPS1taGw+GI++N0Z84++2za29u57rrruPrqq3E4HFx55ZVomhbR+WTOE4/MuSeVNaVADruqO3E4tsblMQLNeW19X0CppfqGdhyOnWGfv855jtqaHTgc7VRVpgP9aWyK7Hw9gUBzvruqCMgHoK6+GYejG4RL/LBhcw5Q6vp7zbqtlBYmR3wk87Nld7X7/+irldso79OZlHFYVFRU+L0tqPjSdX0g8IKPm2ahol1PolKKbbquVwFFtmM6AAzD2O3crtJ1HV3X0wHr2GqUENvg/QCGYcwDrNxWQt5JDocj4IQJimuvvZbBgwdzwQUXcOedd6JpGrfffntEAkzmPPHInHvSgfqQrmlMY9CgctLSIvsiEYhAc97e6b5IdJgZEb027aY6x7DB/amo0EjLNgGTts7IztcTCDTnmdnuOU/PyOnWc5SZo15ri/yiQVSUx/49HAqRfLZU1prkZEFeTnRjbmx1v6Za1kAqKpIzB6EQVHwZhrENOMh7v1NAvQzcbBjGGufutcA4XdezUFGwr53HFhmGUavren8g2zCMDl3XlwFHAg+jImc/j8HzERLIeeedR35+PmeeeSb/+Mc/qK2t5cEHHyQ9PT34nQUhhbDSjp2dqnKsuCCxjx8Lw700WQ2P1p5kuPfyedU1+T4uFWlqMRl9psnowbDswejEUo1tHlLd9xVN2vFU4ACgUNf164EHDMOYr+v6ncBCVLXjuc5jn9J1vQyVhrzKue8h5/45wGuGYUgOpBtyyimnkJeXx8knn8zDDz9MVVUVTz/9NNnZ2ckemiCETIOtyWllbXLFl7SaSAw9qc+Xd2+v7mS637Zb/c99uz6683R2mh7zsG13dOeLNxGLL8MwngWe9bF/PjDfa98sH8fVAydG+vhC6nDsscfy9ttvc/zxx/Piiy9SXV3NSy+9RGFhYbKHJggh4SG+6mBEgh8/JoZ7P+KruRVM04zYk9lT6UnLC9U2erpyupP4slpjNDSpTv3p6ZG9T70FaKpHvqTJqhATDj74YBYuXMiAAQN47733OOyww9i1a1eyhyUIIdFgS9MkuuLRNM24pB0zMjTS08E0u39aLR701GpH6F69vuxjj6Y7v/ccbKtM7WpHEV9CzJg4cSKLFy9mxIgRGIbBQQcdxI8//pjsYQm9nL89bTLlF53UNfr/MLZHvhLd5b61TQmkzAzQNOjogPb28C4cHR0mbe3q/lmZ7v2u1KP4vrrQk9KOltiyhHd3jHyBp2crXLzvm+pd7kV8CTFl1KhRLF68mH322YfVq1ez//7788033yR7WEIv5l+vmny+Br5Y4/v2tnbT4+Kb6Ear9nRhpD4te9TLnl6URqv+6Uniy4oYDe6ntt1JfMVqaaSuka/Iz5UIRHwJMWfQoEEsXLiQgw8+mC1btrhSkoKQaBqaTNY723bV+6kAa/Dan+i0o118WWIpXPHl7feyENO9f3pitePg/mpb15TaKTc7Ht35o0k7Ou87xDkH4vkSeiWlpaW8/fbbnHTSSdTU1HDUUUfx4osvJntYQi9jlS3r7Vd8NXv+XVmb2AuXZbbPy468PYQlvizxZiHiyz89KfJlCY+Kvs6/u1Hkyz7WmvrIz2Pdd88haiuRL6HXkpOTw/PPP8+ll15KS0sLs2fP5t577032sIRexApb+bo/M28X8ZXEtGOkaULreO/Il6Qd/dOjqh2tyFc3TDvaKzVjEfkaNkD5J2vqobkldSOAIr6EuJKens69997LX/7yF0zT5Fe/+hW//e1v6exM7rIPQu/guw3uD9/ukHaMNFLlva6jhTRa9U9PqnZ0e76U36+7VjtGIxqtyFdJAfR3rrSUyqlHEV9C3NE0jWuuuYbHHnuMjIwMbrvtNs444wyam5uD31kQomDFBvfvoaYdE13t6Et8hR35stKO4vkKmR6ZduyWkS/379FUO1oRtKJ8jYHOlaJTueJRxJeQMM477zzefPNNCgsLef7555k5cyaVlSn83yF0e77b4P7dX6sJS3xZ35YTHvmyRa0iNtz7iXxJ2tE/0Yivzk6TphRJabW0mrS0Qnq6+z3cnSJfntWOkc+pFfkqzocBznlIZd+XiC8hoRxxxBEsWrSIiooKFi1axAEHHMDGjRuTPSyhB9LY7K50hOBpR6tKKtGer0an+MuNwnDv3WDVQiJf/omm2nH2H02GnmJSH6B3XKKwxEtRnhIe0M0iXzFKO1qCsygfd+RL0o6C4GbChAksW7aMCRMmsHr1ambNmsXSpUuTPSyhh7Fqo2peahEs7egSX0nyfOXlRB6p8ttqQjxffonGcP/JSthVAz/uiO2YIqHOJjqK8j33dQdi1mTVHvlyii+JfAmCF4MHD+bjjz/myCOPZPfu3fzkJz9h/vz5we8oCCFi+b2sju/Bqh37lahjm1tJaEopJoZ7P60mJO3oH/scd3SoZZ5CxRLyzS2Bj0sEtbbIV1Ge577uQHwiX6rwYHsKLzEk4ktIGkVFRSxYsICzzz6blpYWTj/9dFdVpCBEy4r16n00abT6O1jaMT8HypxrwSfSdO8SX1lRGO79tJqQtKNv2ttNOjuVTyojXe0Lx/dlCfZUELWWYCnMUz/Wvu7yORqrJqtW1Ew8X4IQAhkZGfz1r3/ljjvuQNM0rrvuOubMmUNrawp8qgndGstsv99eahss7ZifA2VF6vdEph6bbMJJOtwnBms+sjJUTygIXXzZl6NKBfFlTzump2vk5ah0u3cLlVSlzjbOqKodnfctyoeBfdTv4vkShABomsaVV17Jf//7X/Ly8nj88cc54ogj2LVrV7KHJnRjrLTjfuNUCsJf2rGxWUUI8nO1pIiveBruXWnHFEiPpRKW+MrODF982UVNtOKrvd3kN/d38v5ngaNUX601+fgr38fY0472bXdIPZqmGbu0o6/I1+7IzxdvRHwJKcOJJ57IRx99RHl5OR9//DHTpk1jxYoVyR6W0A2xKh0z0kNIO9ojX860YyIrHi1/WV6OFj/DvUS+PLDEbXaWO+0YasWjvS9cU5Sidtl3cPtzcNNjgcXX8b83mXmV6bNdij3iY992h4rHhibPopiomqzaI19S7SgI4TFlyhQ+/fRTdF1n/fr17L///rzxxhvJHpbQzbAqHUcPdqcSQxFfpZb4SmTa0YfnK1yx1NyqrmA5WZrHfkk7+qbVGeWKJPJVH8PIlyU2AnkMTdPEsUsJxq0+Ijl2zxd0r4pHKzpnjT3StGNbu0lTi/Lw5eVAcYEqnqlrdEe2Uw0RX0LKUV5ezsKFCzn11FOpq6vj+OOP5x//+Ee3MZAKyec7Z+u48SPcH+x+qx0tw32uW6gl1HBv83xFarj3F/myxJglzpLJl9+brNqY/HGAV9rRMtyHGvmKofiyFlUPJJSaWsBajW2Hj0hOXZOzs3s3TDtawnFgGaSlqefa1h7+e8QV/ctTNhZNS/0u9yK+hJQkLy+P5557jhtvvJHOzk6uuuoq5syZI0sSCSFhVTqOG64EiaapC2W7jw92z7SjEiuVdclpNeE23If3+P5aTbgiX0k2hje1mBzyK/XTGuZziweutGMkni/bR1DU4st5rroA5ni7MPMlvtxpR8259dyfyrh8WgVu0RhJxM479QqpX/Eo4ktIWTRN44YbbuD55593GfFnzJjB1q1bg99Z6NVYlY7jh6tvwQW56m/vdRzt+/KSVO3oabhXF9BIDfeJ8HztqDLZWR2egNpVrS6qO6thybexG0ukuKodky2+Qoh82W/z5WHqknbM89yfyliisyhPCTBwN0sNB3ubCYtU932J+BJSntmzZ7N48WKGDh3K8uXL0XWdTz75JNnDElIYq9Jx3HC1DZR69OjzlYxWE7HocJ+gtR07O032vcBkyi/MsGwAVbYL6pvLUiDylSLVjpbwbm3Db0QwaOTLq9qxsBumHYvyo0uX+ox8pXiXexFfQrdg3333xTAMDjnkELZs2cIhhxzC448/nuxhCSlIU4vJD1tUFdueQ9Q+K/Lly3Tv03CfDM9XNIb7YGnHGEW+ahqU6XvTDthdE/r9qm3z+eby2IwlGqKpdvQ03EcnJBttUTR/0S9P8dX18ex9vuzb7hD5skftrHHHPPIl4ksQoqNfv3688847XHLJJbS0tHD++eczd+5cacgqeGCvdMzKVGm8kMRXbpI73EdjuE9Qh3t7RHBTGOsa2ufzmx9g0/bkRr+iqXaMZdqxySbe/Iov23t2R3XX27u0msjTnPuTH2EMhj1q51oUPGaeLzUP21J0iSERX0K3IisriwceeIB58+aRlZXFfffdx2GHHSY+MMGF5feyUo7gTsX4FF8pknaMpsN9opqs2udl887Q71ftFc14K8muAQ/DfbjVjjHs8xV+5Kvr7d7tGlytJrpBh3uPtGMUETufkS+ry71EvgQhdlx44YV89NFHVFRUsHjxYqZMmcKSJUuSPSwhBVixQX3THT/Cvc+KfPn0fPlaXiiBka9YdLhPVJNVewQrHPFl3c+6wCbb9+XyfGVF4vlyjz1Wni+IQnzZ2ixAd0s7Wm0yNNf4I+n15T0HINWOghA39ttvPz777DMOOeQQtm7dyowZM/jnP/8p/cB6OSvWq+24Ye6Go/7Sjp2dpofhvThftaWoqffdliIeWCnDvOwoDPcJ8nzZRemmHeEY7tWxJx2i/n7H8G8wTwTRrO0Yj2pH8B+pClbt2MXz1R2rHfPd1Y6RjLvW2fm/uMD9Py/VjoIQRwYMGMC7777L5ZdfTltbG//3f//HmWeeSX19BK5NoUfgajNhi3z5Szvao05paRppaRolzouAd6osXvjyfEWaduzaZNXz9miJOO3oFG0TR2mMH6Feh8XfxGZMkeCr2jGS5YUSHfmqqvMUraZpdkk7dt9qR6dXzccSSsGwTPoekS+pdhSE+JKZmcmdd97J/PnzKSgo4LnnnmPatGmsXLky2UMTEkxTi8m6LWqZkdGD3fv9pR3tKUeLRHe5j4nh3l/aMY6G+83hGO6dF8fSQjhmP/X7m8uTGPnyUe2YjOWFPCJffsWX5zztslWZNjar7vc5WZCZ0X2brBbmRlftWOsV/QMlQnOz1RzVRyDo4o2IL6HHcOqpp/Lpp58ybtw4Vq5cydSpU3nuueeSPSwhgaz+0VnpWOFuWAr+0472SkeLRC6ubZpmXA33kXrI/FFl6/wfSbVjSQEcs596Xd5YFpsxRYJHtWOY4iuWfb6aQhJfnn/bfV/eKUeIzfJC7e0mzS3xFyx20RRNtaMl2OyGe03TUtr3JeJL6FGMHTuW5cuXc+aZZ9LQ0MAZZ5zBL3/5S1mWqJfg8nsN99xf6Exp1Dd5XlDslY4Wiax4tC7eWZkq7Rlrw33M045ehvtQ/ZXVtsjXQROUGF6xPnktJ3wuL5SqaUevLwx28eXdYBWij3yZpsmkn5vsd4lJR0d8X59YVTv6inyBreIxBX1fIr6EHkdBQQFPPfUU999/P1lZWTz44IMccMABrF27NtlDE+LMhm1qu0eF5/5I0o6JEF8us79TNEXb4T7uhnvbnDS3hj5HrshXoeq9doSu/k5Ww9Woqh3jZbj3kxqz3rNWdNbe68tXfytXq4kII19NLfDtevh6HSxdEdk5QsVXn69Iqh19tZoAW8Xj7sjGF09EfAk9Ek3T+OUvf8nSpUsZOXIkX3zxBVOmTOGFF15I9tCEOGI1VBzUR/PYH07asdRpuE9E2tE7YhWJWGpvN+nogLQ0t5CwiGe1I4SeenRFvpxze+x0K/WYpMiX07SelaFFtbxQIvt8WV8o7H2rvNd1BCXAM9KVMIykotQ+plcXx/f1sadNo4p8+RChkNoVjyK+hB7N5MmT+fzzzzn55JOpra1l9uzZzJ07V9KQPRTrQ9ZKN1j4q3YMlHZMhOHen/gKJ6Ji726vaZ6iMyc7/PMFwpqT8r5qG2rFo3U/a/kmy3T/3mfJaTlhTztGt7xQdOMIp9XEqHK1tS8xVOcj7ahpWsC1TMMZ0yuLwr9/OMS8yWqB5353xaMY7gUh4RQXF/Of//yHe+65h8zMTO677z72339/1qxZk+yhCTHGSi9Y33gtwks7KgFTWRv/D+xGL/FliaVwIlX+zPZgi3zFuNXExFFqG4r4am0zaWxWFahWhHFwf429nS0nFn0dm7GFQ8qkHcOIfI1yRr480o5+vE7RCBn7mNZsgtU/xuf/oLXNpLlVvS9ysoKnHesbTZ9jMU3TZ5NVgIFl6n85Fbvci/gSegWapvGrX/2KJUuWMGrUKL788ksmT57MU089leyhCTHEqmryJ7789flKVrWj37RjOJEv6xyBxFdb6OZ4f5im6ZqTCU7xFUqjVXvK0R6ZO3a62r79aeKjElFVO8ZybccQqh1rXZEvNXcehnsfaUeIruKx0Ssp8Ori8M8RCvaonaZpbsHoZ8zn/MVkr3NM1m72fL80t6rXLjvLs8IZUrvLvYgvoVeh6zqff/45p59+Og0NDZxzzjnMmTNHmrL2EKwP2QFe4stv2tFH5MtKjSXDcG9PO4YqlgJFvtLTNTLSVfuNUMVFoLG2tKqL3OjB6iIXSq8v75SjxfgR6hyOXdGNKxKiqnaMUdqxrd30SHVGFfnyFl/RRL6c70lLJ7+yKD7i2NunZXnVWlqhpbXrY369Tr2Pv/Sqm/IX9QLxfAlCSlFUVMQzzzzDQw89RG5uLo899hhTpkzh888/T/bQhChobDapa1RtG0q8vB+pXu1oRb4ssQShiyV/bSYsYrW+oyWiygphSH/1eyiGeyvy5f2aRONLipZI046tbUowpTmvnOGIZG+8I0y+5qGjw3QdN2KQ2nr2+XKujZjvGfEpisbz5Xy8/cap/6Ul38LO6tgLMG/hqGmae4khr3GbpskWp0jfsNXrPH7M9pDaXe5FfAm9Ek3T+MUvfsGnn37KPvvsw5o1a5g+fTp33HEHnZ2dyR6eEAHbbSlHb+O532pHZ9+v/Fz38ck03INbLIUaVfG3rqPrfDHyfVlitKwIBjvFVyieL3+Rr1QQX+Gu7Wi9f4ryVJSmszN0o743oYgv6/EKct1RnB1VbsHnT3gES+EFHJfz/TSgFA6brKJNry8J/zzBCNgg1itiV13v/n/YsM1TCPprMwHutOP2yujT7rEmI/ghvtF1fQpwF9AJbAfOMgyjTdf104BfA83AeYZhbNJ1/TFgPNAALDAM4zZd188HrgUcgMMwjLOieSKCEAnjx49n+fLl/Pa3v+Xee+/l6quv5u233+bxxx9n4MCByR6eEAb+/F4QXtoxkZ4vb8M9KBHV0BR6pMrfuo7280H0ka9Km4gaYhNfpml2Ebt27N3t7SRVfHksL6QBJu0dJuD/eYCtOjZXia76JiV+vVt8hIL12pcUKHHhq9rRmpvCPPUFIT/XpKFJ7S/Kp8u6jhaxMNzn5cBR0zTeWm7y6mKTOccGnptw8eVX8zfuLbbU9PowIl8Fee45q23oWg2ZTKKJfDmAowzDOBRYC5yo63omcCUwA7je+WMxxzCMGYZh3Gbbd7dznwgvIWnk5ubyz3/+k1deeYU+ffrw9ttvM2HCBF599dVkD00Ig0DiK8vZUqC1zbO1QTDPV7y/Lfsyy4cbqQqadoxwvUhv7GnHwjxlkG5qCZ6etXe3t5MKkS8Pz1cIkS/7+yXa1QMskWOlxuoau77f6rzEVf8StbVSj/78ToW5nreHNS6bD/H4A9Tvb3+q1k2NJb78av4qHrfamqRajZQtAkW+IHV9XxGLL8MwthmGYf3btAHtwGhghWEYrYZhLAb2cd5uAg/puv6OrusTbae5VNf1j3VdPz3ScQhCrJg1axZff/01hx9+ODt37uSEE07gwgsvFDN+NyGQ+NI0zWfq0Ypk5NnEV3aWRl6OO7IRT1yGe/vjhymWAhnu7eeLOvJlSzsCDO6ntsFSj37TjpYPL85z7AsP8RWGxy6W4st67Qvz1Lk6O7s2be0ivpxpNEt8+Urdqb9VlKo2ggWl7ZGvwf01poxR+977LOxTBSRQd/5Aka8N2zxFaqDIF9jWjEyxhcYjTjta6Lo+FDgC+DMwFbB/D3K+rbnaMIzduq6PBR4DpgMvA08A+cB7uq4vNAzDI6Co6/pFwEUAc+fOZebMmdEONyhtbW04HI64P47gJtXm/NFHH+WRRx7hr3/9Kw8//DDvvPMO99xzD1OmTEn20GJGqs15LFizoQAoJDezDoejq2DOy+5PdX06a9dvo6Kv8vXtri4FcmhurMThcJtwivP609iczndrtjO4X3imng+/ymLN5kwu+qnnp72vOd+2Mx8oor21HodDqZSMtL5AJj9u3kGuFlwROLblAKXQ0YTDUd3l9nRNnW/T5h0UZ0Ze8rh+sxprlqbG2q9Izd1XK3fTN9d/q/cftxYCBWidtTgc7jmpa9CAgdTWd+JwbPV7/2jw9z6vb+wDZFFTvZOGhkygmKqaBhyOwGG8DZuygD5kprWSkZ4GZLBx03bSIzB+bXSoc6XTQn5OBs2t6axZt41+JW7P6Xrn42Wlt+BwVFKUo+Z85brdDCtrYXe1eh7NDTtxONzq2mxXr9WW7cGfkzdbt6v7drSp13nGPgV8trqQZ99uYNKwmqD3D/WzZdNW9Thpnbb3vlYC5LJhcxUOh1uVr/xBHQtKCH69cht9i9U8bdySBxSTbvp+rumamqNNjp0MKozRUg8hUlFR4fe2oOJL1/WBgK81WWahol1PolKKbbquV2HNkKIDwDCM3c7tKl3X0XU93TCMaucxdbqufwDsBXj8BxqGMQ+Y5/wzIW45h8MRcMKE2JOKc37DDTdw8sknc/bZZ/PVV1/xs5/9jN///vf88Y9/JDvbT36nG5GKcx4tTe3qw3jPYUVUVBR3ub24oJMtuyG/aCAVFSoy0IG6z9CKMtc+gH6lnWythOz8AR77Q+Hm33ayZhOcfUwxo4e47+trzrOy1eP371tARYX66MzPU/tKSvuH9Nh5+SZgUlqSS0VF16//BfnqfEUloZ3PHx2aOs+QQYVUVBSxx5BOFn4NjZ19Ap7XmuPhFcVUVJS49g9oV+NuaEmjvLw8oG8sUvy9z03nmAaX9+PHSrUnOyefiorCLsfayf1RjbmsJItGZ8SruDT89whAvvNcpcXZFNfC7looKB7oca7sH9QxfUuyqaioYOggNe6ONDXnTW3q71HD+nncb8ggdb/OtODPyZsM53tyQF/1Op9zrMkdL5i8/2Uegwblk5YW+LmG+tmSlqkep3xAoeu9P6if2peeVUpFhTuE3dDmWQTVgnue0jLUcy0f4Pu5FhWo+xYU9Yvq/R9rgqYdnenFg7x/gBrgaeBmwzCsVuFrgXG6rmfpun4g8DWArutFzm1/INswjA7bvnRgP+CHmD87QYiCvffe22XGN02TW265xdUnTEg9AqUdwXfFo6/lhSC6dhO7nMGBUNowuAz3tuaQ4aazQvV8xazVhHNuhvS3en0F/l7sL+2YkaGRm+073RZvYuL5spZuinDsdm+VP/9b5GlH3+cLaVxW2tH5/CaMgqED1P/Xp6vCP58/fKYd/TSHtdKO6c5cmt33VdOg3n/F+b6FlfV/EasltmJFNIb7U4EDgOt1Xf9Q1/XTDMNoA+4EFqLSkH92HvuUruuLgFeAq5z7rtB1fRmwBHjZMIwNUYxFEOJCdnY2f/vb3/j444/ZY489+Pbbb5k2bRo33HADra0p9t/cywkmvnxVPPoy3EPkFY+maboMwFt2Bz4W/LSaCFMsBWs1EbNqxwg9X/76fEHyTPee1Y7q91Ayh/b3S26MDPd5OaGLrwGlzuVynOs7xmV5Ief7yVr1QdM0Zh2ofo/lQtu+qx2dXrUGz8exxNek0Wprr3gM5vmy3v+JFvjBiNjzZRjGs8CzPvbPB+Z77Zvl47ibgJsifXxBSCQHHnggX331FX/4wx+45557uPnmm3nllVd45JFHmDx5crKHJ2ATX3183+6r0arrYprreWykXe4bm6HDeRHfGob4ioXhPmi1Y5QXn0pbtSO4e30Fi/D5i3yBek12VKnXxHtVgngSceTL1moi6mpHe+TLT/FBoMhXR4dqoaBpXb88uKodYxD5Ajh8isa9/zX5IobL4UZS7XjAeDBWWb2+NI9j/VU7Wv8XqSa+pMmqIIRIXl4ed999Nx9++CEjRozgq6++Ytq0afzud7+jqSkJJVuCC9M03UsLlfo+JhFpR/tFY8uu4FECX5GvcCNVTc6lWHKzfKddYtXh3poLS0TZe30Fwl+fL0hi5MtXtWOYka9oIyr2195/5Eu9toV56rV1ia9q97EFuXTxYcUi8mX/QrCH08K1bkv45/NHqNWOpmm6osgH7K2epz3tGCzyFW2EMl6I+BKEMDn00EP5+uuvufzyy+ns7OTvf/87EydOZOHChckeWq+ltkGlkgpyPbvV2wkv7ajOUVUXXpql1kN8BT/eZ58vSyyFGvlKUNrR2/NlpR037QjcD81fny9InvhqjXB5oXrniggFuZrb85XAtKO9z5c/v5d9X7RNVi1Glqvt+q0q4hYLAkW+7OOurFWvV3EBjBvuHkeg89hJ1bSjiC9BiICCggLuvPNOlixZwvjx4/n++++ZMWMGF110EZWVKbiQWA8nmN8LuqYdTdP0m3Z0Rb7C9HzZI1+hpB39dbiHMAz3oaYdo11eyEt8FeVrFOapi5q/pZg6O02X+PKVFkpWr69IlxeyR0qjTzsqEZOXrfkXX7bljMAz7RhIdPgzroc2Lpzjcu/Ly9EY1EfNUShLSoWCz+WFfKQdrS8x5X1gmHPRkY22Xl811vvLT/f6nmi4F4Rez/Tp0/n888+58cYbyczM5KGHHmLs2LE8+eSTKbeWWE8mmN8L7GlH9bq0tKpKu8wMyMzwjJZFnHa0tRdLlOE+5CarUVx82ttNauqVv8guooKlHlXXdhW5ycjoGpFMRuSrs9N0Ca0sm+crLMN9LDxfEUS++hSp12B3rfu96b20kH2fr6754YzLjhX9+iFGqcdQqx2t/6PyvkrwlxWpObfWcg058tWaWp/HIr4EIUqysrK44YYb+Oqrrzj00EPZuXMn5557LocddhirVsWwNlvANE2fF5Ntzg/oQJEvyzdT7/yw9pdyBJvhPorI15ZdwS98sTDcB2s1EYu0o71i0e4vsqcefRHIbA/JEV9WyjErU1XyWdWOyVpeSIkvNad1Xh3pvcVXRoZG32IlaK3Um6+0Y3q6Rn6uOq4hzKiiL8M9wCin+IqV78vXupRW9MrjS4wV+eqrtiMGqa31/F2Ge7+RLzW3knYUhB7KXnvtxQcffMBjjz1G3759+fDDD5kwYQJ/+MMfZImiGHDGTZ30Oc5k5caut4WVdnRejPylHMHWaiLMyJfdq9LUEtxzExPDfRDPV3aUIgG6+r0sXJGvbiS+7GZ7SGbaUW3D6fMF7tTjWocSav4iPpFWPPoy3AOMcjYoXeeIPoJkmqa71YTt/8/lVbON2Urflzuj2sOdqUdrmSFf57ET7esUL0R8CUIM0TSN8847j1WrVvHzn/+ctrY2br31VsaMGcPTTz8tqcgoqG9SF/MV67veZvU9svog+cK72tFfpSO4RYY/L5M/vEvkg5nuXX6taAz3QT1fak5a2iJ/73m3mbBw9/ryfe5APb4gRcRXGNWO1nunIC96L5E96hlqqwlwm+7XOlfw8VflF6npviGGka+qOpOr7+tk5QbP90dDk4rK5eV4pqNdaccGd9TYqhoe1EcdZxdf9c7z5Of6TmuDtJoQhF5Fnz59ePjhh1m2bBlTp05ly5YtnH322Rx88MHSIT9Cxg9X2+82dL0tFM+Xq9rReUFzNZMMIL7CTzt6NYcM4vuyUjyekS91EWkO0aMSctoxim/+3m0mLAY7u9xHnnb0nW6LJ/ZKR4iiw32Yr5M39tc+osjX5q632YlUfMXS8/XiQrhjPtz6tOcc+fNpZWdpZGep18IStV3Tjmre1291R738Rf9ADPeC0CvZb7/9WLZsGY888gj9+/dn8eLF6LrO+eefz+bNm5M9vG7FuOHqQ3fFhsg8X13SjraGmb6OzUhXx7SEcXGt8couB6t4TKThPq5pRz+G+0A9viC5ka8sp+iKXHyp3yONqISUdnS+R32nHdXWn/CIpOLRNM0AaUe1XRd8zWwX1jJI3laBgG0ybNEv8DTcAwx3er42bA3eYBWk1YQg9FrS0tKYM2cOa9as4corryQjI4PHH3+c0aNHc91111FbG8ECgr2Q8SPU1lfaMRzPV72358tH5EvTNFe0JpzUo3Whs8y/oaYd42m4j0WTVdfSQn7Tjr7vF6jHF/hufBtvvNOOYS0vFMsO9+FUO9q+IPQvsXrQqb+L/KxpGEnkq61drdDgqwK4X4l6varrobI2tC8kVp+81Zs8i098LS3kb9z2VhPgmXYM1mAVJPIlCL2e4uJi7rjjDlauXMns2bNpbm7mL3/5C3vssQf33XefrBUZhLFD1XbNJmhr9/zwD0V8eacdA4kviCz1aEW+9hqmtoG63Hd2mq5UoD1qFWvDfSyqHb17fFkEa7RqXXxLC/00vvWx5FO8sa/rCNFHvuJluG9tM2ltU+Iw2/baWpEvC7+erwiiiv5SjqC+kIQb/bIEYm2DuzUEBG4PYV9iqLPTdEWPB3mJr43b7QLU/xgk8iUIAgCjRo3i+eefZ8mSJRxwwAHs3LmTuXPnMmbMGB577DHa20O4CvRC8nM1RgxSEYrvbRnbzk6THdXqd+8Lk51w0o7gTpV5pxIDYaVBLKEYKO1oTxdqmlucxN5w73lcJFiRDm8RVVygGoQ2NrujXHZCNtwnMfIVXod7tS1IQOTL7veyvz+8l8/yV+Xnq3Iw6Jh8NFi1M9KZ8gvV92WvFl69yf17oIiVPfK1u1b9v5cVQY6zZUR+rka/EuXdW/2jOjZQ2lEM94IgeLD//vuzaNEiXnzxRcaNG8eGDRuYM2cOe++9N88//zydnZ3JHmLKYaUe7ab73bUqVVJWBFmZAaodvZYXChb58rfIbyDc4kuNI5Dh3pfZHiLvcB/PJqv+PF9gSz36MN13i1YTIVY7eqyIEIPIV5OvyJdNhPoy20PokS/rfuGkHQNFvsDm+wpRfFXZBLkllOxjCuj5anSnHAd5FdJY0a+v1pl+z2MhrSYEQeiCpmmcdNJJfP311zzxxBOMHDmS1atXc9pppzFx4kTmz59PR0cIZpRewjhnOs/u+wrFbA+e/iLvC6kvXEudhBH5si4q7rSj/2P9ebXCNdwHrXbMDu98vvDXagLcpntfFY+paLiPtNrRWhEhK1O1NYjWS2RfWsp6DzY0qUgu+G5CCuGkHdUXgNqG0AtGgkW+wu31ZfdLrv7R5vkKlHa0RZy9/V4WVqPVr9c57yORL0EQIiE9PZ1zzjmHVatW8eCDDzJ48GC+/fZbTj/9dMaPH8+TTz4p6Uhg/IiuFY+h+L1AGYizs1SUrLkVGpzLDPlLO0YV+XKKr627/Xe5d5nt/YivUC7qpml6RFB8EZu0o9r6imAFMt0HM9x3p2pHb7Eey7RjWprWpfgg5MhXsFYTMfJ8Qfi9vjzEly3tGFK1Y2PXNhMWVuRrxQb/57HIlciXIAjByMzM5OKLL2bt2rX861//Yvjw4axevZpzzz2XMWPGcP/999PYmMArVYoxbrja2tOOoYov8Ix+uZtJ+k5VFtu8J6FiRckG91OP1dTiP3LmL2IVjkG+pVU1mczKVEvK+CLcSJovXNWOvtKOrsiXL8O92qaU+LIM92FWO8ZSfLW1m7R3QHq6W/x5z4WvSkfw9JvZ7+dNJNWO/pYWsgi315eH58sj7ajeK1afNztW5Ku2oWubCYvhzl5f1mtZ7KfiE+xrO4Y25kQh4ksQUpDs7Gwuuugi1qxZwyOPPMIee+zBDz/8wGWXXcawYcO46aab2LUrSB+DHoiVzrNXPG4PQ3xZF7L6xhA8XwXqA927cao/WttMmlvVBTU32+1T8ef78pt2DMNw7+qQ7+diCbGpdrS8O77Tjmqeftze9bZghnu7GLbSbfGmJcK0Y4PNbA/RVdHZRY5lpvcrvrzElaZpHtGvmFY7+unxZTF0gHp/b94ZvP9dW7tJfROkpanFwNdvU/8jEDjtaKVLaxpMV7VweR9PcWWlHV33kVYTgiDEkszMTObMmcOqVat4/vnnmTp1Krt27eLGG29k6NChXHrppXz33XfJHmbCsCoe29rdHb63VTqXFirz/+3Xwl7xGKza0bowhJp2tDd81DTN9W3dX8VjLAz3wSIVYFvbMULPi2maAdOOower7aofu95WFSTtmJamuebfEsPxxm+1Y5DIV73X+yWayJev9F6o4gs8Kx5jmXa0/if8ia/MDI1hAzwX9vaHPeU8fKBK91stKkKtdvRuM2FhpR0tpMmqIAhxIT09ndmzZ7N8+XI++OADjj32WJqamnjggQcYP348RxxxBK+88kqvMOdbqUfL7xFW2tHW6yt45EttQzXc19rEF7hTJf5M9/6iVuGkCYOZ7cM9ny8ampTYzc12l/vbsS/7ZPe3NbWoPmbZWZDrJ7ULie/15a/JakeHf38exDbt6MvvF474siJf3j3A7ERU7RjEPwih+75cgr0Axjhbr1i+r0DLAhXbRKM/z9cwL/EVKPJlzU9rG3R0pM7auiK+BKEboWkaM2bMYMGCBaxYsYJLLrmEvLw83nvvPU488UT22GMPbrnlFrZsCWMBtm6GdbG3Kh7DEV+FPjxfsTLcWyLNEm2DnOPxK778XOjCMciHcrGMVnwFajMB0LdEY0CZmlN76rE6SKWjRaJ9X95NVjVNcwmwQKnHWIovX1FPbxEaivgqyvfsAWYnkuWFghnuIXTfl93vN2aI+t3yfbnSjgEiXzX1/j1fudmax/97oMiXpmkxSb3HGhFfgtBNGTduHA888AAOh4N//OMfjBw5kg0bNnDttdcyZMgQZs2axauvvtrjqiStNR6/c1Y8hrKotkWB7QLnSjsGiXyFGjmo8fo2X95XjXPrbj/VjjEw3IcS+Yq2Ki9QmwkLSxB/a2sB4ko5BhFfBQmOfLU6/x2sakcIzfflnaaOxksUMO3oqnb0b0rvX6K2gRaUjshwH0rkK8R2E3bRPsbZ9271JnWfUKodq+oCf7EabvN9BYp8QWq2mxDxJQjdnJKSEq644grWrFnDm2++ycknn0xaWhqvvfYaJ5xwAoMHD+byyy/n008/DZhW6S641njcoLbhGO7tjVaD9vmKwvMFtrRjHA33oUQqol3bMVClo4WvdTddPb4CiDZIfuQLQqt4tN4v3ob7iMSXD5HTJe1oLartIzLbv1SJmUCiI5pWE/6iwRB62jFg5CvA2o7Wl551W1QquG8xZGd1FaB231cgEQqpaboX8SUIPYT09HSOPvpoXnjhBRwOB7fddhtjxoxh+/bt3H333UybNo2xY8dy0003sXbt2mQPN2Lsazw2tZjsqlEVVX0CiAOLsNKOlucrRPHl8nxZaUer2tFP2jEWhvuwPF+RRr4CmO0txjujkSvWu8V9dYiRr0KbIE4ELc6Ku2zbagihRL7qvSKlWc55bW0Lv1IzWsO9lXb012YC1PsoI1297sEqE93jUsf5a78ChLy+o/1908XzFbDaUW13VKmtd8rRwl7xWBzkPZaKpnsRX4LQA+nfvz9XX301K1euZPny5fz6179mwIABrFmzhhtvvJEZM2Ywfvx4rr/+er744otuFREryNMYPlBdKBd/o/b1L/Hf58rjvuGkHcPscO8v8uWv2tFluPcyTIfj0QrH89XcGthQ7o9AbSYs9h6ptt/6iHwFEm2QhMiXl+Eewkw7Ot8vdi9RuBEV35Ev9f610o2BUnNWyxXLf+ULTdPc65OG+AUiWKsJ+2Ou3xpYdNorXcv7qv+93TWwu8YMqdrRwrvS0WL4QDVfmub/f9hC0o6CICQUTdOYNm0ad911F5s3b+Z///sf5513HsXFxXz33Xf8+c9/ZvLkyYwcOZK5c+eyYMGCbtHE1UpzvfeZ+vAPxe8FSrgB1DcFX16oOMy0jSXSrIuHPfLlS/Q0tTijDDmeotGKqLS1B4+ohBL5Sk8PzVDuj5DSjsPVduVG95hT3nBvF18hrO/Y0GytiOB+vSIVX00+RE44ka8pYzSMhzTuvTzwFw5r7n0teu6LUFqXFOapha2bWwMvHF9Vp+arrFBD0zT2dKYev12PRz88b7zFl7/Il5V2LMpXLUsCkYrrO4r4EoReQkZGBkceeSSPPfYYX375JW+//TaXXHIJAwYMYMOGDdx3330cd9xxlJWVcfTRR3PXXXfxzTffpGRUzGo38f7nahuK3wvCSzvmZGtkZaq0UnNL8DmwmrFa3bYL8zQK89QHvq+Lnz/hpGlayD6tUDxfEJ3vq7LWeREt8n+BKylUfc2aWtz9n4L1+LJIWqsJW8QxpMiXD7EeceTLV7VjGOILlAArCtDZHdx+O/syPwHHFULkC0JLPXqnqy3x9dlqtS3K812pmWlbNxO6rutoYfWX61sceKwgkS9BEFKEzMxMZs6c6aqWXLp0KX/84x/RdZ2Wlhb+97//ccUVVzBhwgQGDhzIGWecwcMPP8y6detSQoxZHiPD+UEeqviyDPfV9UpUaZrnUi3ehGO69/Z8gTv65StCEChqFapPy3WOAM8BovvmXxli+nBvL9O9FfkoLQwsENxVfol5X0Vb7VhgE+sxTTvaGgBDcPEVCqVxiHxBaKZ777SzZbr/dJVVxen/vvbol1U17M2Ico0HrtJ48KrgdoNUXN9RxJcg9HLS09OZPn06N910E59++inbtm3j8ccf55xzzmHQoEHs2LGD5557jgsvvJA99tiDwYMHc8YZZ/Dggw+yYsUKOjs7Ez5mK/JlPXTI4st5gdvuNPPm5/jvkwThme69PV8QuNFqYwjiK9jFItRIRTSm+6oQWk2AOxVs+b6CLS1k4fY6hT+2SIi02tG7wz1EH/nylXa0RHygasdQiVfky/J9BWo34d0fzmo38ekq9XegCkVf/0O+uOQEjSP04OIrFQ33GcEPEQShNzFgwADOPfdczj33XEzTZPXq1bz33nu89957fPTRR2zZsoXnnnuO5557DoDi4mL2228/9t9/f/bff3+mTZtGaWlpkEeJDstw7BpzafAPYHBf4Kz2FIFK6iE8032NDxNxuc33tZfXenSBolah9vqyfGOBOshDdI1WQ/F8gRWNNJ0Vj1rPM9z7SDu6WhiEeVFvbOlaVRhu2jEUwo18BVteyGJUuXqtfwiwxJC/yJeVqgylTQb4N9yHQyq2mhDxJQiCXzRNY+zYsYwdO5bLLruMzs5OVq1axUcffcTChQtZtGgRmzdv5u233+btt9923W/EiBFMmTKFyZMnM3nyZFf6MlCUKRxUxaPJhm3q75AN9z4iX4EIx3Tv6nDv48IRKO3o60IXcuQrxDRRItKO3v3XQo98qW13FF/xiHzVNaoCjXofac5wseY+7MhXsLRjKJ4v633jHIPl+bIIKL5sgtOf5yscXJEvEV+CIHRH0tLSGDduHOPGjeOSSy4BYPPmzSxbtoylS5eydOlSvvjiC9avX8/69et54YUXXPctKytj7733Zu+992bcuHGMGTOGPffck8GDB5OWFr4DYtxw3OIrzLTjjhDFV1EYkS9LoBV38auYbNnlq9pRbX2lHUOOfPlZH9KbcBq3euOKfAURX1YqeOVGaG83Uzfy5SPtGFK1YwzTjsGqHRubVUo9NxsyMiL/wqL8dibVdSoaGYxQCzgi8XwV5GlU9DNx7FR/h5p2DPWLVSBS0XAv4ksQhKgYPHgwp5xyCqeccgoA7e3trFq1is8//9z1880331BZWclHH33ERx995HH/nJwc9thjD/bYYw9GjBjh8TNkyBCKinznu8aPgDeWqd9DrnZ0fuBb3p6Q046heL681naEwF3uAxruQxRLIVc7RpF2DLa2o0VRvsbQASY/blcX5VDFV6KXF4o28uXLcB9uRCVgh/um2KQcweb5CtVwH2Lka2Af9b7dXQM19SbFBZ7CrrnFpKlFzav9f2zMENziK4S0Y/9SVf0YLanYakLElyAIMSUjI8MV4Tr33HMBlUbZunUr3377Ld9++y0rVqzg+++/Z82aNWzfvt213xdFRUUMHjyYIUOGUFFRwaBBgxg0aBCNlfsBkwEozmsGgudnvFM4QdOOluE+HM+X7YIZqMt9YwDPV6hpx1D6fEHkF5+2dpO6RtWTKdj6eaD6ff24XVU8hp12TFCH+0DVjiEZ7n2lHcP1fAVpNREr8RVptWOwLyWapjGy3GTFerXA9qQ9PW+3C2+71WDMUHd7mEDPzbtRcbRI5EsQhF6JpmmUl5dTXl7OkUce6XFbbW0t33//PevWrXOlK9evX8+GDRvYtGkTtbW1fPfdd3z33XeeJy3QYdJy6GyhvH8excXFDBw4kAEDBrh++vfv79r269eP3IL+wCjXKWLl+eroMH1eMMsjbDURatox1EhFpJEv1/qMBYGrQi3Gj4A3l8PX61QXc00LLtpSIe0YShNan56vCI3cviKWOVlK5La2wW5nqjdWka/qGHu+AEYOUiJ7/VYf4stPj7cxQ1QaFEJbFHxQiBHtYKiCFJPm1tDSr4lAxJcgCEmlqKiIKVOmMGXKlC63maZJZWUlmzdvZtOmTWzevJlt27axdetWHFsrebtqB2kta+jMzKSmpoaamhpWr14d4NHS4GC3AvnwvQUcdNDf6NOnD2VlZZSWllJcXExJSQklJSVs2jAZGM/qtVtZtaqWwsJCCgsLyc/PJz093XUeKypSmOe5zJEr8rUbvNujxcJwH2rkK9JWE6G2mbDYe4S6yC12BjFLCoJ3H7c3vk0EUS8vFKc+X5qmUZhrUl3vFuvRtJkAm+E+hMhXR4dJS6sSzNk+orHeDO6vtg4fUV1/KWdrjUcgYINYdZsZk0pHkFYTgiAIYaFpGn369KFPnz5MnDixy+0trSYZ6QNIS2uhqqrKJcx27NjBjh072L59u2u7a9cudu7cybqOBkhXX61rq7ayeO1i/wMYeCGMfpBnnl/AM3+5yOOmnJwcCgoKKCgoILNwFJS8TWvjDo477hfk5+eTm5tLXl4eWWm309Kaw+13/ZuRQ0vIy8sjLy+P6toTgRy+/fpT6nZmkZeXR35+PgUFBWRnFgBazDxfkUZoQm0zYWFVPC5dobbBUo6QItWOQSJfpul7OapIm3f6e90K81SK0EpTR512DCPyZf8yEEqUc3A/JZA27+gaTfIn2sfYKh4DRUSP2x9e/hjOOSo2USpJOwqCIMSQ7Cz3h3NZWRllZWWMGzcu4H0GnNDpqnY864yfcdERY9m9eze7d++mpqaG6upq1893O0fxeSOU9B1Of21P6urqqK+vp76+nubmZpqbm9m1axfkFcAUaGnYyYKPF3g+4JS5kDeWux+YD4221On+uyEjhxNnHQXt1Z73GfM09D+d8y64iCs73nZF3KyfgoICCgsLWbfh90A5r748n7Wft1BUVOT6sUfwcpwGp3CjS5VhRr6s/mtWlCiY2R5UJEnTlCDp6DBDWiA9GnxWO1qRLz+eL7UouZUajOHajl4RS0tsbdkdvAt8KIQT+Qon5QgwuJ/abt7Z9TbvpYUshg5Q897SGjjtuNdwjcX3x+59IIZ7QRCEJFOY5241MXRwHw455BC/x7613OSY35hM2/9w/neHO51pmiZNTU00NDRQV1fHx1+ZnH8njBszmFtvfJWGhgaamppobGzkznfzWLcbjj/5YoYVf09jYyONjY3Md+RjAtP0CTQ3VtPQ0OD6qTPVVaKhsYOG7T/6fzJTLoM8+Ptfb4Qm/+nWjBHXweCb+O2f5vPEbQ+40qx9+vRx+eGsn0GDBjFgwAAyMjL8XkT9kZ+rMWKQ6VrfMZTIl6ZpFOQqz1x9k2e1aDyIJO3oq7s9ROH58pNytsSWVREYK/FVXa/es4EiWqFGUS0qnOIrnLRjerrG6AqTb9dH/9zCoUdFvnRdnwLcBXQC24GzDMNo03X9NODXQDNwnmEYm3RdzwbuAUYDtYZhnKjregHwJNAPeN0wjFujeyqCIAjBsVc85ucE/nbtr9WEpmmu9GG/fv1Yud0ETIZWFHP88cd7HLtkdyfr3oXDjj6by89UDuKODpPnfmKiabBsyYddLooX397JvFfh77ffzeyD/khdXZ3Pnz++PpCaZjjnrFOg5Udqa2tdP1YUr6qqivZd78Lgm6jsmNCl1YcvNE2jX79+ZAy7AnJ+y1effcBf/rKMIUOGMGTIEIYPH86QIUPIyOh6Cdl7hHtx7VBFW2Geu8ov3uLLVe1oE1/Blhdq8FHpCJCTFZmR21e1I9giXzFKO2ZlauTlmDQ2KwEZ6HyxjHy51/XsetsFP9V4ZIHJtL1Ce5xY0NMiXw7gKMMwGnVdvwU4Udf1l4ErgYOBqcD1wEXAr4AFhmG8arv/hc59D+u6/pau608ZhrE5ivEIgiAExVN8BT421CarrkW1ffhYrHL57dXuRrJ2o7yvaESOUxhkZBUwfLh/BXPzO53QDHfc9if6lfi++JumSXVNA4Nnd9LIWP7zyiK0tm3s3r3b5YOzfnbs2MG2bdtcnjlymmAYrPjyY6579SaP86anpzNs2DBGjhzJyJEjGT16NHvuuScDiw8AlMgMR3xBYnxfrrRjGJEvX34viNzI7U/oWAZ7qy9cLKJDpYVK7FXXBT5fqEsLWVQ439ebd3aNqrk9X13fk1ecqnHFqYmtOOxRkS/DMLbZ/mwD2lGRrRWGYbQCi3Vdv915+9HAAF3XrwSeNQzjX8D+wNXO298BpgMvIAiCEEfsF6BYNVn1ta6jhdXlfnuVuzoyWGd6V6uJEA33vnqFWWiaRmlJAQdP7OR/n0B7/gGcfnjgi197ezs7duzgyvvSmP8xnHzC4YzKbWLTpk38+OOPbNiwAYfDwQ8//MAPP/zgeed+Z8HYJwD48N2XuabacK2KMHbsWPLyuiqARIkv0zQjSjv6qnSE2C4vBD4iX7nRi5SSApXGrKqHIQMCjCnMyFdBnkZJgarO3F0DfUvct4W6JFWi8C6MME2TmpoaSkpKkjamqD1fuq4PBY4A/oyKdtXabrY+bYYA9wN/AN7TdX0BUGI7tgbrq5LnuS9CRc6YO3cuM2fOjHa4QWlra8PhCLBglRBzZM4TT2+e83RKsBqytjRV4nA0+z22oUkDBlJd34nD4X8V4R+35ANFpJn1OByepWXZWg5QytZKzTXnjl1pwACy0jt8nrelpQAoZOfuWhwO32E304SmFrVad+XuLdRU+R0eAJNG5vO/T4pYsKieg8fWBjx24/Z0Xl2ax8IVSk0evP94TjlkpMcxzc3NbN68mY0bN7Jx40bWr1/PDz/8wMpNO9nhPGbtqk/56ztuR4mmaQwbNsy1XujYsWMZN24cWWk6kM36TbuoKI5dbsj7fd7WDqY5iPQ0k23b3PPe0lwE5LNrdzUOR1cFuGFzFtCHDK0Fh6PStb+pIRcoYXd1Iw5HTWhjaof2DjWGHdu3Yg98aqYahxU56mj1PZ5wyMvqA2Tx/fpd9MnxP7c/OrKBMtJoxuEI8mZyMqCkL9X1mXzx3Q7GDVPKta2tja07m4EcOlt343AkP9xUVan+j79ft5ljj72ETz/9lDFjxjB//vy4Pm5FRYXf24KKL13XB+I7IjULFe16Epjj9HtVAfaiZCuDXg28ZxhGu67rS4A9AevYapQQ2+D9AIZhzAPmOf/sujhaHHA4HAEnTIg9MueJpzfPeb+yTtfvQwaVUVHhP7qg0ikmTS1pDBhQ7n+dvXR1zsEDCqmo8OzLsPdo5QfbvDPTNed17WpfQV66z9ehX5m6PSunkIqKYp8P2dTiPCYThg4J/lqecKjJrc+ZfLImn4qKriEJ0zT59wL49wKTZSvc+weUwXGHlFJR0bXj5ahRo7rsa24xyT+qk85OjQvOPZnB6VmsXLmSFStWsGbNGjZs2MCGDRt46623XPdJn/AaFB/LE0+/RMOMDKZMmcK4cePIzMzscv5w8H6f1zeqOcvO0jz2lxar1y+voISKitIu58ndoO7XpyTb437lA9X+9Iw8KipCM6vVNqj75OVoDB7s+boN6tfp8feQct/jCYcBfdQ5M3P6Bnyv532vxlVWnBPyZ8Pw8k5Wb4ZWrb/r3A6Hg6Y2FdLbY3ifgI8ZT9avX8+CBQtYsGABH35aDeMWs3nLLjZ/8Sag+guWl5eH1FYjHgQVX8704kHe+3VdTwdeBm42DGONc/daYJyu61moKNjXzv2LgX2BhcBE4CFgGXAk8DAqcvbzKJ6HIAhCSISTdtQ0jaJ8k5p61eXeX78rl+fLx/V30p7qMb/dkMlXa00m7qEFbY4aSod7f+0K/DFljPK7rdkEW3aZznSom6ffgQv/rr7j5ufCCQfCGUdoHDlVGbdDJSdbY1S5xveb4YgZUzjjCN11W2trK6tXr+abb77hm2++4euvv+bLL79kS0s1AG/872PeePIpdZ6cHCZOnMiUKVPQdZ2pU6ey1157eTS3DRdfKUeI3vMVTtoxUFVhYZ67A7z6O/Tz+sPVbiJIry8r7Rjsf8KOy3S/w3N/uP3hYoFpmnzyySe88MILvP7666xatcp9Y+5YAIpLB3DnI49w8MEHM2rUqKQJL4gu7XgqcABQqOv69cADhmHM13X9TpTIagbOdR77N+AxpzH/LcMwftB1/SHgKV3X5wCvGYbRO3MggiAklHAM96B8XzX16sffxcTXuo4WhXkac44xuedF+OeLJg//TgvY3R5C63AfbmuAzAyNgyaYvLUcFn4JZxzhefsDL6uL/nXnwu/P0siPwm900AT4fjOMHuy5Pysri3322Yd99tnHY/95f2rgiXfghJPOJruylc8++4x169axfPlyli9f7jouPz+fyZMnM23aNPbbbz+mT5/OkCFDCBVLfGV5ia+Qqx1j4PkKtKant9gKZT3NYLgarQYpGnG9n0IU82BvN+FZ7elveaFYY5omX331Fc899xzz589nw4YNrtuKioo46qijOPbYYxk/+VimzYXiskHMmTMnvoMKkWgM988Cz/rYPx+Y77VvO3CM17564MRIH18QBCESCnLd0YVQvuWHYrq3qiH9tUmYe5LGPS+aPP0O/O0S022492OUt/pHBTLch7q0kJ0Z+2q8tdzkgy9MzjjCfbFcsd5kybfq4v+7M6MTXgD3Xq5x1WkwfkRo5+nfR70Q+x90JL876ygAqqqq+PzzzzEMA8Mw+PTTT9m4cSMff/wxH3/8seu+FRUVTJ8+nenTp3PggQcyefJksrN9T0qr38iXek+0tftuGRFJ5GvzDpNH34TLfgZlRe5zBo58ef0d5fJCYI98BW6H4a/3WCBcXe5t7SZM03+fr1ixbds2nnzySR599FFWrlzp2l9eXs7s2bM58cQTOfDAA11p6+2VKqXaU1pNCIIgdDs80o6hRL6cF6/aQOIrQKsJgNFDNH6ybxMffJnDw6+7l+HxJ5xCWQg73Oo0gJ9MUtsPv/Dc/9BrSoyeNVNVsUVLXo7meo6hYKXb6hrdAqG0tJTDDz+cww8/3HXcjh07MAyDTz75hOXLl7Ns2TIcDgcvvvgiL774IgDZ2dlMnTqVAw88kL322otZs2ZRWqp8U/FKO/pqYXDPiya3Pat6yV15mnt/QPHlJbZi02pCzW3Ika+wxJfa2tOOza1K5OZkWQtax4b29nbeeOMNHnnkEV5//XU6OlSYsm/fvsyePZvTTz+dgw46iLS0tC73lbUdBUEQkkwkaUcIHPmqbfQ81hcXHNXIB1/mcN9LJrderC5KwcRXoG/qkUS+Ju+pnv/3m8Gx06Sin0Zzi8kT/1O3X3hccjwwlsgItvxR//79OfbYYzn22GMB6OzsZM2aNSxdupQlS5awePFiVq5cyaJFi1i0aBGgfHsTJkzg4IMPZti444CZXcVXkLUd65uUOC3wiggGinxtcxZFbtjmGXEKJJq7RL4S6vkyneMK/T3gq8t9Vb0SP7GKem3ZsoWHHnqIefPmsWXLFkD1mDvhhBO44IILOOaYY4IWZvSoPl+CIAjdEQ/xFUJapyiMtGMgj86hE1rYc4gyvD/3nrrQRWO4jyRSkZGhcfAEkzedvq8zZ8KLC9WFecoYmDwmueIr3D5faWlprpYVlpensrLSJcTef/99vvzyS7766iu++uorKFgGk2ay9vsVXHbZg8yYMYNDDz2UzAylIvyt7RiJ52u3s/OEY6fn/kB+v3iIr7A9X5FEvmzPsaYhevFlmiYffPAB999/Py+//LIryjVmzBh+8YtfcPbZZzNw4MCQz5eZodYPbe+A9nbTf9VyAhHxJQhCr8J+QQslZeeKfAW4eNUEqHa0SEuDX52k8au7TV5bEvjxs0MwcgfzjfnjJ5M13nT6vs6cqTHPmXK86PjkXZCsdFtdmAt/+6KsrIzjjjuO4447DofDQVlZGZ988gkfffQRr3ywi8/aobmhmvvvv5/7778fgAGTboSC61m5ah3bthV2ubBH4vna7az48177MJCx3f7eTEsLTwj5I+TIVwSG+9JC9QWitgHqGk0K87SoxFddXR1PPvkk9957r8vLlZGRwezZs7n00ks59NBDI6pQ1DSN3Gy1zFJzKxSkgPJJgSEIgiAkDivylZOlFvoNRrC0o2maAasd7Zx3DFzzkDvCE02H+0giFQAz9lXbD7+AVRtNPvpKRXS8qx8TSTw73Ofm5nLooYdy6KGHcsCxJkdcYTJp0t6cfOqf+fDDD1myZAnbtzpgNLz77gcMevBixowZ47rPoYceSkOzambrLb6s18+X+LLaLXhHvhoDpIvt4qsg1/fSU+FiX1w7EA0RvJ80TaOir8lah3qeY4dBdb0ac1kY4uv777/nvvvu49FHH6W2Vk1ceXk5F198Mb/4xS8oLy8P/WR+yMnCLb4SuKi3P7o60wRBEHowlvgKtZ9RcYG6mKjmmF1paoGODhWtys4KfLFUbSfcf0djuI/E8wUwabS6yK91wI2Pqud0xuGW6T05JGp5IavasX/fYq699lreeecdqqqquOYPvwGgfPAw8vLyWL16NfPmzeOss85i8ODBvPr6ewB8suwDj3YGoUS+tlaqhdQtQq12jEXKEeLbagJgcH+1tVKPoUa+Ojs7WbBgAccccwx77rknd999N7W1tRx00EGuthF//OMfYyK8IPV8XyK+BEHoVVgXhUDmeDtWNMtf5MvVZiLE8809yS1y/FWDhdTnK4JqR1C+r0Mmqt/nv6+2yUw5QnzE1+YdJnWNns/LV7VjVlYWe43dA4AZP5lJdXU1S5cu5dZbb+Xoo4+moKDAFRW6585bGDFiBMOGDeOcc87h6aceAbq+Th0dpnuJoA7YblutJ1TDfSzaTED4TVbDjaR6+76Cia/KykruuOMORo8ezXHHHcdbb71FTk4Oc+bM4fPPP+fjjz/m1FNPjXp1A2+813dMNpJ2FAShVzFsoMaffg7jhod2vOXj8iu+grSZ8Gb0EI1jp5u8scz/fcLpcB9u5AtUv68FS1U0ZuIeoI8N/xyxxIpGxkp8VdeZ7HmWyfhhZXz6sHu/lcbN9vLJuaodOyAzM9PVN+x3v/sd7e3tTDq/kW9/hIMOmMyKpZ/z448/8tRTT/HUU8/CwXNobOrg+ONP5KCDDuSAAw5g5J46pul+YRw7obyv+j1Q5CszQyM7y6SlNXaRr8I85R+rbwpsNo80jV3hfF4Ol/hytgopdD+OaZosXryYf/3rX/znP/+hpUW9eYcPH86ll17KBRdcQJ8+fcJ74DBxtZsQ8SUIgpAcrjsv9EhPMMN9KGZ7b+6/UuOfL5qcNdP37aEY7iO9WALMmOT+/aLjtaQuswKxj3xt2KbE6bcbMp3rc6rnF0mfr4yMDEhXL+599/yNvUfcyjfffMOiRYv4+OOPme9oAy2T1xe8xeuvv6buUzgW9nUvkPnlyp3oY/uhaZpzTU7/LR0Kc4mp+EpL0yjOV5G46nroW+L7uEgjqe5Gq6qlRrWz1URZkerL9swzz/DQQw/x3XffAcondtRRR3HZZZdx7LHHRrVcVDikWtpRxJcgCEIALPFV60cYuNpMhHGxHDZQ4/bL/AueUAz31kU8kkaWk0bD0AHKZO1PACYSl/iKQbUjuM3uza0aVXXuZaFi0WQ1LS2NiRMnMnHiRC677DIWHNVJfRP866HH+cL4iCVLlvD1Bs83w0Vzb+SGuS8zffp0dhb+HtBJoxnomlsszINdNbETX6BSgEHFl/Ucw0x3enu+dteqhbwffvA2rjjtGlebiIEDB3LBBRfwi1/8ghEjwujAGyMiWQoqnoj4EgRBCEBRkMhXKA1WwyVeHe4t0tM1lj8IHZ3ugoJkkputUmMtrdDWbjqX+4mcSpu/afNOm/hyXnjDXtvRT6sJUBf1+iY48aTTuejnZwDwwnsNzL7JdkzxKLau2spLL70Ee8yEQTrX/uEKnrx1IVOnTmXKlClMmjSJfffdl8I8FWWLpfgKxfcV6fvJSjt+s7qSM874FW98dx4UH8nXny0kQ9P46U9/ygUXXMDxxx8fcx9XOEjkSxAEoRsRrNVEsHUdIyFeHe7tDOyTfNFloWkahXkmNfUq9ehvAfNQsSJfoJa+mTBK/d7qjGxFGvkq8BEV8tVuoqk9DzDRNLXW4alnX8G1s49n6dKl3PLiGNZUQ7rWyqpVq1i1ahVPPvmk6745+30CWVNYtcLghRd+ZPz48eyxxx5RCZdQ2k2Ek8aura11meNfWrAMsl5j49Z2Ni5/Dib+HwBX/noOv7/0Mfr16xfxuGOJRL4EQRC6EbE23IdCvDrcpzKFucRHfNn6bEWSduzsNF0d7n3Nta+LutXdfvRgtaKBYxfsueee7Lnnnry2tpM1C+GJRx9kz7JL+eSTT/jiiy/44osv+Oabb2iu3wllYCx7n9nP/UGNLzOTPfbYg1GjRrl+Ro4cyZAhQygvL6dPnz4BfXtW5WE4kS/TNKmurmbDhg1s2LCBdevW8cUXX2AYBmvWrLHdMw0ObIOs/tx2+z3cs3gCm3bBheefTL9+qSPwJfIlCILQjbC8XLUN6kKcluZ5Qalx9v8KtLRQuGRkaKSlmXR2+q9Qi7TDfaoSS9P97lp3Xy3LCA7Q0qr2B6p29MYeYfR+7cG3+KqsU4+zz0in+LIJQEs0Fxdmous6uq67bmtra+OnV9fxzhdw0AH7Ujz+p3z33XesX7+elStXurq+e5OVlcWgQYMYOHAgpaWllJaWUlJSQmlpKfn5+Wxa/1NgH15+/UNq1q2lra2NlpYWmpubaWlpoaGhkYamW4A0jj5qBpW7d+JwOFwNT3093sSJE5k6dSpHH300lz6WzuadcPIZc/nr+0rBxmptx1gh4ksQBKEbkZGhkZ+roh8NzV29OLWuyFdsv+VnZ6oLhb/lUHpc5CvExbVDwR752rTD/bs78uX5WgWKfAXye4FNfNku6lbka8IojRcXmh7RN0s0+/JWZWZmMrS8BL6AU048il/PPlqNoaGBtWvXsm7dOtfPDz/8gMPhYMuWLVRXV7Nx40Y2btzoe5AjMmDwPjz7nzd5dvNtXW/XsuGgW6GzmcWLP3Ltzs/PZ8SIEQwfPpwRI0awzz77oOs648ePJyvLrWD/+kYnm3equY7F2o7xQNKOgiAI3YyiPLW4ck19V/EVSauJUMjJUuKrpQ18nTpaz1eqEcvIl7fh3iJY2tGX4d7fotoWPtOOTvE3qly9PvVNaoWEonwtqGie/RONr9eZHL2fe19+fr6rwtIXTU1NbN26lW3btlFVVUV1dTXV1dVUVVXR0NDAxxv3ZvFmmDT1J0w+qpLMzEyys7PJzs4mJyeHzvRS/vwuFOSm8fqHH9KnTx8GDhwYNJ1pMbg/sAJWboSOTo28HMjKTJ2UI0jkSxAEodtRnA9bdyuhNdjrtnA73IdKMNN9NNWOqUhMxZeX4d4iWLVjoMiXL7M9+G7eaT1+n2JVDWitfViUH3wZn6OmaRw1LTzhkpuby8iRIxk5cqTP2+9/yWTxnSb7HXgUD1x1TJfbN203+fO7JsVFWRx66KFhPTa4u9x/u16lW8NZ1zFRpFrkS5YXEgRBCILLdO+jWsy1qHaMxVcw071EvvzjkXbcqczjEFm1o5UGDSvt6Hz8skKocAoTxy61DbSwdrwI1moiWiFf0VeJxW9+UH+nWsoR3P3wrP54yUbElyAIQhACNVqtjUO1I7hN4f4arfY0z1cslxjabRNfDU3u1yiSasegni8frSZ2e0W+wG26T8brFmxx7WjHZEW+vl7n+XipRKqt7SjiSxAEIQiBGq3Go9UEBE879rjIlyW+ojTcm6bp8nyV91EmLsv3Fcrajt4E83z5uqi70o5F/iNfiUwXxzvyZXW5t86fiuLLlR5OEc+XiC9BEIQgBGq0Gk/DPfhPO/Y8z5dKC9U1RpcWampRIis7C0YMVKEsl/iKR+TLS3y1tpnUNaqO/UX57pScY6fpGh8kNvIVrMlqpEsLWVjRPYto+7TFA5fhXiJfgiAI3YOA4iuCtR1DoddFvmLk+bJHnVyRL6fp3p/4CrS8UKiGe+t1sqI/ZYWqL5g98tXWbtLWDunpbsGXCII1WQ1WBBCMci/xVRrjLyKxQAz3giAI3Qxr/cPaBs+oTGubSXOruphGGjXwR6DIl2maIr78UGkTP4PKlJratEO9bv6qHQMa7p3jCTXyZfd7gdsP5dhli3plE1ILh1hhj3xZxQd2GqOMxmVlagwoc/9dWphabSYg9VpNiPgSBEEIgr/Il2XkLsqL/cU0kOG+2eZd8tV1vTsS68hXWREMKusEYpR29Bf58jLcWw1WrXYLVkpu8w53hCnRgjknWyMnSz0/awx2oo18gWfqMRXTjhL5EgRB6Gb4M9zHy2wPgdOOsbhYphqxEl8u8VPU1XAftNWEz7SjihTl5/gWuTlZni0MKr0iXwP7gKbB9ir3+yUZr1sg31e0kS9wR/ggNQ33EvkSBEHoZviLfLn8XnEQX4HSjj0t5Qg28RVltaNH2jHEakfL89XR0TUtZ/X58l7ZwMJv2tEZ/cnM0BhQCqYJ67eqfcloDxKo3UQsxHx3EV8S+RIEQegmuJqseqcdnVGahEe+elilI9jWdoyV4b7Y7fkKlnbUNM1vl3tLfPkz3Htf1Hfb0p4Wlun++81qmwzxFajdhBXdy/MT3QuFin7u+6ai+JJWE4IgCN0MV5NVP5GvWLeZAFvky4f46pGRrxj1+aqstZa40SgpMMnJUq9TXaPpV3yB/4rHYOLLO/JlPX6fIrcYsfxQ3292ipxUSzvGoPGrPfKVissLSdpREAShm1HkL+0YT89XgLRjT+tuD1AQ62rHIuW1clUb7vRf7Qj+TfdWJC5U8eVd7QipEfkK1G4iFpHUVE87iuFeEAShm1EcxHAfD89XoLRjj458xdBwD+7u65t2+E87QgDxFWbky7vaEdyNVi3xlevlOUsE8Y58VdjEV0kK9vmSyJcgCEI3w264txuyXWnHuBju1QW7pS1AX6YeJL6ys1Tqr60dWloj73JvN9wDDHGKr807bdWOPsSPP/FVF27a0fn4viJfG7apbU+MfA0doNpxVPRtJyMj9dqfpFrkK4E9dgVBELonOdkaWZkmrW0qdWX1dvp0lRIJwwbG/mITSuSrJ6UdNU2jMM+kqk5Fv3wJpFDwbvVgpcM229KOPiNfftZ3dKUdg1Q7Wq+JFfnqYzfcOz1fHc5zJ8dwrwEm1fUm4Pl+jXZ5IYDcbI0l90NNVSUwMPITxQlZXkgQBKEbYi0fZKUa6xpN/vep8hXNOjD2jxfIcJ+sZp3xJha9vrwjX4OdVXg/bjddZnpfS/sESzsWhun58lXtaJGMiGXAyFeM+sZNGKUxcpCPZmkpQGaGRnq6EsBt7dGtHxoLRHwJgiCEgHe7iQVLlTA6YG8o7xuHyFegPl/OC31PSjtCbHp9VXqJHyvytc6httlZvlcjCFrt6Cfy5d1qotKrzxd0XXg6ma0m4tVktTuQSqlHSTsKgiCEgLfp/sWF6tvzyYfGx98SSof7nhr5Ov8Wk31Gmows1xhVAUdMgYF9gs9zU4ta8zIrUwmJamzia4vaZvm56vmKfHV2mq7lhfwJXfsFvbFZrfWZneUpZIryVUqvock6V+I9USE1We3h4is3S70GTS3+m+YmChFfgiAIIWA33Tc2m7yxTP198qHxebxQOtz3tIvlwRNg2Qr44nv1A0rg7jUMvnsyuGBxRb0K3dEte7Uj+PZ7gW/x1dSiOtPn5UB6ur/lhdS2udWz0tEeXdM0jYq+Jms2qb9TrclqTyzg8IVEvgRBELoZVtqxtgHeWq6iBVPHwtABSYh8OdcRzM1KvaqyaPjbJRqX/UylCH/YCuscJnfMh5Ubob7RpCAv8PP1NtsD9CtRkbBWq82EHyO/L/EVrM0EeF7QXZWOPhaWruiLS3wlI2JZIpGvlGo3IeJLEAQhBOyG+3cNJX5OmRE/8WNVVAYy3Pe0i6WmaQwbCMMGwmFqD68u7uS7DUq4TB4T+P7eZnvrnIP7mfzgTDv6jXz5qHYMV3y5Kh2Lux5nReAg9Qz3wVKrPYVUWt8xYvGl6/oU4C6gE9gOnGUYRpuu66cBvwaagfMMw9ik63o2cA8wGqg1DONEXdfPB64FHIDDMIyzonomgiAIccSKfO2ogteXqt/jlXIEt0joLQtr+2PMEPhuA6wORXz5qDQE5fsKKr5iEPnabUt7emM33SdDNFtfHmoboKPD9Eij9lQx700qre8YTeTLARxlGEajruu3ACfquv4ycCVwMDAVuB64CPgVsMAwjFe9znG3YRj3RjEGQRCEhGB5vl5caFLbABP3gFEV8Yt8WRd87yWNoPd4dADGDFXb1T927U/lja82D+C59I2/tKOvaker5UUg8WUtVdTaBjur1e++Il+qy721gLX/88WL9HSN4gKTmnr1nrLmqK1dteBIT/fdgqMnkUppx4hbTRiGsc0wDKsbSxvQjopsrTAMo9UwjMXAPs7bjwYO1nX9Q13XL7ad5lJd1z/Wdf30SMchCIKQCIrz1YX/01Xq71PiVOVo0b9Uba0Lup3eFPnac4ia5zWbgx9b6SfyZBdf4VQ7hhL50jTNFVHZsstaVLvrcfZeX8kSzb7aTdh7fPlqwdGT6FGGe13XhwJHAH9GRbtqbTc7v0swBLgf+APwnq7rC4CXgSeAfOe+hYZhbPU690WoyBlz585l5syZ0Q43KG1tbTgcjrg/juBG5jzxyJyHT0dbLlDi+vugvXbgcLT7Pd6bcOe8o1kDBrK90mTzZgf262JldSmQQ1PDbhyOFPgaH0fKcjOBvny7rg2HY1fAYzduKQQKyKQWh6PBNecFWXmACkdpZgsOR2WX+3a0qzndtt09pxsdOUAp6VoTDke138fNzhxAc2sa3//YCOSRbqrHt5NpqucBUF+3E4fDRz45zhRk9wUyWb1uB9mmeu9ur0oDBpCT2YHDsTXg/UMhpT9bOtVrvHlrJQ5Hc9wfrqKiwu9tQcWXrusDgRd83DQLFe16Epjj9HtVAXbNbwVwq4H3DMNo13V9CbCnYRjvO2+r03X9A2AvwOOVNwxjHjDP+WdCWtI6HI6AEybEHpnzxCNzHj7DK0zsrQ9mTBsQ1v0jmfO8nE4amzWKSsspynerL1PrBGBweR8q4pj6TAVyCtS8r9+WSXl5ecDoTJup5mX44GIqKkpcc77Pnu7XrrAg2+frUJiv7ltU7J7T7Fx1v36luVRU+F/AMy+nk5oGqG5UxqqRQ9Tje5DlHsOwwf2S8rr1K+uEjZCV19/1+M2ocRXkpcfkMyGVP1tKi9VrnF9QlvT/m6DiyzCMbcBB3vt1XU9HRa9uNgxjjXP3WmCcrutZqCjY1879i4F9gYXAROAhXdeLDMOodZ5nP+CB6J6KIAhC/LAM9wCnzEjMYw4ohfVblcm/yHbt702erz7FGn2KTXbXwJZdXZfqsRPIcG8R1HBvr3Z0GmuCNeS00llWYM6X52tAKaSlQWdn8tOO9opH17qOPdxsDz3E8wWcChwAXO/0cp1mGEYbcCdKZP3Z+QPwN+D3uq4vBpYahvEDcIWu68uAJcDLhmFsiGIsgiAIcaXYJn7i1dXeG8v3tb3Kc39v8nyBqngEd58sf4RkuPcjvnwZ7kPxfIFNfO10Pr6PaseMDI09ByuR19eHOEsEvrrc95alhUB1uIfUEF8Re74Mw3gWeNbH/vnAfK9924FjvPbdBNwU6eMLgiAkkiH9VUXYmCEwYVRiHrN/idru8BJfvaU1gMWeQ2DJt6rdxE8m+z/On+G+f6kSV+0d4TZZVWnCgtzAYtsSX5ao8RX5Anj1rxq7aqCkMDkpL5fh3kfkqze8l3qU4V4QBKE3MLi/xsJ7VBQlUVVhA8rUtkvky3nxyPUjJHoaY4aoNg3B2k346nAPkJamUdHPZOO22Fc7gvuibuGr2hFg9BCN0UMCnyuelBaqeayqd89jb0phu9KOKSC+okk7CoIg9CoO3Edj2MDERS2stGNvj3y5e30FPs5Xh3sLK/UYUZPVED1fFt5pz1RBIl/OIoPWhNTvBUTElyAIQooyoFRdLLZXel4sep3nyxJfATxfzS0mjc1KROX7iFQNcS7v4zftaC0vZBNfoTRZBc/XoSAXsjJTswLV8nztqHbv6y1LC0HPMdwLgiAIccQV+ap27+vsNF2eFe+IS09lVLmqFNywDVr8RC1cUa8i32nhkCNfURjuwb/fKxWwvIovfwyfrVbz2LsiX2qbCp4vEV+CIAgpii/DvV14paWlZoQl1mRnaQwfqNo0rNvi+xh/ZnuLn0zSyMqEaXv5nrNYVDsGevxUYMIojV+fop7jebeYtLSaHh3uezoS+RIEQRCC4stw35siFXasdhP+fF/+enxZHLu/Rv3/NGb/xLf4ipXhPpUjXwC3XKQxejCsWA83PGL2rlYTIr4EQRCEYPgy3Pc2v5dFMNO9lXb0V2kIkJnhP1Jo3dbW7k5rRiS+UtRsb5GXo/H4NRppaXDbc/D+56Zrf09H0o6CIAhCUPoUKa9TVR20tjk9Or2oNYCdMUOtBbb9eL6CRL6CESjyFWqH+2geP5Hsv7fGb05XadyFX6p9veH9JJEvQRAEIShpaRr9StTvO6vVttdGvoKkHXcH8XwFw1e1Y8iRL9trkeqRL4ubLtAYP8L9t68K0Z6GRL4EQRCEkBjglXrsrZ6vPS3x5afdRGWtioiVFUWWPvOudjRN0yW+gq17mJvlfsw+ET5+osnO0njiGs1VaNAbGvZK5EsQBEEICe/1HXtbd3uL8r4qArW7BnbXdE09Rpt29K52bG5VabmcLLUuYyC6W9rRYvIYjX9eriJgh+6b7NHEHxFfgiAIQkh4t5vorZEvTdNc0S9fC2yHYrgPhLfnK9SUI3SvakdvLjlB49vH0xjcv3tE7KJB0o6CIAhCSHi3m+itni8I3Ok+1ob7ULvbQ/f0fPVGrGixrO0oCIIgBKR/iYpI7Kjq3dWOYC2wjXOBbU+iNtzHKPLVndKOvQ1LJEvkSxAEQQiIFfnaIZEvt+neR8Vj1JEvq9rR6fmqtyJfQdpMQPfq89WbcUW+xPMlCIIgBMLbcN9bPV9gazcRwPMVq7RjJJEvTYOSgsgeX4g/ds+XafruF5coRHwJgiCkMN6tJiTyBWsd0NHhvni2tJo0NKmKxWANUf3hXe0YifgqKYD09J5vXO+uZGSo1hqdnZ793JKBiC9BEIQUpkvkq8W5HEx277vIF+RpVPSD1jbYuN29v8oW9dK0KPt8eUW+QhFzlhCWlGPqkyrtJkR8CYIgpDD2VhOmabouGr0x7Qi+O91Ha7aH6NKOg/uplKNVjSmkLqnSbkLElyAIQgqTk61RlK/SYVV1bs9Xb0w7gm/TfbRme4hOfA0bqPHNYxpPXdf7opHdDYl8CYIgCCFhj35ZPYp6Y6sJgH1GKoHz2Fuma7HxmIgv72rHJnXugtzQBNX4ERolhSK+Uh2JfAmCIAghYW830dsjX+ceBSPL4au1cNNjTvEVZXd7iK7JqtB9kMiXIAiCEBJW5Gt7Fb3e81WQp/H4NRqaBrc+DUu/NWMS+Yqm2lHoPuSkSK8vEV+CIAgpTn9buwmrw31vW1jbzkETNH5zumoZcO5fTH7criJgZVGk/aLxfAndh9wU6XIv4ksQBCHFca/vKNWOFjf/XGPvEarn14Ovqn3JMtwL3YdUWd9RxJcgCEKK417fUTxfFtlZGk9ep5GZofp+gYgvITguw72kHQVBEIRA2A33Tb14YW1v9h2tcdMF7lRjVIb7LtWOaiviq2fhMtxL5EsQBEEIhN1w39iLlxfyxW9OhxmTICsTxg2P/DxdDPfOasdIlysSUpNUaTWRkdyHFwRBEILhM/LVyz1fFhkZGu/cATUN0KdYDPdCYFKl1YSIL0EQhBTHvr5jq1McSOTLTUaGRp/i6M7hV3xJ5KtHkSqtJkR8CYIgpDglBUocWI0/wX0REWKDXXyZpkmdU3zlS4SxRyGtJgRBEISQ0DTNFf0CdQHRNFnKJpa4xFcHtLRCR4fykWVlyjz3JHKz1evZ1GImdRwivgRBELoBlukexO8VDyzDfUcHrqiX+L16HqliuBfxJQiC0A2wTPfQu7vbxwtN00h3CrBq51qRIr56HqliuBfxJQiC0A2QyFf8sXp9VYn46rGkiuFexJcgCEI3wCPyJZWOccHyfVXVq62Ir56HGO4FQRCEkLGWGALpbh8vXOJLIl89llyJfAmCIAih4l3tKMQeb/El3e17HjkS+RIEQRBCxZ52FM9XfBDPV8/HFfnqrssL6bo+BbgL6AS2A2cZhtGm6/ppwK+BZuA8wzA26bp+PzDOedf9gAqgFXgS6Ae8bhjGrRE/C0EQhB6O3XAvka/4kOESX6oHlIivnkdPaDXhAI4yDONQYC1woq7rmcCVwAzgeucPhmFcahjGDOAcYKlhGJXAhcACwzAOAmbouj44irEIgiD0aDwiXyK+4oJ4vno+qdJqIuLIl2EY22x/tgHtwGhghWEYrcBiXddv97rbKcALzt/3B652/v4OMN12GwC6rl8EXAQwd+5cZs6cGelwQ6atrQ2HwxH3xxHcyJwnHpnzxBPtnKs1HQcB0NnegMNRG5uB9WDCnXPN7AtksmVnE5BLZ3sdDkd93MbXE0n1z5bGunT2GVHKsP7tOBzVcX2siooKv7dFvbajrutDgSOAPwNTAfsnQrrX4ScBs52/l9iOrQHKvI7FMIx5wDznnwlZC8DhcAScMCH2yJwnHpnzxBOLOS8t7KSqDvqV5VNRURijkfVcwp3z3NxOAJrbVMirvH8RFRVRrtjdy0j1z5aKCvj6cYBsID9p4wgqvnRdH4hXRMrJLFS060lgjtPvVQUU2Y7psJ1nMNBui5hZx1ajhNiG8IcvCILQexhQqlJi4vmKD136fEm1oxAngoovp1g6yHu/ruvpwMvAzYZhrHHuXguM03U9CxUF+9p2F3vKEWAZcCTwMCpy9vMIxi8IgtBr6F8Kq36EvBxZ7DkeSLWjkCiiSTueChwAFOq6fj3wgGEY83VdvxNYiKp2PNd2/Mm4U44ADwFP6bo+B3jNMIzUTRILgiCkAJbpXiJf8cGqdqyWDvdCnInGcP8s8KyP/fOB+T72H+z1dz1wYqSPLwiC0NsYP1zjP5iMGJTskfRMrLRjjYgvIc5EbbgXBEEQEsMfzoYTD9aYMCrZI+mZZHpdEUV8CfFCxJcgCEI3IStTY+IeyR5Fz8VbfMnyQkK8kOWFBEEQBAG34d5CIl9CvBDxJQiCIAhAhqQdhQQh4ksQBEEQkMiXkDhEfAmCIAgCnp6vjHTIykzeWISejYgvQRAEQcBTfBXkgqZJM1shPoj4EgRBEAS6ii9BiBcivgRBEAQBT8+XiC8hnoj4EgRBEATcywuBLKotxBcRX4IgCIKApB2FxCHiSxAEQRDwFF+FIr6EOCLiSxAEQRCAzAx3daOkHYV4IuJLEARBEJC0o5A4RHwJgiAIAlLtKCQOEV+CIAiCgFe1o4gvIY6I+BIEQRAEvNOO0t1eiB8ivgRBEAQB8XwJiUPElyAIgiAg4ktIHCK+BEEQBAERX0LiEPElCIIgCEi1o5A4RHwJgiAIAp7VjoXSZFWIIyK+BEEQBAFJOwqJQ8SXIAiCICDiS0gcIr4EQRAEAS/xJWlHIY6I+BIEQRAEJPIlJA4RX4IgCIKAu9oxLQ1yspI7FqFnI+JLEARBEHBXOxbkgqbJ8kJC/BDxJQiCIAi4046SchTijYgvQRAEQQBys9W2OD+54xB6PhnBDxEEQRCEns+YoXDVabD/eEk5CvFFxJcgCIIgoHxet18mwkuIP5J2FARBEARBSCAivgRBEARBEBKIiC9BEARBEIQEIuJLEARBEAQhgYj4EgRBEARBSCAivgRBEARBEBJIxK0mdF2fAtwFdALbgbMMw2jTdf004NdAM3CeYRibdF2/HxjnvOt+QAUwC7gWcAAOwzDOivhZCIIgCIIgdBOiiXw5gKMMwzgUWAucqOt6JnAlMAO43vmDYRiXGoYxAzgHWGoYRqXzHHcbhjFDhJcgCIIgCL2FiCNfhmFss/3ZBrQDo4EVhmG0Aot1Xb/d626nAC/Y/r7UGSm7zzCM57wfQ9f1i4CLAObOncvMmTMjHW7ItLW14XA44v44ghuZ88Qjc554ZM4Tj8x54pE5d1NRUeH3tqg73Ou6PhQ4AvgzMBWotd2c7nX4ScBs5+8vA08A+cB7uq4vNAxjq/1gwzDmAfOcf5rRjjUUHA5HwAkTYo/MeeKROU88MueJR+Y88cich0ZQ8aXr+kA8o1UWs1DRrieBOU6/VxVQZDumw3aewUC7FTEzDKPaeVOdrusfAHsBHuJLEARBEAShpxFUfDnF0kHe+3VdT0dFr242DGONc/daYJyu61moKNjXtrt4pBx1XS8yDKPWeZ79gAcifRKCIAiCIAjdhWjSjqcCBwCFuq5fDzxgGMZ8XdfvBBaiqh3PtR1/Mu6UI8AVuq4fA2jAs4ZhbIhiLIIgCIIgCN0CzTQTYqUSBEEQBEEQkCargiAIgiAICUXElyAIgiAIQgIR8SUIgiAIgpBARHwJgiAIgiAkEBFfgiAIgiAICUTElyAIgiAIQgKJenmhnoKu67cB04EfUR37W5M8pB6JrutTgLuATmA7cBZq2alfo3rDnWcYxqakDbAHo+v6GcA9hmH0c66pKnMeR3RdnwFcj/qc/QeQg8x53NB1PQ14FBjp3HU+oCNzHnN0XS8E3gXGA9MNw/jW12eKruvjgH+h/geuNwzj3aQNOsWQyBeg6/okYJBhGAcD36G68QvxwQEcZRjGoagVEU4ErgRmoC5U1ydtZD0Y54XpFGCTruuZyJzHFV3Xc4CrgGOc7/U3kDmPN/sC2c7P8ZuBucicx4sm4Dicq9YE+Ey5BbgAOAr1mghORHwp9gfedv7+FqpzvxAHDMPYZhhGo/PPNmBPYIVhGK2GYSwG9kne6Ho0Z6I+KDuB0cicx5sDUBeo13Rdfwm13JrMeXzZDKDrugaUADuROY8LhmG0G4ax07bL32fKIMMwvjcMoxbYret634QPNkUR8aUoAWqdv9cAZckbSu9A1/WhwBHAItxzD5CenBH1XJzrp54KzHfuKkHmPN4MAEYAxwPzgBuROY83u1BfLlYCfwc+ROY8UZTge6412z65ttoQ8aWoAoqcv5cAlckbSs9H1/Ui4ElgDrAD99wDdCRlUD2bs4HnDcPodP5tf7+DzHk8qAYWOb2j7wOTkDmPN0cBTYZhjEWtJfxrZM4Thb/PlE7bvhLk2upCDPeKZSh/xhOof+DFyR1Oz8UZhXkauNkwjDVOr8A4XdezUKmZr5M6wJ7JOGCSrutno9IDFyFzHm8+AS53/j4JZWuQOY8/Vc5tNdAXGCZznhDW4vv9vU3X9dGo4qoywzB2JWuAqYaIL8AwjC90Xd+q6/rHqGrH25I9ph7MqSg/TKGu69cDDwB3AgtRVTLnJnFsPRLDMH5n/a7rumEYxhXOyiSZ8zhhGMZuXddf1XX9I9S3/wtQFyWZ8/jxNnCOrusLgWyUAXwIMudxQdf1N1BFDmPw/zl+DfAISmv8MfGjTF000zSTPQZBEARBEIReg3i+BEEQBEEQEoiIL0EQBEEQhAQi4ksQBEEQBCGBiPgSBEEQBEFIICK+BEEQBEEQEoiIL0EQBEEQhAQifb4EQUgJdF3PA34LbDAM4zFd188HHgV+YxjG7XF83MeA84CphmEYYdzvFOA/wE2GYdwYn9EJgtATkciXIAipQh5wA3C+8++FwBnAa3F+3Aecj7Muzo8jCIIASORLEITUwYo6HarruglsBIYBvwFW67q+AbVkzL+AXwDvAQ8C/0Z9ls0xDOMt5xInt6AEVT7wDnCpYRg7/TzuL3FGvnRd3wWsRy0xthv4CfA6cJZhGKau62cCd6AWCX7PfhJd1/cC7gH2Qy1zc5dhGHfqun4ssAD4G3Ad8BkwEBgvy60IQu9EIl+CIKQK1zi3K1HCyVeqMR/IAZYCPwPmoZYD6w/c6jzmD6i1Wl8D7gKOQUW3wmF/1Jqvq51jOUjX9QEoodcJ/AM41DpY1/UM4BXUOpp/B5YD/9B1/XjDMN5ApU+vct5/AnCJCC9B6L2I+BIEIVV427ndYRjGc0C9j2M6gSuAF51/P2kYxj3AFmCEc99xzu3FqDRmPnBkmGNZbhjGX22PMxyYjhJ+jxiGMQ+1lp3FGNSi5eXAn4DZzv0zndvLgW2oNe+eMQzjpTDHIwhCD0LSjoIgpAqhLDTbZBhGq67rbc6/a5zbDiDd+bsGtKNEWIdzX7hfNCud23bnNt3HMZqP3/+HZ8Rum3NbCBQ4fx+o67pmGIYsrCsIvRSJfAmCkCrUoiJbe+i6fhbK7xUJr6G+WJ4HDAWORkXBomUZ0AzM0XX9IlQ0y2IV8D1wEDAJFQm7DJjsvP0hIAuVGj0M5TMTBKGXIuJLEISUwDCMNpR/qwR4CnfUKlz+6jzPwcC9KM/XwhiMbzvwc1QU7HfAh7bb2oETUEb961Cpx0LgG13XL3CO4XqUr+0D4O+6ro9AEIReiWaaEvkWBKHn4+wjlue1u9EwjMZkjEcQhN6LRL4EQegt/BbY6fXz26SOSBCEXokY7gVB6C08ASzy2vdDMgYiCELvRtKOgiAIgiAICUTSjoIgCIIgCAlExJcgCIIgCEICEfElCIIgCIKQQER8CYIgCIIgJJD/B6hqnVUhNOUpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(posX_test))\n",
    "print(idx)\n",
    "pred = model.predict(series=posX_test[idx][:50], past_covariates=posY_test[idx][:50], n=60)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "(posX_test[idx]*scaler).plot(label=\"actua\")\n",
    "(pred*scaler).plot(label=\"forecast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effcc013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Predicting: 5it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lowest_q, low_q, high_q, highest_q = 0.01, 0.1, 0.9, 0.99\n",
    "label_q_outer = f\"{int(lowest_q * 100)}-{int(highest_q * 100)}th percentiles\"\n",
    "label_q_inner = f\"{int(low_q * 100)}-{int(high_q * 100)}th percentiles\"\n",
    "\n",
    "idx = np.random.randint(len(posX_test))\n",
    "print(idx)\n",
    "pred = model.predict(series=posX_test[idx][:50], past_covariates=posY_test[idx][:50], n=60)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "(posX_test[idx]*scaler).plot(label=\"actual\")\n",
    "(pred*scaler).plot(low_quantile=lowest_q, high_quantile=highest_q, label=label_q_outer)\n",
    "(pred*scaler).plot(low_quantile=low_q, high_quantile=high_q, label=label_q_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe3bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
